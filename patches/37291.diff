commit 96518634fbd2b405af197df15a0d787dd883afa4
Author: lazymio <mio@lazym.io>
Date:   Sat Feb 12 21:34:46 2022 +0100

    Fix the wrong block found when doing split_region

diff --git a/tests/unit/test_mem.c b/tests/unit/test_mem.c
index 5e7a0927..d74cf3be 100644
--- a/tests/unit/test_mem.c
+++ b/tests/unit/test_mem.c
@@ -118,9 +118,36 @@ static void test_splitting_mmio_unmap()
     OK(uc_close(uc));
 }
 
+static void test_mem_protect_map_ptr()
+{
+    uc_engine *uc;
+    uint64_t val = 0x114514;
+    uint8_t *data1 = NULL;
+    uint8_t *data2 = NULL;
+    uint64_t mem;
+
+    data1 = calloc(sizeof(*data1), 0x4000);
+    data2 = calloc(sizeof(*data2), 0x2000);
+
+    OK(uc_open(UC_ARCH_X86, UC_MODE_64, &uc));
+
+    OK(uc_mem_map_ptr(uc, 0x4000, 0x4000, UC_PROT_ALL, data1));
+    OK(uc_mem_unmap(uc, 0x6000, 0x2000));
+    OK(uc_mem_map_ptr(uc, 0x6000, 0x2000, UC_PROT_ALL, data2));
+
+    OK(uc_mem_write(uc, 0x6004, &val, 8));
+    OK(uc_mem_protect(uc, 0x6000, 0x1000, UC_PROT_READ));
+    OK(uc_mem_read(uc, 0x6004, (void *)&mem, 8));
+
+    TEST_CHECK(val == mem);
+
+    OK(uc_close(uc));
+}
+
 TEST_LIST = {{"test_map_correct", test_map_correct},
              {"test_map_wrapping", test_map_wrapping},
              {"test_mem_protect", test_mem_protect},
              {"test_splitting_mem_unmap", test_splitting_mem_unmap},
              {"test_splitting_mmio_unmap", test_splitting_mmio_unmap},
+             {"test_mem_protect_map_ptr", test_mem_protect_map_ptr},
              {NULL, NULL}};
diff --git a/uc.c b/uc.c
index 57b3dd28..01bbb549 100644
--- a/uc.c
+++ b/uc.c
@@ -1167,149 +1167,151 @@ static bool split_mmio_region(struct uc_struct *uc, MemoryRegion *mr,
    The do_delete argument indicates that we are being called to support
    uc_mem_unmap. In this case we save some time by choosing NOT to remap
    the areas that are intended to get unmapped
  */
 // TODO: investigate whether qemu region manipulation functions already offered
 // this capability
 static bool split_region(struct uc_struct *uc, MemoryRegion *mr,
                          uint64_t address, size_t size, bool do_delete)
 {
     uint8_t *backup;
     uint32_t perms;
     uint64_t begin, end, chunk_end;
     size_t l_size, m_size, r_size;
     RAMBlock *block = NULL;
     bool prealloc = false;
 
     chunk_end = address + size;
 
     // if this region belongs to area [address, address+size],
     // then there is no work to do.
     if (address <= mr->addr && chunk_end >= mr->end) {
         return true;
     }
 
     if (size == 0) {
         // trivial case
         return true;
     }
 
     if (address >= mr->end || chunk_end <= mr->addr) {
         // impossible case
         return false;
     }
 
+    // Find the correct and large enough (which contains our target mr)
+    // to create the content backup.
     QLIST_FOREACH(block, &uc->ram_list.blocks, next)
     {
         // block->offset is the offset within ram_addr_t, not GPA
         if (block->mr->addr <= mr->addr &&
-            block->used_length >= (mr->end - mr->addr)) {
+            block->used_length + block->mr->addr >= mr->end) {
             break;
         }
     }
 
     if (block == NULL) {
         return false;
     }
 
     // RAM_PREALLOC is not defined outside exec.c and I didn't feel like
     // moving it
     prealloc = !!(block->flags & 1);
 
     if (block->flags & 1) {
         backup = block->host;
     } else {
         backup = copy_region(uc, mr);
         if (backup == NULL) {
             return false;
         }
     }
 
     // save the essential information required for the split before mr gets
     // deleted
     perms = mr->perms;
     begin = mr->addr;
     end = mr->end;
 
     // unmap this region first, then do split it later
     if (uc_mem_unmap(uc, mr->addr, (size_t)int128_get64(mr->size)) !=
         UC_ERR_OK) {
         goto error;
     }
 
     /* overlapping cases
      *               |------mr------|
      * case 1    |---size--|
      * case 2           |--size--|
      * case 3                  |---size--|
      */
 
     // adjust some things
     if (address < begin) {
         address = begin;
     }
     if (chunk_end > end) {
         chunk_end = end;
     }
 
     // compute sub region sizes
     l_size = (size_t)(address - begin);
     r_size = (size_t)(end - chunk_end);
     m_size = (size_t)(chunk_end - address);
 
     // If there are error in any of the below operations, things are too far
     // gone at that point to recover. Could try to remap orignal region, but
     // these smaller allocation just failed so no guarantee that we can recover
     // the original allocation at this point
     if (l_size > 0) {
         if (!prealloc) {
             if (uc_mem_map(uc, begin, l_size, perms) != UC_ERR_OK) {
                 goto error;
             }
             if (uc_mem_write(uc, begin, backup, l_size) != UC_ERR_OK) {
                 goto error;
             }
         } else {
             if (uc_mem_map_ptr(uc, begin, l_size, perms, backup) != UC_ERR_OK) {
                 goto error;
             }
         }
     }
 
     if (m_size > 0 && !do_delete) {
         if (!prealloc) {
             if (uc_mem_map(uc, address, m_size, perms) != UC_ERR_OK) {
                 goto error;
             }
             if (uc_mem_write(uc, address, backup + l_size, m_size) !=
                 UC_ERR_OK) {
                 goto error;
             }
         } else {
             if (uc_mem_map_ptr(uc, address, m_size, perms, backup + l_size) !=
                 UC_ERR_OK) {
                 goto error;
             }
         }
     }
 
     if (r_size > 0) {
         if (!prealloc) {
             if (uc_mem_map(uc, chunk_end, r_size, perms) != UC_ERR_OK) {
                 goto error;
             }
             if (uc_mem_write(uc, chunk_end, backup + l_size + m_size, r_size) !=
                 UC_ERR_OK) {
                 goto error;
             }
         } else {
             if (uc_mem_map_ptr(uc, chunk_end, r_size, perms,
                                backup + l_size + m_size) != UC_ERR_OK) {
                 goto error;
             }
         }
     }
 
     if (!prealloc) {
         free(backup);
     }
     return true;
