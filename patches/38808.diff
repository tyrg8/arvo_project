commit 1dce4fed6e3432f6fca8d4b09dc4ca6a44823ee1
Author: Daniel Lemire <lemire@gmail.com>
Date:   Mon Sep 20 09:33:21 2021 -0400

    [no ci] moving documentation bit to the right location. (#1719)

diff --git a/doc/ondemand_design.md b/doc/ondemand_design.md
index ecd88cc1..92d414e1 100644
--- a/doc/ondemand_design.md
+++ b/doc/ondemand_design.md
@@ -658,93 +658,57 @@ The On Demand API is powerful. To compensate, we add some safeguards to ensure t
 in production systems:
 
   - If the value fails to be parsed as one type, the program can try to parse it as something else until the program succeeds. Thus
     the programmer can engineer fall back routines.
   - If the value succeeds in being parsed or converted to a type, the program cannot try again. An attempt to parse the same node twice will
     cause the program to abort. We put this safety measure in the API to prevent double iteration of an array which
     would cause inconsistent iterator state or double-unescaping a string which may cause memory
     overruns if done.
   - Guaranteed Iteration: If you discard a value without using it--perhaps you just wanted to know
     if it was `nullptr` but did not care what the actual value was--it will iterate. The destructor automates
     the iteration.
 
   Some care is needed when using the On Demand API in scenarios where you need to access several sibling arrays or objects because
   only one object or array can be active at any one time. Let us consider the following example:
 
 ```C++
     ondemand::parser parser;
     const padded_string json = R"({ "parent": {"child1": {"name": "John"} , "child2": {"name": "Daniel"}} })"_padded;
     auto doc = parser.iterate(json);
     ondemand::object parent = doc["parent"];
     // parent owns the focus
     ondemand::object c1 = parent["child1"];
     // c1 owns the focus
     //
     if(std::string_view(c1["name"]) != "John") { ... }
     // c2 attempts to grab the focus from parent but fails
     ondemand::object c2 = parent["child2"];
     // c2 is now in an unsafe state and the following line would be unsafe
     // if(std::string_view(c2["name"]) != "Daniel") { return false; }
 ```
 
     A correct usage is given by the following example:
 
 ```C++
     ondemand::parser parser;
     const padded_string json = R"({ "parent": {"child1": {"name": "John"} , "child2": {"name": "Daniel"}} })"_padded;
     auto doc = parser.iterate(json);
     ondemand::object parent = doc["parent"];
     // At this point, parent owns the focus
     {
       ondemand::object c1 = parent["child1"];
       // c1 grabbed the focus from parent
       if(std::string_view(c1["name"]) != "John") { return false; }
     }
     // c1 went out of scope, so its destructor was called and the focus
     // was handed back to parent.
     {
       ondemand::object c2 = parent["child2"];
       // c2 grabbed the focus from parent
       // the following is safe:
       if(std::string_view(c2["name"]) != "Daniel") { return false; }
     }
 ```
 
-
-### Long-Running Processes and Memory Capacity
-
-The On Demand approach also automatically expands its memory capacity when larger documents are parsed. However, for longer processes where very large files are processed (such as server loops), this capacity is not resized down. Similarly to the DOM-based approach (see [here](https://github.com/simdjson/simdjson/blob/master/doc/dom.md#server-loops-long-running-processes-and-memory-capacity)]), On Demand also lets you adjust the maximal capacity that the parser can process:
-
-* You can set an upper bound (*max_capacity*) when construction the parser:
-```C++
-    ondemand::parser parser(1000*1000);  // Never grows past documents > 1 MB
-    auto doc = parser.iterate(json);
-    for (web_request request : listen()) {
-      padded_string json;
-      padded_string json = padded_string::load(request.body);
-      auto error = parser.iterate(json);
-      // If the document was above our limit, emit 413 = payload too large
-      if (error == CAPACITY) { request.respond(413); continue; }
-      // ...
-    }
-```
-
-The capacity will grow as the parser encounters larger documents up to 1 MB.
-
-* You can also allocate a *fixed capacity* that will never grow:
-```C++
-    ondemand::parser parser(1000*1000);
-    parser.allocate(1000*1000)  // Fix the capacity to 1 MB
-    auto doc = parser.iterate(json);
-    for (web_request request : listen()) {
-      padded_string json;
-      padded_string json = padded_string::load(request.body);
-      auto error = parser.iterate(json);
-      // If the document was above our limit, emit 413 = payload too large
-      if (error == CAPACITY) { request.respond(413); continue; }
-      // ...
-    }
-```
-You can also manually set the maximal capacity using the method `set_max_capacity()`.
 ### Benefits of the On Demand Approach
 
 We expect that the On Demand approach has many of the performance benefits of the schema-based approach, while providing a flexibility that is similar to that of the DOM-based approach.
diff --git a/doc/performance.md b/doc/performance.md
index fc2db8f7..79a71ea2 100644
--- a/doc/performance.md
+++ b/doc/performance.md
@@ -56,6 +56,43 @@ or simply
 ```
 
 
+Server Loops: Long-Running Processes and Memory Capacity
+---------------------------------
+
+The On Demand approach also automatically expands its memory capacity when larger documents are parsed. However, for longer processes where very large files are processed (such as server loops), this capacity is not resized down. On Demand also lets you adjust the maximal capacity that the parser can process:
+
+* You can set an upper bound (*max_capacity*) when construction the parser:
+```C++
+    ondemand::parser parser(1000*1000);  // Never grows past documents > 1 MB
+    auto doc = parser.iterate(json);
+    for (web_request request : listen()) {
+      padded_string json;
+      padded_string json = padded_string::load(request.body);
+      auto error = parser.iterate(json);
+      // If the document was above our limit, emit 413 = payload too large
+      if (error == CAPACITY) { request.respond(413); continue; }
+      // ...
+    }
+```
+
+The capacity will grow as the parser encounters larger documents up to 1 MB.
+
+* You can also allocate a *fixed capacity* that will never grow:
+```C++
+    ondemand::parser parser(1000*1000);
+    parser.allocate(1000*1000)  // Fix the capacity to 1 MB
+    auto doc = parser.iterate(json);
+    for (web_request request : listen()) {
+      padded_string json;
+      padded_string json = padded_string::load(request.body);
+      auto error = parser.iterate(json);
+      // If the document was above our limit, emit 413 = payload too large
+      if (error == CAPACITY) { request.respond(413); continue; }
+      // ...
+    }
+```
+You can also manually set the maximal capacity using the method `set_max_capacity()`.
+
 Large files and huge page support
 ---------------------------------
 
