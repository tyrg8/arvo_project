commit 718e03e5f297564b828730dfc012fa3f6fbf576b
Author: Andreas Rheinhardt <andreas.rheinhardt@outlook.com>
Date:   Tue Apr 20 18:18:36 2021 +0200

    avcodec/jpeglsdec: Don't presume the context to contain a JLSState
    
    Before 9b3c46a081a9f01559082bf7a154fc6be1e06c18 every call to
    ff_jpegls_decode_picture() allocated and freed a JLSState. This commit
    instead put said structure into the context of the JPEG-LS decoder to
    avoid said allocation. But said function can also be called from other
    MJPEG-based decoders and their contexts doesn't contain said structure,
    leading to segfaults. This commit fixes this: The JLSState is now
    allocated on the first call to ff_jpegls_decode_picture() and stored in
    the context.
    
    Found-by: Michael Niedermayer <michael@niedermayer.cc>
    Reviewed-by: Michael Niedermayer <michael@niedermayer.cc>
    Signed-off-by: Andreas Rheinhardt <andreas.rheinhardt@outlook.com>

diff --git a/libavcodec/jpeglsdec.c b/libavcodec/jpeglsdec.c
index 92df81600b..e17de09e9f 100644
--- a/libavcodec/jpeglsdec.c
+++ b/libavcodec/jpeglsdec.c
@@ -45,11 +45,6 @@
  */
 //#define JLS_BROKEN
 
-typedef struct JpegLSDecodeContext {
-    MJpegDecodeContext mjpeg;
-    JLSState state;
-} JpegLSDecodeContext;
-
 /**
  * Decode LSE block with initialization parameters
  */
@@ -353,186 +348,192 @@ static inline int ls_decode_line(JLSState *state, MJpegDecodeContext *s,
 int ff_jpegls_decode_picture(MJpegDecodeContext *s, int near,
                              int point_transform, int ilv)
 {
     int i, t = 0;
     uint8_t *zero, *last, *cur;
-    JLSState *const state = &((JpegLSDecodeContext*)s)->state;
+    JLSState *state = s->jls_state;
     int off = 0, stride = 1, width, shift, ret = 0;
     int decoded_height = 0;
 
+    if (!state) {
+        state = av_malloc(sizeof(*state));
+        if (!state)
+            return AVERROR(ENOMEM);
+        s->jls_state = state;
+    }
     zero = av_mallocz(s->picture_ptr->linesize[0]);
     if (!zero)
         return AVERROR(ENOMEM);
     last = zero;
     cur  = s->picture_ptr->data[0];
 
     /* initialize JPEG-LS state from JPEG parameters */
     memset(state, 0, sizeof(*state));
     state->near   = near;
     state->bpp    = (s->bits < 2) ? 2 : s->bits;
     state->maxval = s->maxval;
     state->T1     = s->t1;
     state->T2     = s->t2;
     state->T3     = s->t3;
     state->reset  = s->reset;
     ff_jpegls_reset_coding_parameters(state, 0);
     ff_jpegls_init_state(state);
 
     if (s->bits <= 8)
         shift = point_transform + (8 - s->bits);
     else
         shift = point_transform + (16 - s->bits);
 
     if (shift >= 16) {
         ret = AVERROR_INVALIDDATA;
         goto end;
     }
 
     if (s->avctx->debug & FF_DEBUG_PICT_INFO) {
         av_log(s->avctx, AV_LOG_DEBUG,
                "JPEG-LS params: %ix%i NEAR=%i MV=%i T(%i,%i,%i) "
                "RESET=%i, LIMIT=%i, qbpp=%i, RANGE=%i\n",
                 s->width, s->height, state->near, state->maxval,
                 state->T1, state->T2, state->T3,
                 state->reset, state->limit, state->qbpp, state->range);
         av_log(s->avctx, AV_LOG_DEBUG, "JPEG params: ILV=%i Pt=%i BPP=%i, scan = %i\n",
                 ilv, point_transform, s->bits, s->cur_scan);
     }
     if (get_bits_left(&s->gb) < s->height) {
         ret = AVERROR_INVALIDDATA;
         goto end;
     }
     if (ilv == 0) { /* separate planes */
         if (s->cur_scan > s->nb_components) {
             ret = AVERROR_INVALIDDATA;
             goto end;
         }
         stride = (s->nb_components > 1) ? 3 : 1;
         off    = av_clip(s->cur_scan - 1, 0, stride - 1);
         width  = s->width * stride;
         cur   += off;
         for (i = 0; i < s->height; i++) {
             int ret;
             if (s->bits <= 8) {
                 ret = ls_decode_line(state, s, last, cur, t, width, stride, off, 8);
                 t = last[0];
             } else {
                 ret = ls_decode_line(state, s, last, cur, t, width, stride, off, 16);
                 t = *((uint16_t *)last);
             }
             if (ret < 0)
                 break;
             last = cur;
             cur += s->picture_ptr->linesize[0];
 
             if (s->restart_interval && !--s->restart_count) {
                 align_get_bits(&s->gb);
                 skip_bits(&s->gb, 16); /* skip RSTn */
             }
         }
         decoded_height = i;
     } else if (ilv == 1) { /* line interleaving */
         int j;
         int Rc[3] = { 0, 0, 0 };
         stride = (s->nb_components > 1) ? 3 : 1;
         memset(cur, 0, s->picture_ptr->linesize[0]);
         width = s->width * stride;
         for (i = 0; i < s->height; i++) {
             int ret;
             for (j = 0; j < stride; j++) {
                 ret = ls_decode_line(state, s, last + j, cur + j,
                                Rc[j], width, stride, j, 8);
                 if (ret < 0)
                     break;
                 Rc[j] = last[j];
 
                 if (s->restart_interval && !--s->restart_count) {
                     align_get_bits(&s->gb);
                     skip_bits(&s->gb, 16); /* skip RSTn */
                 }
             }
             if (ret < 0)
                 break;
             last = cur;
             cur += s->picture_ptr->linesize[0];
         }
         decoded_height = i;
     } else if (ilv == 2) { /* sample interleaving */
         avpriv_report_missing_feature(s->avctx, "Sample interleaved images");
         ret = AVERROR_PATCHWELCOME;
         goto end;
     } else { /* unknown interleaving */
         avpriv_report_missing_feature(s->avctx, "Unknown interleaved images");
         ret = AVERROR_PATCHWELCOME;
         goto end;
     }
 
     if (s->xfrm && s->nb_components == 3) {
         int x, w;
 
         w = s->width * s->nb_components;
 
         if (s->bits <= 8) {
             uint8_t *src = s->picture_ptr->data[0];
 
             for (i = 0; i < s->height; i++) {
                 switch(s->xfrm) {
                 case 1:
                     for (x = off; x < w; x += 3) {
                         src[x  ] += src[x+1] + 128;
                         src[x+2] += src[x+1] + 128;
                     }
                     break;
                 case 2:
                     for (x = off; x < w; x += 3) {
                         src[x  ] += src[x+1] + 128;
                         src[x+2] += ((src[x  ] + src[x+1])>>1) + 128;
                     }
                     break;
                 case 3:
                     for (x = off; x < w; x += 3) {
                         int g = src[x+0] - ((src[x+2]+src[x+1])>>2) + 64;
                         src[x+0] = src[x+2] + g + 128;
                         src[x+2] = src[x+1] + g + 128;
                         src[x+1] = g;
                     }
                     break;
                 case 4:
                     for (x = off; x < w; x += 3) {
                         int r    = src[x+0] - ((                       359 * (src[x+2]-128) + 490) >> 8);
                         int g    = src[x+0] - (( 88 * (src[x+1]-128) - 183 * (src[x+2]-128) +  30) >> 8);
                         int b    = src[x+0] + ((454 * (src[x+1]-128)                        + 574) >> 8);
                         src[x+0] = av_clip_uint8(r);
                         src[x+1] = av_clip_uint8(g);
                         src[x+2] = av_clip_uint8(b);
                     }
                     break;
                 }
                 src += s->picture_ptr->linesize[0];
             }
         }else
             avpriv_report_missing_feature(s->avctx, "16bit xfrm");
     }
 
     if (shift) { /* we need to do point transform or normalize samples */
         int x, w;
 
         w = s->width * s->nb_components;
 
         if (s->bits <= 8) {
             uint8_t *src = s->picture_ptr->data[0];
 
             for (i = 0; i < decoded_height; i++) {
                 for (x = off; x < w; x += stride)
                     src[x] <<= shift;
                 src += s->picture_ptr->linesize[0];
             }
         } else {
             uint16_t *src = (uint16_t *)s->picture_ptr->data[0];
 
             for (i = 0; i < decoded_height; i++) {
                 for (x = 0; x < w; x++)
                     src[x] <<= shift;
                 src += s->picture_ptr->linesize[0] / 2;
             }
         }
     }
@@ -546,13 +547,13 @@ end:
 AVCodec ff_jpegls_decoder = {
     .name           = "jpegls",
     .long_name      = NULL_IF_CONFIG_SMALL("JPEG-LS"),
     .type           = AVMEDIA_TYPE_VIDEO,
     .id             = AV_CODEC_ID_JPEGLS,
-    .priv_data_size = sizeof(JpegLSDecodeContext),
+    .priv_data_size = sizeof(MJpegDecodeContext),
     .init           = ff_mjpeg_decode_init,
     .close          = ff_mjpeg_decode_end,
     .receive_frame  = ff_mjpeg_receive_frame,
     .capabilities   = AV_CODEC_CAP_DR1,
     .caps_internal  = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |
                       FF_CODEC_CAP_SETS_PKT_DTS,
 };
diff --git a/libavcodec/mjpegdec.c b/libavcodec/mjpegdec.c
index f3d9e99aab..7c7cc20af8 100644
--- a/libavcodec/mjpegdec.c
+++ b/libavcodec/mjpegdec.c
@@ -2880,42 +2880,43 @@ the_end_no_picture:
 /* mxpeg may call the following function (with a blank MJpegDecodeContext)
  * even without having called ff_mjpeg_decode_init(). */
 av_cold int ff_mjpeg_decode_end(AVCodecContext *avctx)
 {
     MJpegDecodeContext *s = avctx->priv_data;
     int i, j;
 
     if (s->interlaced && s->bottom_field == !s->interlace_polarity && s->got_picture && !avctx->frame_number) {
         av_log(avctx, AV_LOG_INFO, "Single field\n");
     }
 
     if (s->picture) {
         av_frame_free(&s->picture);
         s->picture_ptr = NULL;
     } else if (s->picture_ptr)
         av_frame_unref(s->picture_ptr);
 
     av_packet_free(&s->pkt);
 
     av_frame_free(&s->smv_frame);
 
     av_freep(&s->buffer);
     av_freep(&s->stereo3d);
     av_freep(&s->ljpeg_buffer);
     s->ljpeg_buffer_size = 0;
 
     for (i = 0; i < 3; i++) {
         for (j = 0; j < 4; j++)
             ff_free_vlc(&s->vlcs[i][j]);
     }
     for (i = 0; i < MAX_COMPONENTS; i++) {
         av_freep(&s->blocks[i]);
         av_freep(&s->last_nnz[i]);
     }
     av_dict_free(&s->exif_metadata);
 
     reset_icc_profile(s);
 
     av_freep(&s->hwaccel_picture_private);
+    av_freep(&s->jls_state);
 
     return 0;
 }
diff --git a/libavcodec/mjpegdec.h b/libavcodec/mjpegdec.h
index 0d69d9101b..2400a179f1 100644
--- a/libavcodec/mjpegdec.h
+++ b/libavcodec/mjpegdec.h
@@ -49,120 +49,123 @@ typedef struct ICCEntry {
     int    length;
 } ICCEntry;
 
+struct JLSState;
+
 typedef struct MJpegDecodeContext {
     AVClass *class;
     AVCodecContext *avctx;
     GetBitContext gb;
     int buf_size;
 
     AVPacket *pkt;
 
     int start_code; /* current start code */
     int buffer_size;
     uint8_t *buffer;
 
     uint16_t quant_matrixes[4][64];
     VLC vlcs[3][4];
     int qscale[4];      ///< quantizer scale calculated from quant_matrixes
 
     int orig_height;  /* size given at codec init */
     int first_picture;    /* true if decoding first picture */
     int interlaced;     /* true if interlaced */
     int bottom_field;   /* true if bottom field */
     int lossless;
     int ls;
     int progressive;
     int bayer;          /* true if it's a bayer-encoded JPEG embedded in a DNG */
     int rgb;
     uint8_t upscale_h[4];
     uint8_t upscale_v[4];
     int rct;            /* standard rct */
     int pegasus_rct;    /* pegasus reversible colorspace transform */
     int bits;           /* bits per component */
     int colr;
     int xfrm;
     int adobe_transform;
 
     int maxval;
     int near;         ///< near lossless bound (si 0 for lossless)
     int t1,t2,t3;
     int reset;        ///< context halfing interval ?rename
 
     int width, height;
     int mb_width, mb_height;
     int nb_components;
     int block_stride[MAX_COMPONENTS];
     int component_id[MAX_COMPONENTS];
     int h_count[MAX_COMPONENTS]; /* horizontal and vertical count for each component */
     int v_count[MAX_COMPONENTS];
     int comp_index[MAX_COMPONENTS];
     int dc_index[MAX_COMPONENTS];
     int ac_index[MAX_COMPONENTS];
     int nb_blocks[MAX_COMPONENTS];
     int h_scount[MAX_COMPONENTS];
     int v_scount[MAX_COMPONENTS];
     int quant_sindex[MAX_COMPONENTS];
     int h_max, v_max; /* maximum h and v counts */
     int quant_index[4];   /* quant table index for each component */
     int last_dc[MAX_COMPONENTS]; /* last DEQUANTIZED dc (XXX: am I right to do that ?) */
     AVFrame *picture; /* picture structure */
     AVFrame *picture_ptr; /* pointer to picture structure */
     int got_picture;                                ///< we found a SOF and picture is valid, too.
     int linesize[MAX_COMPONENTS];                   ///< linesize << interlaced
     int8_t *qscale_table;
     DECLARE_ALIGNED(32, int16_t, block)[64];
     int16_t (*blocks[MAX_COMPONENTS])[64]; ///< intermediate sums (progressive mode)
     uint8_t *last_nnz[MAX_COMPONENTS];
     uint64_t coefs_finished[MAX_COMPONENTS]; ///< bitmask of which coefs have been completely decoded (progressive mode)
     int palette_index;
     ScanTable scantable;
     BlockDSPContext bdsp;
     HpelDSPContext hdsp;
     IDCTDSPContext idsp;
 
     int restart_interval;
     int restart_count;
 
     int buggy_avid;
     int cs_itu601;
     int interlace_polarity;
     int multiscope;
 
     int mjpb_skiptosod;
 
     int cur_scan; /* current scan, used by JPEG-LS */
     int flipped; /* true if picture is flipped */
 
     uint16_t (*ljpeg_buffer)[4];
     unsigned int ljpeg_buffer_size;
 
     int extern_huff;
     AVDictionary *exif_metadata;
 
     AVStereo3D *stereo3d; ///!< stereoscopic information (cached, since it is read before frame allocation)
 
     const AVPixFmtDescriptor *pix_desc;
 
     ICCEntry *iccentries;
     int iccnum;
     int iccread;
 
     AVFrame *smv_frame;
     int smv_frames_per_jpeg;
     int smv_next_frame;
 
     // Raw stream data for hwaccel use.
     const uint8_t *raw_image_buffer;
     size_t         raw_image_buffer_size;
     const uint8_t *raw_scan_buffer;
     size_t         raw_scan_buffer_size;
 
     uint8_t raw_huffman_lengths[2][4][16];
     uint8_t raw_huffman_values[2][4][256];
 
     enum AVPixelFormat hwaccel_sw_pix_fmt;
     enum AVPixelFormat hwaccel_pix_fmt;
     void *hwaccel_picture_private;
+    struct JLSState *jls_state;
 } MJpegDecodeContext;
 
 int ff_mjpeg_build_vlc(VLC *vlc, const uint8_t *bits_table,
