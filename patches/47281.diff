commit ca8a0f3ea32af8fdaf2f99ad87a43e82be854f62
Author: Behdad Esfahbod <behdad@behdad.org>
Date:   Fri May 6 11:54:38 2022 -0600

    [gvar] Protect against out-of-range access
    
    Fixes https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=47281
    Fixes https://oss-fuzz.com/testcase-detail/5508865908670464

diff --git a/src/hb-ot-var-gvar-table.hh b/src/hb-ot-var-gvar-table.hh
index 618cec08f..05c1fafd1 100644
--- a/src/hb-ot-var-gvar-table.hh
+++ b/src/hb-ot-var-gvar-table.hh
@@ -385,268 +385,271 @@ struct GlyphVariationData
 struct gvar
 {
   static constexpr hb_tag_t tableTag = HB_OT_TAG_gvar;
 
   bool sanitize_shallow (hb_sanitize_context_t *c) const
   {
     TRACE_SANITIZE (this);
     return_trace (c->check_struct (this) && (version.major == 1) &&
 		  (glyphCount == c->get_num_glyphs ()) &&
 		  sharedTuples.sanitize (c, this, axisCount * sharedTupleCount) &&
 		  (is_long_offset () ?
 		     c->check_array (get_long_offset_array (), glyphCount+1) :
 		     c->check_array (get_short_offset_array (), glyphCount+1)) &&
 		  c->check_array (((const HBUINT8*)&(this+dataZ)) + get_offset (0),
 				  get_offset (glyphCount) - get_offset (0)));
   }
 
   /* GlyphVariationData not sanitized here; must be checked while accessing each glyph variation data */
   bool sanitize (hb_sanitize_context_t *c) const
   { return sanitize_shallow (c); }
 
   bool subset (hb_subset_context_t *c) const
   {
     TRACE_SUBSET (this);
 
     gvar *out = c->serializer->allocate_min<gvar> ();
     if (unlikely (!out)) return_trace (false);
 
     out->version.major = 1;
     out->version.minor = 0;
     out->axisCount = axisCount;
     out->sharedTupleCount = sharedTupleCount;
 
     unsigned int num_glyphs = c->plan->num_output_glyphs ();
     out->glyphCount = num_glyphs;
 
     unsigned int subset_data_size = 0;
     for (hb_codepoint_t gid = (c->plan->flags & HB_SUBSET_FLAGS_NOTDEF_OUTLINE) ? 0 : 1;
          gid < num_glyphs;
          gid++)
     {
       hb_codepoint_t old_gid;
       if (!c->plan->old_gid_for_new_gid (gid, &old_gid)) continue;
       subset_data_size += get_glyph_var_data_bytes (c->source_blob, old_gid).length;
     }
 
     bool long_offset = subset_data_size & ~0xFFFFu;
     out->flags = long_offset ? 1 : 0;
 
     HBUINT8 *subset_offsets = c->serializer->allocate_size<HBUINT8> ((long_offset ? 4 : 2) * (num_glyphs + 1));
     if (!subset_offsets) return_trace (false);
 
     /* shared tuples */
     if (!sharedTupleCount || !sharedTuples)
       out->sharedTuples = 0;
     else
     {
       unsigned int shared_tuple_size = F2DOT14::static_size * axisCount * sharedTupleCount;
       F2DOT14 *tuples = c->serializer->allocate_size<F2DOT14> (shared_tuple_size);
       if (!tuples) return_trace (false);
       out->sharedTuples = (char *) tuples - (char *) out;
       memcpy (tuples, this+sharedTuples, shared_tuple_size);
     }
 
     char *subset_data = c->serializer->allocate_size<char> (subset_data_size);
     if (!subset_data) return_trace (false);
     out->dataZ = subset_data - (char *) out;
 
     unsigned int glyph_offset = 0;
     for (hb_codepoint_t gid = (c->plan->flags & HB_SUBSET_FLAGS_NOTDEF_OUTLINE) ? 0 : 1;
          gid < num_glyphs;
          gid++)
     {
       hb_codepoint_t old_gid;
       hb_bytes_t var_data_bytes = c->plan->old_gid_for_new_gid (gid, &old_gid)
 				? get_glyph_var_data_bytes (c->source_blob, old_gid)
 				: hb_bytes_t ();
 
       if (long_offset)
 	((HBUINT32 *) subset_offsets)[gid] = glyph_offset;
       else
 	((HBUINT16 *) subset_offsets)[gid] = glyph_offset / 2;
 
       if (var_data_bytes.length > 0)
 	memcpy (subset_data, var_data_bytes.arrayZ, var_data_bytes.length);
       subset_data += var_data_bytes.length;
       glyph_offset += var_data_bytes.length;
     }
     if (long_offset)
       ((HBUINT32 *) subset_offsets)[num_glyphs] = glyph_offset;
     else
       ((HBUINT16 *) subset_offsets)[num_glyphs] = glyph_offset / 2;
 
     return_trace (true);
   }
 
   protected:
   const hb_bytes_t get_glyph_var_data_bytes (hb_blob_t *blob, hb_codepoint_t glyph) const
   {
     unsigned start_offset = get_offset (glyph);
     unsigned length = get_offset (glyph+1) - start_offset;
     hb_bytes_t var_data = blob->as_bytes ().sub_array (((unsigned) dataZ) + start_offset, length);
     return likely (var_data.length >= GlyphVariationData::min_size) ? var_data : hb_bytes_t ();
   }
 
   bool is_long_offset () const { return flags & 1; }
 
   unsigned get_offset (unsigned i) const
-  { return is_long_offset () ? get_long_offset_array ()[i] : get_short_offset_array ()[i] * 2; }
+  {
+    if (unlikely (i > glyphCount)) return 0;
+    return is_long_offset () ? get_long_offset_array ()[i] : get_short_offset_array ()[i] * 2;
+  }
 
   const HBUINT32 * get_long_offset_array () const { return (const HBUINT32 *) &offsetZ; }
   const HBUINT16 *get_short_offset_array () const { return (const HBUINT16 *) &offsetZ; }
 
   public:
   struct accelerator_t
   {
     accelerator_t (hb_face_t *face)
     { table = hb_sanitize_context_t ().reference_table<gvar> (face); }
     ~accelerator_t () { table.destroy (); }
 
     private:
     struct x_getter { static float get (const contour_point_t &p) { return p.x; } };
     struct y_getter { static float get (const contour_point_t &p) { return p.y; } };
 
     template <typename T>
     static float infer_delta (const hb_array_t<contour_point_t> points,
 			      const hb_array_t<contour_point_t> deltas,
 			      unsigned int target, unsigned int prev, unsigned int next)
     {
       float target_val = T::get (points[target]);
       float prev_val = T::get (points[prev]);
       float next_val = T::get (points[next]);
       float prev_delta = T::get (deltas[prev]);
       float next_delta = T::get (deltas[next]);
 
       if (prev_val == next_val)
 	return (prev_delta == next_delta) ? prev_delta : 0.f;
       else if (target_val <= hb_min (prev_val, next_val))
 	return (prev_val < next_val) ? prev_delta : next_delta;
       else if (target_val >= hb_max (prev_val, next_val))
 	return (prev_val > next_val) ? prev_delta : next_delta;
 
       /* linear interpolation */
       float r = (target_val - prev_val) / (next_val - prev_val);
       return (1.f - r) * prev_delta + r * next_delta;
     }
 
     static unsigned int next_index (unsigned int i, unsigned int start, unsigned int end)
     { return (i >= end) ? start : (i + 1); }
 
     public:
     bool apply_deltas_to_points (hb_codepoint_t glyph, hb_font_t *font,
 				 const hb_array_t<contour_point_t> points) const
     {
       /* num_coords should exactly match gvar's axisCount due to how GlyphVariationData tuples are aligned */
       if (!font->num_coords || font->num_coords != table->axisCount) return true;
 
       if (unlikely (glyph >= table->glyphCount)) return true;
 
       hb_bytes_t var_data_bytes = table->get_glyph_var_data_bytes (table.get_blob (), glyph);
       if (!var_data_bytes.as<GlyphVariationData> ()->has_data ()) return true;
       hb_vector_t<unsigned int> shared_indices;
       GlyphVariationData::tuple_iterator_t iterator;
       if (!GlyphVariationData::get_tuple_iterator (var_data_bytes, table->axisCount,
 						   shared_indices, &iterator))
 	return true; /* so isn't applied at all */
 
       /* Save original points for inferred delta calculation */
       contour_point_vector_t orig_points;
       orig_points.resize (points.length);
       for (unsigned int i = 0; i < orig_points.length; i++)
 	orig_points[i] = points[i];
 
       contour_point_vector_t deltas; /* flag is used to indicate referenced point */
       deltas.resize (points.length);
 
       hb_vector_t<unsigned> end_points;
       for (unsigned i = 0; i < points.length; ++i)
 	if (points[i].is_end_point)
 	  end_points.push (i);
 
       int *coords = font->coords;
       unsigned num_coords = font->num_coords;
       hb_array_t<const F2DOT14> shared_tuples = (table+table->sharedTuples).as_array (table->sharedTupleCount * table->axisCount);
       do
       {
 	float scalar = iterator.current_tuple->calculate_scalar (coords, num_coords, shared_tuples);
 	if (scalar == 0.f) continue;
 	const HBUINT8 *p = iterator.get_serialized_data ();
 	unsigned int length = iterator.current_tuple->get_data_size ();
 	if (unlikely (!iterator.var_data_bytes.check_range (p, length)))
 	  return false;
 
 	hb_bytes_t bytes ((const char *) p, length);
 	hb_vector_t<unsigned int> private_indices;
 	bool has_private_points = iterator.current_tuple->has_private_points ();
 	if (has_private_points &&
 	    !GlyphVariationData::unpack_points (p, private_indices, bytes))
 	  return false;
 	const hb_array_t<unsigned int> &indices = has_private_points ? private_indices : shared_indices;
 
 	bool apply_to_all = (indices.length == 0);
 	unsigned int num_deltas = apply_to_all ? points.length : indices.length;
 	hb_vector_t<int> x_deltas;
 	x_deltas.resize (num_deltas);
 	if (!GlyphVariationData::unpack_deltas (p, x_deltas, bytes))
 	  return false;
 	hb_vector_t<int> y_deltas;
 	y_deltas.resize (num_deltas);
 	if (!GlyphVariationData::unpack_deltas (p, y_deltas, bytes))
 	  return false;
 
 	for (unsigned int i = 0; i < deltas.length; i++)
 	  deltas[i].init ();
 	for (unsigned int i = 0; i < num_deltas; i++)
 	{
 	  unsigned int pt_index = apply_to_all ? i : indices[i];
 	  deltas[pt_index].flag = 1;	/* this point is referenced, i.e., explicit deltas specified */
 	  deltas[pt_index].x += x_deltas[i] * scalar;
 	  deltas[pt_index].y += y_deltas[i] * scalar;
 	}
 
 	/* infer deltas for unreferenced points */
 	unsigned start_point = 0;
 	for (unsigned c = 0; c < end_points.length; c++)
 	{
 	  unsigned end_point = end_points[c];
 
 	  /* Check the number of unreferenced points in a contour. If no unref points or no ref points, nothing to do. */
 	  unsigned unref_count = 0;
 	  for (unsigned i = start_point; i <= end_point; i++)
 	    if (!deltas[i].flag) unref_count++;
 
 	  unsigned j = start_point;
 	  if (unref_count == 0 || unref_count > end_point - start_point)
 	    goto no_more_gaps;
 
 	  for (;;)
 	  {
 	    /* Locate the next gap of unreferenced points between two referenced points prev and next.
 	     * Note that a gap may wrap around at left (start_point) and/or at right (end_point).
 	     */
 	    unsigned int prev, next, i;
 	    for (;;)
 	    {
 	      i = j;
 	      j = next_index (i, start_point, end_point);
 	      if (deltas[i].flag && !deltas[j].flag) break;
 	    }
 	    prev = j = i;
 	    for (;;)
 	    {
 	      i = j;
 	      j = next_index (i, start_point, end_point);
 	      if (!deltas[i].flag && deltas[j].flag) break;
 	    }
 	    next = j;
 	    /* Infer deltas for all unref points in the gap between prev and next */
 	    i = prev;
 	    for (;;)
 	    {
 	      i = next_index (i, start_point, end_point);
 	      if (i == next) break;
 	      deltas[i].x = infer_delta<x_getter> (orig_points.as_array (), deltas.as_array (), i, prev, next);
 	      deltas[i].y = infer_delta<y_getter> (orig_points.as_array (), deltas.as_array (), i, prev, next);
 	      if (--unref_count == 0) goto no_more_gaps;
 	    }
 	  }
diff --git a/test/fuzzing/fonts/clusterfuzz-testcase-hb-subset-fuzzer-5508865908670464 b/test/fuzzing/fonts/clusterfuzz-testcase-hb-subset-fuzzer-5508865908670464
new file mode 100644
index 000000000..140481059
Binary files /dev/null and b/test/fuzzing/fonts/clusterfuzz-testcase-hb-subset-fuzzer-5508865908670464 differ
