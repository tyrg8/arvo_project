commit b7e98787c4698521b7adc771ee919a74e83f28ed
Author: Michael Tuexen <tuexen@fh-muenster.de>
Date:   Sat Oct 12 20:01:57 2019 +0200

    Ensure that local variables are reset to their initial value when
    dealing with error cases in a loop over all remote addresses.
    This issue was found and reported by OSS_Fuzz in:
    https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=18080
    https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=18086
    https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=18121
    https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=18163

diff --git a/usrsctplib/netinet/sctp_output.c b/usrsctplib/netinet/sctp_output.c
index 7a123856..579d7313 100755
--- a/usrsctplib/netinet/sctp_output.c
+++ b/usrsctplib/netinet/sctp_output.c
@@ -34,58 +34,58 @@
 
 #ifdef __FreeBSD__
 #include <sys/cdefs.h>
-__FBSDID("$FreeBSD: head/sys/netinet/sctp_output.c 353119 2019-10-05 09:46:11Z tuexen $");
+__FBSDID("$FreeBSD: head/sys/netinet/sctp_output.c 353452 2019-10-12 17:57:03Z tuexen $");
 #endif
 
 #include <netinet/sctp_os.h>
 #ifdef __FreeBSD__
 #include <sys/proc.h>
 #endif
 #include <netinet/sctp_var.h>
 #include <netinet/sctp_sysctl.h>
 #include <netinet/sctp_header.h>
 #include <netinet/sctp_pcb.h>
 #include <netinet/sctputil.h>
 #include <netinet/sctp_output.h>
 #include <netinet/sctp_uio.h>
 #include <netinet/sctputil.h>
 #include <netinet/sctp_auth.h>
 #include <netinet/sctp_timer.h>
 #include <netinet/sctp_asconf.h>
 #include <netinet/sctp_indata.h>
 #include <netinet/sctp_bsd_addr.h>
 #include <netinet/sctp_input.h>
 #include <netinet/sctp_crc32.h>
 #if defined(__Userspace_os_Linux)
 #define __FAVOR_BSD    /* (on Ubuntu at least) enables UDP header field names like BSD in RFC 768 */
 #endif
 #if defined(INET) || defined(INET6)
 #if !defined(__Userspace_os_Windows)
 #include <netinet/udp.h>
 #endif
 #endif
 #if defined(__APPLE__)
 #include <netinet/in.h>
 #endif
 #if defined(__FreeBSD__)
 #if defined(__FreeBSD__) && __FreeBSD_version >= 800000
 #include <netinet/udp_var.h>
 #endif
 #include <machine/in_cksum.h>
 #include <netinet/in_kdtrace.h>
 #endif
 #if defined(__Userspace__) && defined(INET6)
 #include <netinet6/sctp6_var.h>
 #endif
 
 #if defined(__APPLE__)
 #define APPLE_FILE_NO 3
 #endif
 
 #if defined(__APPLE__)
 #if !(defined(APPLE_LEOPARD) || defined(APPLE_SNOWLEOPARD))
 #define SCTP_MAX_LINKHDR 16
 #endif
 #endif
 
 #define SCTP_MAX_GAPS_INARRAY 4
@@ -8343,1117 +8343,1119 @@ int
 sctp_med_chunk_output(struct sctp_inpcb *inp,
 		      struct sctp_tcb *stcb,
 		      struct sctp_association *asoc,
 		      int *num_out,
 		      int *reason_code,
 		      int control_only, int from_where,
 		      struct timeval *now, int *now_filled, int frag_point, int so_locked
 #if !defined(__APPLE__) && !defined(SCTP_SO_LOCK_TESTING)
 		      SCTP_UNUSED
 #endif
 	)
 {
 	/**
 	 * Ok this is the generic chunk service queue. we must do the
 	 * following:
 	 * - Service the stream queue that is next, moving any
 	 *   message (note I must get a complete message i.e. FIRST/MIDDLE and
 	 *   LAST to the out queue in one pass) and assigning TSN's. This
 	 *   only applys though if the peer does not support NDATA. For NDATA
 	 *   chunks its ok to not send the entire message ;-)
 	 * - Check to see if the cwnd/rwnd allows any output, if so we go ahead and
 	 *   fomulate and send the low level chunks. Making sure to combine
 	 *   any control in the control chunk queue also.
 	 */
 	struct sctp_nets *net, *start_at, *sack_goes_to = NULL, *old_start_at = NULL;
 	struct mbuf *outchain, *endoutchain;
 	struct sctp_tmit_chunk *chk, *nchk;
 
 	/* temp arrays for unlinking */
 	struct sctp_tmit_chunk *data_list[SCTP_MAX_DATA_BUNDLING];
 	int no_fragmentflg, error;
 	unsigned int max_rwnd_per_dest, max_send_per_dest;
 	int one_chunk, hbflag, skip_data_for_this_net;
 	int asconf, cookie, no_out_cnt;
 	int bundle_at, ctl_cnt, no_data_chunks, eeor_mode;
 	unsigned int mtu, r_mtu, omtu, mx_mtu, to_out;
 	int tsns_sent = 0;
-	uint32_t auth_offset = 0;
-	struct sctp_auth_chunk *auth = NULL;
+	uint32_t auth_offset;
+	struct sctp_auth_chunk *auth;
 	uint16_t auth_keyid;
 	int override_ok = 1;
 	int skip_fill_up = 0;
 	int data_auth_reqd = 0;
 	/* JRS 5/14/07 - Add flag for whether a heartbeat is sent to
 	   the destination. */
 	int quit_now = 0;
 
 #if defined(__APPLE__)
 	if (so_locked) {
 		sctp_lock_assert(SCTP_INP_SO(inp));
 	} else {
 		sctp_unlock_assert(SCTP_INP_SO(inp));
 	}
 #endif
 	*num_out = 0;
 	*reason_code = 0;
 	auth_keyid = stcb->asoc.authinfo.active_keyid;
 	if ((asoc->state & SCTP_STATE_SHUTDOWN_PENDING) ||
 	    (SCTP_GET_STATE(stcb) == SCTP_STATE_SHUTDOWN_RECEIVED) ||
 	    (sctp_is_feature_on(inp, SCTP_PCB_FLAGS_EXPLICIT_EOR))) {
 		eeor_mode = 1;
 	} else {
 		eeor_mode = 0;
 	}
 	ctl_cnt = no_out_cnt = asconf = cookie = 0;
 	/*
 	 * First lets prime the pump. For each destination, if there is room
 	 * in the flight size, attempt to pull an MTU's worth out of the
 	 * stream queues into the general send_queue
 	 */
 #ifdef SCTP_AUDITING_ENABLED
 	sctp_audit_log(0xC2, 2);
 #endif
 	SCTP_TCB_LOCK_ASSERT(stcb);
 	hbflag = 0;
 	if (control_only)
 		no_data_chunks = 1;
 	else
 		no_data_chunks = 0;
 
 	/* Nothing to possible to send? */
 	if ((TAILQ_EMPTY(&asoc->control_send_queue) ||
 	     (asoc->ctrl_queue_cnt == stcb->asoc.ecn_echo_cnt_onq)) &&
 	    TAILQ_EMPTY(&asoc->asconf_send_queue) &&
 	    TAILQ_EMPTY(&asoc->send_queue) &&
 	    sctp_is_there_unsent_data(stcb, so_locked) == 0) {
 	nothing_to_send:
 		*reason_code = 9;
 		return (0);
 	}
 	if (asoc->peers_rwnd == 0) {
 		/* No room in peers rwnd */
 		*reason_code = 1;
 		if (asoc->total_flight > 0) {
 			/* we are allowed one chunk in flight */
 			no_data_chunks = 1;
 		}
 	}
 	if (stcb->asoc.ecn_echo_cnt_onq) {
 		/* Record where a sack goes, if any */
 		if (no_data_chunks &&
 		    (asoc->ctrl_queue_cnt == stcb->asoc.ecn_echo_cnt_onq)) {
 			/* Nothing but ECNe to send - we don't do that */
 			goto nothing_to_send;
 		}
 		TAILQ_FOREACH(chk, &asoc->control_send_queue, sctp_next) {
 			if ((chk->rec.chunk_id.id == SCTP_SELECTIVE_ACK) ||
 			    (chk->rec.chunk_id.id == SCTP_NR_SELECTIVE_ACK)) {
 				sack_goes_to = chk->whoTo;
 				break;
 			}
 		}
 	}
 	max_rwnd_per_dest = ((asoc->peers_rwnd + asoc->total_flight) / asoc->numnets);
 	if (stcb->sctp_socket)
 		max_send_per_dest = SCTP_SB_LIMIT_SND(stcb->sctp_socket) / asoc->numnets;
 	else
 		max_send_per_dest = 0;
 	if (no_data_chunks == 0) {
 		/* How many non-directed chunks are there? */
 		TAILQ_FOREACH(chk, &asoc->send_queue, sctp_next) {
 			if (chk->whoTo == NULL) {
 				/* We already have non-directed
 				 * chunks on the queue, no need
 				 * to do a fill-up.
 				 */
 				skip_fill_up = 1;
 				break;
 			}
 		}
 
 	}
 	if ((no_data_chunks == 0) &&
 	    (skip_fill_up == 0) &&
 	    (!stcb->asoc.ss_functions.sctp_ss_is_empty(stcb, asoc))) {
 		TAILQ_FOREACH(net, &asoc->nets, sctp_next) {
 			/*
 			 * This for loop we are in takes in
 			 * each net, if its's got space in cwnd and
 			 * has data sent to it (when CMT is off) then it
 			 * calls sctp_fill_outqueue for the net. This gets
 			 * data on the send queue for that network.
 			 *
 			 * In sctp_fill_outqueue TSN's are assigned and
 			 * data is copied out of the stream buffers. Note
 			 * mostly copy by reference (we hope).
 			 */
 			net->window_probe = 0;
 			if ((net != stcb->asoc.alternate) &&
 			    ((net->dest_state & SCTP_ADDR_PF) ||
 			     (!(net->dest_state & SCTP_ADDR_REACHABLE)) ||
 			     (net->dest_state & SCTP_ADDR_UNCONFIRMED))) {
 				if (SCTP_BASE_SYSCTL(sctp_logging_level) & SCTP_CWND_LOGGING_ENABLE) {
 					sctp_log_cwnd(stcb, net, 1,
 						      SCTP_CWND_LOG_FILL_OUTQ_CALLED);
 				}
 				continue;
 			}
 			if ((stcb->asoc.cc_functions.sctp_cwnd_new_transmission_begins) &&
 			    (net->flight_size == 0)) {
 				(*stcb->asoc.cc_functions.sctp_cwnd_new_transmission_begins)(stcb, net);
 			}
 			if (net->flight_size >= net->cwnd) {
 				/* skip this network, no room - can't fill */
 				if (SCTP_BASE_SYSCTL(sctp_logging_level) & SCTP_CWND_LOGGING_ENABLE) {
 					sctp_log_cwnd(stcb, net, 3,
 						      SCTP_CWND_LOG_FILL_OUTQ_CALLED);
 				}
 				continue;
 			}
 			if (SCTP_BASE_SYSCTL(sctp_logging_level) & SCTP_CWND_LOGGING_ENABLE) {
 				sctp_log_cwnd(stcb, net, 4, SCTP_CWND_LOG_FILL_OUTQ_CALLED);
 			}
 			sctp_fill_outqueue(stcb, net, frag_point, eeor_mode, &quit_now, so_locked);
 			if (quit_now) {
 				/* memory alloc failure */
 				no_data_chunks = 1;
 				break;
 			}
 		}
 	}
 	/* now service each destination and send out what we can for it */
 	/* Nothing to send? */
 	if (TAILQ_EMPTY(&asoc->control_send_queue) &&
 	    TAILQ_EMPTY(&asoc->asconf_send_queue) &&
 	    TAILQ_EMPTY(&asoc->send_queue)) {
 		*reason_code = 8;
 		return (0);
 	}
 
 	if (asoc->sctp_cmt_on_off > 0) {
 		/* get the last start point */
 		start_at = asoc->last_net_cmt_send_started;
 		if (start_at == NULL) {
 			/* null so to beginning */
 			start_at = TAILQ_FIRST(&asoc->nets);
 		} else {
 			start_at = TAILQ_NEXT(asoc->last_net_cmt_send_started, sctp_next);
 			if (start_at == NULL) {
 				start_at = TAILQ_FIRST(&asoc->nets);
 			}
 		}
 		asoc->last_net_cmt_send_started = start_at;
 	} else {
 		start_at = TAILQ_FIRST(&asoc->nets);
 	}
 	TAILQ_FOREACH(chk, &asoc->control_send_queue, sctp_next) {
 		if (chk->whoTo == NULL) {
 			if (asoc->alternate) {
 				chk->whoTo = asoc->alternate;
 			} else {
 				chk->whoTo = asoc->primary_destination;
 			}
 			atomic_add_int(&chk->whoTo->ref_count, 1);
 		}
 	}
 	old_start_at = NULL;
 again_one_more_time:
 	for (net = start_at ; net != NULL; net = TAILQ_NEXT(net, sctp_next)) {
 		/* how much can we send? */
 		/* SCTPDBG("Examine for sending net:%x\n", (uint32_t)net); */
 		if (old_start_at && (old_start_at == net)) {
 			/* through list ocmpletely. */
 			break;
 		}
 		tsns_sent = 0xa;
 		if (TAILQ_EMPTY(&asoc->control_send_queue) &&
 		    TAILQ_EMPTY(&asoc->asconf_send_queue) &&
 		    (net->flight_size >= net->cwnd)) {
 			/* Nothing on control or asconf and flight is full, we can skip
 			 * even in the CMT case.
 			 */
 			continue;
 		}
 		bundle_at = 0;
 		endoutchain = outchain = NULL;
+		auth = NULL;
+		auth_offset = 0;
 		no_fragmentflg = 1;
 		one_chunk = 0;
 		if (net->dest_state & SCTP_ADDR_UNCONFIRMED) {
 			skip_data_for_this_net = 1;
 		} else {
 			skip_data_for_this_net = 0;
 		}
 		switch (((struct sockaddr *)&net->ro._l_addr)->sa_family) {
 #ifdef INET
 		case AF_INET:
 			mtu = net->mtu - SCTP_MIN_V4_OVERHEAD;
 			break;
 #endif
 #ifdef INET6
 		case AF_INET6:
 			mtu = net->mtu - SCTP_MIN_OVERHEAD;
 			break;
 #endif
 #if defined(__Userspace__)
 		case AF_CONN:
 			mtu = net->mtu - sizeof(struct sctphdr);
 			break;
 #endif
 		default:
 			/* TSNH */
 			mtu = net->mtu;
 			break;
 		}
 		mx_mtu = mtu;
 		to_out = 0;
 		if (mtu > asoc->peers_rwnd) {
 			if (asoc->total_flight > 0) {
 				/* We have a packet in flight somewhere */
 				r_mtu = asoc->peers_rwnd;
 			} else {
 				/* We are always allowed to send one MTU out */
 				one_chunk = 1;
 				r_mtu = mtu;
 			}
 		} else {
 			r_mtu = mtu;
 		}
 		error = 0;
 		/************************/
 		/* ASCONF transmission */
 		/************************/
 		/* Now first lets go through the asconf queue */
 		TAILQ_FOREACH_SAFE(chk, &asoc->asconf_send_queue, sctp_next, nchk) {
 			if (chk->rec.chunk_id.id != SCTP_ASCONF) {
 				continue;
 			}
 			if (chk->whoTo == NULL) {
 				if (asoc->alternate == NULL) {
 					if (asoc->primary_destination != net) {
 						break;
 					}
 				} else {
 					if (asoc->alternate != net) {
 						break;
 					}
 				}
 			} else {
 				if (chk->whoTo != net) {
 					break;
 				}
 			}
 			if (chk->data == NULL) {
 				break;
 			}
 			if (chk->sent != SCTP_DATAGRAM_UNSENT &&
 			    chk->sent != SCTP_DATAGRAM_RESEND) {
 				break;
 			}
 			/*
 			 * if no AUTH is yet included and this chunk
 			 * requires it, make sure to account for it.  We
 			 * don't apply the size until the AUTH chunk is
 			 * actually added below in case there is no room for
 			 * this chunk. NOTE: we overload the use of "omtu"
 			 * here
 			 */
 			if ((auth == NULL) &&
 			    sctp_auth_is_required_chunk(chk->rec.chunk_id.id,
 							stcb->asoc.peer_auth_chunks)) {
 				omtu = sctp_get_auth_chunk_len(stcb->asoc.peer_hmac_id);
 			} else
 				omtu = 0;
 			/* Here we do NOT factor the r_mtu */
 			if ((chk->send_size < (int)(mtu - omtu)) ||
 			    (chk->flags & CHUNK_FLAGS_FRAGMENT_OK)) {
 				/*
 				 * We probably should glom the mbuf chain
 				 * from the chk->data for control but the
 				 * problem is it becomes yet one more level
 				 * of tracking to do if for some reason
 				 * output fails. Then I have got to
 				 * reconstruct the merged control chain.. el
 				 * yucko.. for now we take the easy way and
 				 * do the copy
 				 */
 				/*
 				 * Add an AUTH chunk, if chunk requires it
 				 * save the offset into the chain for AUTH
 				 */
 				if ((auth == NULL) &&
 				    (sctp_auth_is_required_chunk(chk->rec.chunk_id.id,
 								 stcb->asoc.peer_auth_chunks))) {
 					outchain = sctp_add_auth_chunk(outchain,
 								       &endoutchain,
 								       &auth,
 								       &auth_offset,
 								       stcb,
 								       chk->rec.chunk_id.id);
 					SCTP_STAT_INCR_COUNTER64(sctps_outcontrolchunks);
 				}
 				outchain = sctp_copy_mbufchain(chk->data, outchain, &endoutchain,
 							       (int)chk->rec.chunk_id.can_take_data,
 							       chk->send_size, chk->copy_by_ref);
 				if (outchain == NULL) {
 					*reason_code = 8;
 					SCTP_LTRACE_ERR_RET(inp, stcb, NULL, SCTP_FROM_SCTP_OUTPUT, ENOMEM);
 					return (ENOMEM);
 				}
 				SCTP_STAT_INCR_COUNTER64(sctps_outcontrolchunks);
 				/* update our MTU size */
 				if (mtu > (chk->send_size + omtu))
 					mtu -= (chk->send_size + omtu);
 				else
 					mtu = 0;
 				to_out += (chk->send_size + omtu);
 				/* Do clear IP_DF ? */
 				if (chk->flags & CHUNK_FLAGS_FRAGMENT_OK) {
 					no_fragmentflg = 0;
 				}
 				if (chk->rec.chunk_id.can_take_data)
 					chk->data = NULL;
 				/*
 				 * set hb flag since we can
 				 * use these for RTO
 				 */
 				hbflag = 1;
 				asconf = 1;
 				/*
 				 * should sysctl this: don't
 				 * bundle data with ASCONF
 				 * since it requires AUTH
 				 */
 				no_data_chunks = 1;
 				chk->sent = SCTP_DATAGRAM_SENT;
 				if (chk->whoTo == NULL) {
 					chk->whoTo = net;
 					atomic_add_int(&net->ref_count, 1);
 				}
 				chk->snd_count++;
 				if (mtu == 0) {
 					/*
 					 * Ok we are out of room but we can
 					 * output without effecting the
 					 * flight size since this little guy
 					 * is a control only packet.
 					 */
 					sctp_timer_start(SCTP_TIMER_TYPE_ASCONF, inp, stcb, net);
 					/*
 					 * do NOT clear the asconf
 					 * flag as it is used to do
 					 * appropriate source address
 					 * selection.
 					 */
 					if (*now_filled == 0) {
 						(void)SCTP_GETTIME_TIMEVAL(now);
 						*now_filled = 1;
 					}
 					net->last_sent_time = *now;
 					hbflag = 0;
 					if ((error = sctp_lowlevel_chunk_output(inp, stcb, net,
 					                                        (struct sockaddr *)&net->ro._l_addr,
 					                                        outchain, auth_offset, auth,
 					                                        stcb->asoc.authinfo.active_keyid,
 					                                        no_fragmentflg, 0, asconf,
 					                                        inp->sctp_lport, stcb->rport,
 					                                        htonl(stcb->asoc.peer_vtag),
 					                                        net->port, NULL,
 #if defined(__FreeBSD__)
 					                                        0, 0,
 #endif
 					                                        so_locked))) {
 						/* error, we could not output */
 						SCTPDBG(SCTP_DEBUG_OUTPUT3, "Gak send error %d\n", error);
 						if (from_where == 0) {
 							SCTP_STAT_INCR(sctps_lowlevelerrusr);
 						}
 						if (error == ENOBUFS) {
 							asoc->ifp_had_enobuf = 1;
 							SCTP_STAT_INCR(sctps_lowlevelerr);
 						}
 						/* error, could not output */
 						if (error == EHOSTUNREACH) {
 							/*
 							 * Destination went
 							 * unreachable
 							 * during this send
 							 */
 							sctp_move_chunks_from_net(stcb, net);
 						}
 						*reason_code = 7;
 						break;
 					} else {
 						asoc->ifp_had_enobuf = 0;
 					}
 					/*
 					 * increase the number we sent, if a
 					 * cookie is sent we don't tell them
 					 * any was sent out.
 					 */
 					outchain = endoutchain = NULL;
 					auth = NULL;
 					auth_offset = 0;
 					if (!no_out_cnt)
 						*num_out += ctl_cnt;
 					/* recalc a clean slate and setup */
 					switch (net->ro._l_addr.sa.sa_family) {
 #ifdef INET
 						case AF_INET:
 							mtu = net->mtu - SCTP_MIN_V4_OVERHEAD;
 							break;
 #endif
 #ifdef INET6
 						case AF_INET6:
 							mtu = net->mtu - SCTP_MIN_OVERHEAD;
 							break;
 #endif
 #if defined(__Userspace__)
 						case AF_CONN:
 							mtu = net->mtu - sizeof(struct sctphdr);
 							break;
 #endif
 						default:
 							/* TSNH */
 							mtu = net->mtu;
 							break;
 					}
 					to_out = 0;
 					no_fragmentflg = 1;
 				}
 			}
 		}
 		if (error != 0) {
 			/* try next net */
 			continue;
 		}
 		/************************/
 		/* Control transmission */
 		/************************/
 		/* Now first lets go through the control queue */
 		TAILQ_FOREACH_SAFE(chk, &asoc->control_send_queue, sctp_next, nchk) {
 			if ((sack_goes_to) &&
 			    (chk->rec.chunk_id.id == SCTP_ECN_ECHO) &&
 			    (chk->whoTo != sack_goes_to)) {
 				/*
 				 * if we have a sack in queue, and we are looking at an
 				 * ecn echo that is NOT queued to where the sack is going..
 				 */
 				if (chk->whoTo == net) {
 					/* Don't transmit it to where its going (current net) */
 					continue;
 				} else if (sack_goes_to == net) {
 					/* But do transmit it to this address */
 					goto skip_net_check;
 				}
 			}
 			if (chk->whoTo == NULL) {
 				if (asoc->alternate == NULL) {
 					if (asoc->primary_destination != net) {
 						continue;
 					}
 				} else {
 					if (asoc->alternate != net) {
 						continue;
 					}
 				}
 			} else {
 				if (chk->whoTo != net) {
 					continue;
 				}
 			}
 		skip_net_check:
 			if (chk->data == NULL) {
 				continue;
 			}
 			if (chk->sent != SCTP_DATAGRAM_UNSENT) {
 				/*
 				 * It must be unsent. Cookies and ASCONF's
 				 * hang around but there timers will force
 				 * when marked for resend.
 				 */
 				continue;
 			}
 			/*
 			 * if no AUTH is yet included and this chunk
 			 * requires it, make sure to account for it.  We
 			 * don't apply the size until the AUTH chunk is
 			 * actually added below in case there is no room for
 			 * this chunk. NOTE: we overload the use of "omtu"
 			 * here
 			 */
 			if ((auth == NULL) &&
 			    sctp_auth_is_required_chunk(chk->rec.chunk_id.id,
 							stcb->asoc.peer_auth_chunks)) {
 				omtu = sctp_get_auth_chunk_len(stcb->asoc.peer_hmac_id);
 			} else
 				omtu = 0;
 			/* Here we do NOT factor the r_mtu */
 			if ((chk->send_size <= (int)(mtu - omtu)) ||
 			    (chk->flags & CHUNK_FLAGS_FRAGMENT_OK)) {
 				/*
 				 * We probably should glom the mbuf chain
 				 * from the chk->data for control but the
 				 * problem is it becomes yet one more level
 				 * of tracking to do if for some reason
 				 * output fails. Then I have got to
 				 * reconstruct the merged control chain.. el
 				 * yucko.. for now we take the easy way and
 				 * do the copy
 				 */
 				/*
 				 * Add an AUTH chunk, if chunk requires it
 				 * save the offset into the chain for AUTH
 				 */
 				if ((auth == NULL) &&
 				    (sctp_auth_is_required_chunk(chk->rec.chunk_id.id,
 								 stcb->asoc.peer_auth_chunks))) {
 					outchain = sctp_add_auth_chunk(outchain,
 								       &endoutchain,
 								       &auth,
 								       &auth_offset,
 								       stcb,
 								       chk->rec.chunk_id.id);
 					SCTP_STAT_INCR_COUNTER64(sctps_outcontrolchunks);
 				}
 				outchain = sctp_copy_mbufchain(chk->data, outchain, &endoutchain,
 							       (int)chk->rec.chunk_id.can_take_data,
 							       chk->send_size, chk->copy_by_ref);
 				if (outchain == NULL) {
 					*reason_code = 8;
 					SCTP_LTRACE_ERR_RET(inp, stcb, NULL, SCTP_FROM_SCTP_OUTPUT, ENOMEM);
 					return (ENOMEM);
 				}
 				SCTP_STAT_INCR_COUNTER64(sctps_outcontrolchunks);
 				/* update our MTU size */
 				if (mtu > (chk->send_size + omtu))
 					mtu -= (chk->send_size + omtu);
 				else
 					mtu = 0;
 				to_out += (chk->send_size + omtu);
 				/* Do clear IP_DF ? */
 				if (chk->flags & CHUNK_FLAGS_FRAGMENT_OK) {
 					no_fragmentflg = 0;
 				}
 				if (chk->rec.chunk_id.can_take_data)
 					chk->data = NULL;
 				/* Mark things to be removed, if needed */
 				if ((chk->rec.chunk_id.id == SCTP_SELECTIVE_ACK) ||
 				    (chk->rec.chunk_id.id == SCTP_NR_SELECTIVE_ACK) || /* EY */
 				    (chk->rec.chunk_id.id == SCTP_HEARTBEAT_REQUEST) ||
 				    (chk->rec.chunk_id.id == SCTP_HEARTBEAT_ACK) ||
 				    (chk->rec.chunk_id.id == SCTP_SHUTDOWN) ||
 				    (chk->rec.chunk_id.id == SCTP_SHUTDOWN_ACK) ||
 				    (chk->rec.chunk_id.id == SCTP_OPERATION_ERROR) ||
 				    (chk->rec.chunk_id.id == SCTP_COOKIE_ACK) ||
 				    (chk->rec.chunk_id.id == SCTP_ECN_CWR) ||
 				    (chk->rec.chunk_id.id == SCTP_PACKET_DROPPED) ||
 				    (chk->rec.chunk_id.id == SCTP_ASCONF_ACK)) {
 					if (chk->rec.chunk_id.id == SCTP_HEARTBEAT_REQUEST) {
 						hbflag = 1;
 					}
 					/* remove these chunks at the end */
 					if ((chk->rec.chunk_id.id == SCTP_SELECTIVE_ACK) ||
 					    (chk->rec.chunk_id.id == SCTP_NR_SELECTIVE_ACK)) {
 						/* turn off the timer */
 						if (SCTP_OS_TIMER_PENDING(&stcb->asoc.dack_timer.timer)) {
 							sctp_timer_stop(SCTP_TIMER_TYPE_RECV,
 									inp, stcb, net,
 							                SCTP_FROM_SCTP_OUTPUT + SCTP_LOC_1);
 						}
 					}
 					ctl_cnt++;
 				} else {
 					/*
 					 * Other chunks, since they have
 					 * timers running (i.e. COOKIE)
 					 * we just "trust" that it
 					 * gets sent or retransmitted.
 					 */
 					ctl_cnt++;
 					if (chk->rec.chunk_id.id == SCTP_COOKIE_ECHO) {
 						cookie = 1;
 						no_out_cnt = 1;
 					} else if (chk->rec.chunk_id.id == SCTP_ECN_ECHO) {
 						/*
 						 * Increment ecne send count here
 						 * this means we may be over-zealous in
 						 * our counting if the send fails, but its
 						 * the best place to do it (we used to do
 						 * it in the queue of the chunk, but that did
 						 * not tell how many times it was sent.
 						 */
 						SCTP_STAT_INCR(sctps_sendecne);
 					}
 					chk->sent = SCTP_DATAGRAM_SENT;
 					if (chk->whoTo == NULL) {
 						chk->whoTo = net;
 						atomic_add_int(&net->ref_count, 1);
 					}
 					chk->snd_count++;
 				}
 				if (mtu == 0) {
 					/*
 					 * Ok we are out of room but we can
 					 * output without effecting the
 					 * flight size since this little guy
 					 * is a control only packet.
 					 */
 					if (asconf) {
 						sctp_timer_start(SCTP_TIMER_TYPE_ASCONF, inp, stcb, net);
 						/*
 						 * do NOT clear the asconf
 						 * flag as it is used to do
 						 * appropriate source address
 						 * selection.
 						 */
 					}
 					if (cookie) {
 						sctp_timer_start(SCTP_TIMER_TYPE_COOKIE, inp, stcb, net);
 						cookie = 0;
 					}
 					/* Only HB or ASCONF advances time */
 					if (hbflag) {
 						if (*now_filled == 0) {
 							(void)SCTP_GETTIME_TIMEVAL(now);
 							*now_filled = 1;
 						}
 						net->last_sent_time = *now;
 						hbflag = 0;
 					}
 					if ((error = sctp_lowlevel_chunk_output(inp, stcb, net,
 					                                        (struct sockaddr *)&net->ro._l_addr,
 					                                        outchain,
 					                                        auth_offset, auth,
 					                                        stcb->asoc.authinfo.active_keyid,
 					                                        no_fragmentflg, 0, asconf,
 					                                        inp->sctp_lport, stcb->rport,
 					                                        htonl(stcb->asoc.peer_vtag),
 					                                        net->port, NULL,
 #if defined(__FreeBSD__)
 					                                        0, 0,
 #endif
 					                                        so_locked))) {
 						/* error, we could not output */
 						SCTPDBG(SCTP_DEBUG_OUTPUT3, "Gak send error %d\n", error);
 						if (from_where == 0) {
 							SCTP_STAT_INCR(sctps_lowlevelerrusr);
 						}
 						if (error == ENOBUFS) {
 							asoc->ifp_had_enobuf = 1;
 							SCTP_STAT_INCR(sctps_lowlevelerr);
 						}
 						if (error == EHOSTUNREACH) {
 							/*
 							 * Destination went
 							 * unreachable
 							 * during this send
 							 */
 							sctp_move_chunks_from_net(stcb, net);
 						}
 						*reason_code = 7;
 						break;
 					} else {
 						asoc->ifp_had_enobuf = 0;
 					}
 					/*
 					 * increase the number we sent, if a
 					 * cookie is sent we don't tell them
 					 * any was sent out.
 					 */
 					outchain = endoutchain = NULL;
 					auth = NULL;
 					auth_offset = 0;
 					if (!no_out_cnt)
 						*num_out += ctl_cnt;
 					/* recalc a clean slate and setup */
 					switch (net->ro._l_addr.sa.sa_family) {
 #ifdef INET
 						case AF_INET:
 							mtu = net->mtu - SCTP_MIN_V4_OVERHEAD;
 							break;
 #endif
 #ifdef INET6
 						case AF_INET6:
 							mtu = net->mtu - SCTP_MIN_OVERHEAD;
 							break;
 #endif
 #if defined(__Userspace__)
 						case AF_CONN:
 							mtu = net->mtu - sizeof(struct sctphdr);
 							break;
 #endif
 						default:
 							/* TSNH */
 							mtu = net->mtu;
 							break;
 					}
 					to_out = 0;
 					no_fragmentflg = 1;
 				}
 			}
 		}
 		if (error != 0) {
 			/* try next net */
 			continue;
 		}
 		/* JRI: if dest is in PF state, do not send data to it */
 		if ((asoc->sctp_cmt_on_off > 0) &&
 		    (net != stcb->asoc.alternate) &&
 		    (net->dest_state & SCTP_ADDR_PF)) {
 			goto no_data_fill;
 		}
 		if (net->flight_size >= net->cwnd) {
 			goto no_data_fill;
 		}
 		if ((asoc->sctp_cmt_on_off > 0) &&
 		    (SCTP_BASE_SYSCTL(sctp_buffer_splitting) & SCTP_RECV_BUFFER_SPLITTING) &&
 		    (net->flight_size > max_rwnd_per_dest)) {
 			goto no_data_fill;
 		}
 		/*
 		 * We need a specific accounting for the usage of the
 		 * send buffer. We also need to check the number of messages
 		 * per net. For now, this is better than nothing and it
 		 * disabled by default...
 		 */
 		if ((asoc->sctp_cmt_on_off > 0) &&
 		    (SCTP_BASE_SYSCTL(sctp_buffer_splitting) & SCTP_SEND_BUFFER_SPLITTING) &&
 		    (max_send_per_dest > 0) &&
 		    (net->flight_size > max_send_per_dest)) {
 			goto no_data_fill;
 		}
 		/*********************/
 		/* Data transmission */
 		/*********************/
 		/*
 		 * if AUTH for DATA is required and no AUTH has been added
 		 * yet, account for this in the mtu now... if no data can be
 		 * bundled, this adjustment won't matter anyways since the
 		 * packet will be going out...
 		 */
 		data_auth_reqd = sctp_auth_is_required_chunk(SCTP_DATA,
 							     stcb->asoc.peer_auth_chunks);
 		if (data_auth_reqd && (auth == NULL)) {
 			mtu -= sctp_get_auth_chunk_len(stcb->asoc.peer_hmac_id);
 		}
 		/* now lets add any data within the MTU constraints */
 		switch (((struct sockaddr *)&net->ro._l_addr)->sa_family) {
 #ifdef INET
 		case AF_INET:
 			if (net->mtu > SCTP_MIN_V4_OVERHEAD)
 				omtu = net->mtu - SCTP_MIN_V4_OVERHEAD;
 			else
 				omtu = 0;
 			break;
 #endif
 #ifdef INET6
 		case AF_INET6:
 			if (net->mtu > SCTP_MIN_OVERHEAD)
 				omtu = net->mtu - SCTP_MIN_OVERHEAD;
 			else
 				omtu = 0;
 			break;
 #endif
 #if defined(__Userspace__)
 		case AF_CONN:
 			if (net->mtu > sizeof(struct sctphdr)) {
 				omtu = net->mtu - sizeof(struct sctphdr);
 			} else {
 				omtu = 0;
 			}
 			break;
 #endif
 		default:
 			/* TSNH */
 			omtu = 0;
 			break;
 		}
 		if ((((SCTP_GET_STATE(stcb) == SCTP_STATE_OPEN) ||
 		      (SCTP_GET_STATE(stcb) == SCTP_STATE_SHUTDOWN_RECEIVED)) &&
 		     (skip_data_for_this_net == 0)) ||
 		    (cookie)) {
 			TAILQ_FOREACH_SAFE(chk, &asoc->send_queue, sctp_next, nchk) {
 				if (no_data_chunks) {
 					/* let only control go out */
 					*reason_code = 1;
 					break;
 				}
 				if (net->flight_size >= net->cwnd) {
 					/* skip this net, no room for data */
 					*reason_code = 2;
 					break;
 				}
 				if ((chk->whoTo != NULL) &&
 				    (chk->whoTo != net)) {
 					/* Don't send the chunk on this net */
 					continue;
 				}
 
 				if (asoc->sctp_cmt_on_off == 0) {
 					if ((asoc->alternate) &&
 					    (asoc->alternate != net) &&
 					    (chk->whoTo == NULL)) {
 						continue;
 					} else if ((net != asoc->primary_destination) &&
 						   (asoc->alternate == NULL) &&
 						   (chk->whoTo == NULL)) {
 						continue;
 					}
 				}
 				if ((chk->send_size > omtu) && ((chk->flags & CHUNK_FLAGS_FRAGMENT_OK) == 0)) {
 					/*-
 					 * strange, we have a chunk that is
 					 * to big for its destination and
 					 * yet no fragment ok flag.
 					 * Something went wrong when the
 					 * PMTU changed...we did not mark
 					 * this chunk for some reason?? I
 					 * will fix it here by letting IP
 					 * fragment it for now and printing
 					 * a warning. This really should not
 					 * happen ...
 					 */
 					SCTP_PRINTF("Warning chunk of %d bytes > mtu:%d and yet PMTU disc missed\n",
 						    chk->send_size, mtu);
 					chk->flags |= CHUNK_FLAGS_FRAGMENT_OK;
 				}
 				if (SCTP_BASE_SYSCTL(sctp_enable_sack_immediately) &&
 				    (asoc->state & SCTP_STATE_SHUTDOWN_PENDING)) {
 					struct sctp_data_chunk *dchkh;
 
 					dchkh = mtod(chk->data, struct sctp_data_chunk *);
 					dchkh->ch.chunk_flags |= SCTP_DATA_SACK_IMMEDIATELY;
 				}
 				if (((chk->send_size <= mtu) && (chk->send_size <= r_mtu)) ||
 				    ((chk->flags & CHUNK_FLAGS_FRAGMENT_OK) && (chk->send_size <= asoc->peers_rwnd))) {
 					/* ok we will add this one */
 
 					/*
 					 * Add an AUTH chunk, if chunk
 					 * requires it, save the offset into
 					 * the chain for AUTH
 					 */
 					if (data_auth_reqd) {
 						if (auth == NULL) {
 							outchain = sctp_add_auth_chunk(outchain,
 										       &endoutchain,
 										       &auth,
 										       &auth_offset,
 										       stcb,
 										       SCTP_DATA);
 							auth_keyid = chk->auth_keyid;
 							override_ok = 0;
 							SCTP_STAT_INCR_COUNTER64(sctps_outcontrolchunks);
 						} else if (override_ok) {
 							/* use this data's keyid */
 							auth_keyid = chk->auth_keyid;
 							override_ok = 0;
 						} else if (auth_keyid != chk->auth_keyid) {
 							/* different keyid, so done bundling */
 							break;
 						}
 					}
 					outchain = sctp_copy_mbufchain(chk->data, outchain, &endoutchain, 0,
 								       chk->send_size, chk->copy_by_ref);
 					if (outchain == NULL) {
 						SCTPDBG(SCTP_DEBUG_OUTPUT3, "No memory?\n");
 						if (!SCTP_OS_TIMER_PENDING(&net->rxt_timer.timer)) {
 							sctp_timer_start(SCTP_TIMER_TYPE_SEND, inp, stcb, net);
 						}
 						*reason_code = 3;
 						SCTP_LTRACE_ERR_RET(inp, stcb, NULL, SCTP_FROM_SCTP_OUTPUT, ENOMEM);
 						return (ENOMEM);
 					}
 					/* upate our MTU size */
 					/* Do clear IP_DF ? */
 					if (chk->flags & CHUNK_FLAGS_FRAGMENT_OK) {
 						no_fragmentflg = 0;
 					}
 					/* unsigned subtraction of mtu */
 					if (mtu > chk->send_size)
 						mtu -= chk->send_size;
 					else
 						mtu = 0;
 					/* unsigned subtraction of r_mtu */
 					if (r_mtu > chk->send_size)
 						r_mtu -= chk->send_size;
 					else
 						r_mtu = 0;
 
 					to_out += chk->send_size;
 					if ((to_out > mx_mtu) && no_fragmentflg) {
 #ifdef INVARIANTS
 						panic("Exceeding mtu of %d out size is %d", mx_mtu, to_out);
 #else
 						SCTP_PRINTF("Exceeding mtu of %d out size is %d\n",
 							    mx_mtu, to_out);
 #endif
 					}
 					chk->window_probe = 0;
 					data_list[bundle_at++] = chk;
 					if (bundle_at >= SCTP_MAX_DATA_BUNDLING) {
 						break;
 					}
 					if (chk->sent == SCTP_DATAGRAM_UNSENT) {
 						if ((chk->rec.data.rcv_flags & SCTP_DATA_UNORDERED) == 0) {
 							SCTP_STAT_INCR_COUNTER64(sctps_outorderchunks);
 						} else {
 							SCTP_STAT_INCR_COUNTER64(sctps_outunorderchunks);
 						}
 						if (((chk->rec.data.rcv_flags & SCTP_DATA_LAST_FRAG) == SCTP_DATA_LAST_FRAG) &&
 						    ((chk->rec.data.rcv_flags & SCTP_DATA_FIRST_FRAG) == 0))
 							/* Count number of user msg's that were fragmented
 							 * we do this by counting when we see a LAST fragment
 							 * only.
 							 */
 							SCTP_STAT_INCR_COUNTER64(sctps_fragusrmsgs);
 					}
 					if ((mtu == 0) || (r_mtu == 0) || (one_chunk)) {
 						if ((one_chunk) && (stcb->asoc.total_flight == 0)) {
 							data_list[0]->window_probe = 1;
 							net->window_probe = 1;
 						}
 						break;
 					}
 				} else {
 					/*
 					 * Must be sent in order of the
 					 * TSN's (on a network)
 					 */
 					break;
 				}
 			}	/* for (chunk gather loop for this net) */
 		}		/* if asoc.state OPEN */
 	no_data_fill:
 		/* Is there something to send for this destination? */
 		if (outchain) {
 			/* We may need to start a control timer or two */
 			if (asconf) {
 				sctp_timer_start(SCTP_TIMER_TYPE_ASCONF, inp,
 						 stcb, net);
 				/*
 				 * do NOT clear the asconf flag as it is used
 				 * to do appropriate source address selection.
 				 */
 			}
 			if (cookie) {
 				sctp_timer_start(SCTP_TIMER_TYPE_COOKIE, inp, stcb, net);
 				cookie = 0;
 			}
 			/* must start a send timer if data is being sent */
 			if (bundle_at && (!SCTP_OS_TIMER_PENDING(&net->rxt_timer.timer))) {
 				/*
 				 * no timer running on this destination
 				 * restart it.
 				 */
 				sctp_timer_start(SCTP_TIMER_TYPE_SEND, inp, stcb, net);
 			}
 			if (bundle_at || hbflag) {
 				/* For data/asconf and hb set time */
 				if (*now_filled == 0) {
 					(void)SCTP_GETTIME_TIMEVAL(now);
 					*now_filled = 1;
 				}
 				net->last_sent_time = *now;
 			}
 			/* Now send it, if there is anything to send :> */
 			if ((error = sctp_lowlevel_chunk_output(inp,
 			                                        stcb,
 			                                        net,
 			                                        (struct sockaddr *)&net->ro._l_addr,
 			                                        outchain,
 			                                        auth_offset,
 			                                        auth,
 			                                        auth_keyid,
 			                                        no_fragmentflg,
 			                                        bundle_at,
 			                                        asconf,
 			                                        inp->sctp_lport, stcb->rport,
 			                                        htonl(stcb->asoc.peer_vtag),
 			                                        net->port, NULL,
 #if defined(__FreeBSD__)
 			                                        0, 0,
 #endif
 			                                        so_locked))) {
 				/* error, we could not output */
 				SCTPDBG(SCTP_DEBUG_OUTPUT3, "Gak send error %d\n", error);
 				if (from_where == 0) {
 					SCTP_STAT_INCR(sctps_lowlevelerrusr);
 				}
 				if (error == ENOBUFS) {
 					asoc->ifp_had_enobuf = 1;
 					SCTP_STAT_INCR(sctps_lowlevelerr);
 				}
 				if (error == EHOSTUNREACH) {
 					/*
 					 * Destination went unreachable
 					 * during this send
 					 */
 					sctp_move_chunks_from_net(stcb, net);
 				}
 				*reason_code = 6;
 				/*-
 				 * I add this line to be paranoid. As far as
 				 * I can tell the continue, takes us back to
 				 * the top of the for, but just to make sure
 				 * I will reset these again here.
 				 */
 				ctl_cnt = bundle_at = 0;
 				continue; /* This takes us back to the for() for the nets. */
 			} else {
 				asoc->ifp_had_enobuf = 0;
 			}
 			endoutchain = NULL;
 			auth = NULL;
 			auth_offset = 0;
 			if (!no_out_cnt) {
 				*num_out += (ctl_cnt + bundle_at);
 			}
 			if (bundle_at) {
 				/* setup for a RTO measurement */
 				tsns_sent = data_list[0]->rec.data.tsn;
 				/* fill time if not already filled */
 				if (*now_filled == 0) {
 					(void)SCTP_GETTIME_TIMEVAL(&asoc->time_last_sent);
 					*now_filled = 1;
 					*now = asoc->time_last_sent;
 				} else {
 					asoc->time_last_sent = *now;
 				}
 				if (net->rto_needed) {
 					data_list[0]->do_rtt = 1;
 					net->rto_needed = 0;
 				}
 				SCTP_STAT_INCR_BY(sctps_senddata, bundle_at);
 				sctp_clean_up_datalist(stcb, asoc, data_list, bundle_at, net);
 			}
 			if (one_chunk) {
 				break;
 			}
 		}
 		if (SCTP_BASE_SYSCTL(sctp_logging_level) & SCTP_CWND_LOGGING_ENABLE) {
 			sctp_log_cwnd(stcb, net, tsns_sent, SCTP_CWND_LOG_FROM_SEND);
 		}
 	}
 	if (old_start_at == NULL) {
 		old_start_at = start_at;
 		start_at = TAILQ_FIRST(&asoc->nets);
 		if (old_start_at)
 			goto again_one_more_time;
 	}
 
 	/*
 	 * At the end there should be no NON timed chunks hanging on this
 	 * queue.
 	 */
 	if (SCTP_BASE_SYSCTL(sctp_logging_level) & SCTP_CWND_LOGGING_ENABLE) {
 		sctp_log_cwnd(stcb, net, *num_out, SCTP_CWND_LOG_FROM_SEND);
 	}
 	if ((*num_out == 0) && (*reason_code == 0)) {
 		*reason_code = 4;
 	} else {
 		*reason_code = 5;
 	}
 	sctp_clean_up_ctl(stcb, asoc, so_locked);
 	return (0);
 }
