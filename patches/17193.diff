commit 901efc4bd45bffa7fae58a06a90949b070ed7303
Author: Chen Huitao <h980501427@163.com>
Date:   Mon Feb 10 22:33:01 2020 +0800

    fix some oss-fuzz (#1200)
    
    * fix oss-fuzz 10419.
    
    * fix oss-fuzz 10427.
    
    * fix oss-fuzz 10421.
    
    * fix oss-fuzz 10422.
    
    * fix oss-fuzz 10425.
    
    * fix oss-fuzz 10426.
    
    * fix oss-fuzz 10426.
    
    * fix oss-fuzz 10422.
    
    * fix oss-fuzz  10426.
    
    * fix oss-fuzz 10456.
    
    * fix oss-fuzz 10428.
    
    * fix oss-fuzz 10429.
    
    * fix oss-fuzz 10431.
    
    * fix oss-fuzz 10435.
    
    * fix oss-fuzz 10430.
    
    * fix oss-fuzz 10436.
    
    * remove unused var.
    
    * fix oss-fuzz 10449.
    
    * fix oss-fuzz 10452.
    
    * fix oss-fuzz 11792.
    
    * fix oss-fuzz 10457.
    
    * fix oss-fuzz 11737.
    
    * fix oss-fuzz 10458.
    
    * fix oss-fuzz 10565.
    
    * fix oss-fuzz 11651.
    
    * fix oss-fuzz 10497.
    
    * fix oss-fuzz 10515.
    
    * fix oss-fuzz 10586.
    
    * fix oss-fuzz 10597.
    
    * fiz oss-fuzz 11721.
    
    * fix oss-fuzz 10718.
    
    * fix oss-fuzz 15610.
    
    * fix oss-fuzz 10512.
    
    * fix oss-fuzz 10545.
    
    * fix oss-fuzz 10598.
    
    * fix oss-fuzz 11112.
    
    * fix oss-fuzz 11589.
    
    * fix oss-fuzz 10674.
    
    * git fix oss-fuzz 19610.
    
    * fix oss-fuzz 19848.
    
    * fix oss-fuzz 19851.
    
    * fix oss-fuzz 19852.
    
    * fix oss-fuzz 10878.
    
    * fix oss-fuzz 11655.
    
    * fix oss-fuzz 19849.
    
    * fix oss-fuzz 11765.
    
    * fix oss-fuzz 10337.
    
    * fix oss-fuzz 10575.
    
    * fix oss-fuzz 19877.
    
    * fix oss-fuzz 19895.
    
    * fix oss-fuzz 19896.
    
    * fix oss-fuzz 19897.
    
    * remove verbose fprintf output.
    
    * fix oss-fuzz 19943.
    
    * fix oss-fuzz 20026.
    
    * fix oss-fuzz 20027.
    
    * fix oss-fuzz 19967.
    
    * fix oss-fuzz 19946.
    
    * fix oss-fuzz 20069.
    
    * fix oss-fuzz 20071.
    
    * fix oss-fuzz 20073.
    
    * fix oss-fuzz 20075.
    
    * fix oss-fuzz 20076.
    
    * fix a operation mistake.
    
    * fix oss-fuzz 20101.
    
    * fix oss-fuzz 20152.
    
    * fix oss-fuzz 20101.
    
    * fix oss-fuzz 20154.
    
    * fix oss-fuzz 20166.
    
    * fix oss-fuzz 14042.
    
    * fix oss-fuzz 10578.
    
    * fix oss-fuzz 11328.
    
    * fix oss-fuzz 10602.

diff --git a/qemu/cputlb.c b/qemu/cputlb.c
index 87f14f75..fd0bb806 100644
--- a/qemu/cputlb.c
+++ b/qemu/cputlb.c
@@ -283,46 +283,51 @@ void tlb_set_page(CPUState *cpu, target_ulong vaddr,
 /* NOTE: this function can trigger an exception */
 /* NOTE2: the returned address is not exactly the physical address: it
  * is actually a ram_addr_t (in system mode; the user mode emulation
  * version of this function returns a guest virtual address).
  */
 tb_page_addr_t get_page_addr_code(CPUArchState *env1, target_ulong addr)
 {
     int mmu_idx, page_index, pd;
     void *p;
     MemoryRegion *mr;
     ram_addr_t  ram_addr;
     CPUState *cpu = ENV_GET_CPU(env1);
 
     page_index = (addr >> TARGET_PAGE_BITS) & (CPU_TLB_SIZE - 1);
     mmu_idx = cpu_mmu_index(env1);
+
+    if ((mmu_idx < 0) || (mmu_idx >= NB_MMU_MODES)) {
+        return -1;
+    }
+
     if (unlikely(env1->tlb_table[mmu_idx][page_index].addr_code !=
                  (addr & TARGET_PAGE_MASK))) {
         cpu_ldub_code(env1, addr);
         //check for NX related error from softmmu
         if (env1->invalid_error == UC_ERR_FETCH_PROT) {
             return -1;
         }
     }
     pd = env1->iotlb[mmu_idx][page_index] & ~TARGET_PAGE_MASK;
     mr = iotlb_to_region(cpu->as, pd);
     if (memory_region_is_unassigned(cpu->uc, mr)) {
         CPUClass *cc = CPU_GET_CLASS(env1->uc, cpu);
 
         if (cc->do_unassigned_access) {
             cc->do_unassigned_access(cpu, addr, false, true, 0, 4);
         } else {
             //cpu_abort(cpu, "Trying to execute code outside RAM or ROM at 0x"
             //          TARGET_FMT_lx "\n", addr);    // qq
             env1->invalid_addr = addr;
             env1->invalid_error = UC_ERR_FETCH_UNMAPPED;
             return -1;
         }
     }
     p = (void *)((uintptr_t)addr + env1->tlb_table[mmu_idx][page_index].addend);
     if (!qemu_ram_addr_from_host_nofail(cpu->uc, p, &ram_addr)) {
         env1->invalid_addr = addr;
         env1->invalid_error = UC_ERR_FETCH_UNMAPPED;
         return -1;
     } else
         return ram_addr;
 }
diff --git a/qemu/target-i386/ops_sse.h b/qemu/target-i386/ops_sse.h
index e5fa7c7f..f142f335 100644
--- a/qemu/target-i386/ops_sse.h
+++ b/qemu/target-i386/ops_sse.h
@@ -1941,24 +1941,27 @@ SSE_HELPER_Q(helper_pcmpgtq, FCMPGTQ)
 
 static inline int pcmp_elen(CPUX86State *env, int reg, uint32_t ctrl)
 {
-    int val;
+    unsigned int val;
 
     /* Presence of REX.W is indicated by a bit higher than 7 set */
     if (ctrl >> 8) {
         val = abs1((int)env->regs[reg]);
     } else {
         val = abs1((int32_t)env->regs[reg]);
     }
 
     if (ctrl & 1) {
         if (val > 8) {
             return 8;
         }
     } else {
         if (val > 16) {
             return 16;
         }
     }
+    if (val == 0x80000000) {
+        val = 0;
+    }
     return val;
 }
 
diff --git a/qemu/tcg/optimize.c b/qemu/tcg/optimize.c
index d525f15b..fcf7a90a 100644
--- a/qemu/tcg/optimize.c
+++ b/qemu/tcg/optimize.c
@@ -535,857 +535,860 @@ static bool swap_commutative2(TCGContext *s, TCGArg *p1, TCGArg *p2)
 /* Propagate constants and copies, fold constant expressions. */
 static TCGArg *tcg_constant_folding(TCGContext *s, uint16_t *tcg_opc_ptr,
                                     TCGArg *args, TCGOpDef *tcg_op_defs)
 {
     struct tcg_temp_info *temps = s->temps2;
     int nb_ops, op_index, nb_temps, nb_globals;
     TCGArg *gen_args;
 
     /* Array VALS has an element for each temp.
        If this temp holds a constant then its value is kept in VALS' element.
        If this temp is a copy of other ones then the other copies are
        available through the doubly linked circular list. */
 
     nb_temps = s->nb_temps;
     nb_globals = s->nb_globals;
     reset_all_temps(s, nb_temps);
 
     nb_ops = tcg_opc_ptr - s->gen_opc_buf;
     gen_args = args;
     for (op_index = 0; op_index < nb_ops; op_index++) {
         TCGOpcode op = s->gen_opc_buf[op_index];
         const TCGOpDef *def = &tcg_op_defs[op];
         tcg_target_ulong mask, partmask, affected;
         int nb_oargs, nb_iargs, nb_args, i;
         TCGArg tmp;
 
         if (op == INDEX_op_call) {
             *gen_args++ = tmp = *args++;
             nb_oargs = tmp >> 16;
             nb_iargs = tmp & 0xffff;
             nb_args = nb_oargs + nb_iargs + def->nb_cargs;
         } else {
             nb_oargs = def->nb_oargs;
             nb_iargs = def->nb_iargs;
             nb_args = def->nb_args;
         }
 
         /* Do copy propagation */
         for (i = nb_oargs; i < nb_oargs + nb_iargs; i++) {
             if (temps[args[i]].state == TCG_TEMP_COPY) {
                 args[i] = find_better_copy(s, args[i]);
             }
         }
 
         /* For commutative operations make constant second argument */
         switch (op) {
         CASE_OP_32_64(add):
         CASE_OP_32_64(mul):
         CASE_OP_32_64(and):
         CASE_OP_32_64(or):
         CASE_OP_32_64(xor):
         CASE_OP_32_64(eqv):
         CASE_OP_32_64(nand):
         CASE_OP_32_64(nor):
         CASE_OP_32_64(muluh):
         CASE_OP_32_64(mulsh):
             swap_commutative(s, args[0], &args[1], &args[2]);
             break;
         CASE_OP_32_64(brcond):
             if (swap_commutative(s, -1, &args[0], &args[1])) {
                 args[2] = tcg_swap_cond(args[2]);
             }
             break;
         CASE_OP_32_64(setcond):
             if (swap_commutative(s, args[0], &args[1], &args[2])) {
                 args[3] = tcg_swap_cond(args[3]);
             }
             break;
         CASE_OP_32_64(movcond):
             if (swap_commutative(s, -1, &args[1], &args[2])) {
                 args[5] = tcg_swap_cond(args[5]);
             }
             /* For movcond, we canonicalize the "false" input reg to match
                the destination reg so that the tcg backend can implement
                a "move if true" operation.  */
             if (swap_commutative(s, args[0], &args[4], &args[3])) {
                 args[5] = tcg_invert_cond(args[5]);
             }
             break;
         CASE_OP_32_64(add2):
             swap_commutative(s, args[0], &args[2], &args[4]);
             swap_commutative(s, args[1], &args[3], &args[5]);
             break;
         CASE_OP_32_64(mulu2):
         CASE_OP_32_64(muls2):
             swap_commutative(s, args[0], &args[2], &args[3]);
             break;
         case INDEX_op_brcond2_i32:
             if (swap_commutative2(s, &args[0], &args[2])) {
                 args[4] = tcg_swap_cond(args[4]);
             }
             break;
         case INDEX_op_setcond2_i32:
             if (swap_commutative2(s, &args[1], &args[3])) {
                 args[5] = tcg_swap_cond(args[5]);
             }
             break;
         default:
             break;
         }
 
         /* Simplify expressions for "shift/rot r, 0, a => movi r, 0",
            and "sub r, 0, a => neg r, a" case.  */
         switch (op) {
         CASE_OP_32_64(shl):
         CASE_OP_32_64(shr):
         CASE_OP_32_64(sar):
         CASE_OP_32_64(rotl):
         CASE_OP_32_64(rotr):
             if (temps[args[1]].state == TCG_TEMP_CONST
                 && temps[args[1]].val == 0) {
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], 0);
                 args += 3;
                 gen_args += 2;
                 continue;
             }
             break;
         CASE_OP_32_64(sub):
             {
                 TCGOpcode neg_op;
                 bool have_neg;
 
                 if (temps[args[2]].state == TCG_TEMP_CONST) {
                     /* Proceed with possible constant folding. */
                     break;
                 }
                 if (op == INDEX_op_sub_i32) {
                     neg_op = INDEX_op_neg_i32;
                     have_neg = TCG_TARGET_HAS_neg_i32;
                 } else {
                     neg_op = INDEX_op_neg_i64;
                     have_neg = TCG_TARGET_HAS_neg_i64;
                 }
                 if (!have_neg) {
                     break;
                 }
                 if (temps[args[1]].state == TCG_TEMP_CONST
                     && temps[args[1]].val == 0) {
                     s->gen_opc_buf[op_index] = neg_op;
                     reset_temp(s, args[0]);
                     gen_args[0] = args[0];
                     gen_args[1] = args[2];
                     args += 3;
                     gen_args += 2;
                     continue;
                 }
             }
             break;
         CASE_OP_32_64(xor):
         CASE_OP_32_64(nand):
             if (temps[args[1]].state != TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[2]].val == -1) {
                 i = 1;
                 goto try_not;
             }
             break;
         CASE_OP_32_64(nor):
             if (temps[args[1]].state != TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[2]].val == 0) {
                 i = 1;
                 goto try_not;
             }
             break;
         CASE_OP_32_64(andc):
             if (temps[args[2]].state != TCG_TEMP_CONST
                 && temps[args[1]].state == TCG_TEMP_CONST
                 && temps[args[1]].val == -1) {
                 i = 2;
                 goto try_not;
             }
             break;
         CASE_OP_32_64(orc):
         CASE_OP_32_64(eqv):
             if (temps[args[2]].state != TCG_TEMP_CONST
                 && temps[args[1]].state == TCG_TEMP_CONST
                 && temps[args[1]].val == 0) {
                 i = 2;
                 goto try_not;
             }
             break;
         try_not:
             {
                 TCGOpcode not_op;
                 bool have_not;
 
                 if (def->flags & TCG_OPF_64BIT) {
                     not_op = INDEX_op_not_i64;
                     have_not = TCG_TARGET_HAS_not_i64;
                 } else {
                     not_op = INDEX_op_not_i32;
                     have_not = TCG_TARGET_HAS_not_i32;
                 }
                 if (!have_not) {
                     break;
                 }
                 s->gen_opc_buf[op_index] = not_op;
                 reset_temp(s, args[0]);
                 gen_args[0] = args[0];
                 gen_args[1] = args[i];
                 args += 3;
                 gen_args += 2;
                 continue;
             }
         default:
             break;
         }
 
         /* Simplify expression for "op r, a, const => mov r, a" cases */
         switch (op) {
         CASE_OP_32_64(add):
         CASE_OP_32_64(sub):
         CASE_OP_32_64(shl):
         CASE_OP_32_64(shr):
         CASE_OP_32_64(sar):
         CASE_OP_32_64(rotl):
         CASE_OP_32_64(rotr):
         CASE_OP_32_64(or):
         CASE_OP_32_64(xor):
         CASE_OP_32_64(andc):
             if (temps[args[1]].state != TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[2]].val == 0) {
                 goto do_mov3;
             }
             break;
         CASE_OP_32_64(and):
         CASE_OP_32_64(orc):
         CASE_OP_32_64(eqv):
             if (temps[args[1]].state != TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[2]].val == -1) {
                 goto do_mov3;
             }
             break;
         do_mov3:
             if (temps_are_copies(s, args[0], args[1])) {
                 s->gen_opc_buf[op_index] = INDEX_op_nop;
             } else {
                 tcg_opt_gen_mov(s, op_index, gen_args, op, args[0], args[1]);
                 gen_args += 2;
             }
             args += 3;
             continue;
         default:
             break;
         }
 
         /* Simplify using known-zero bits. Currently only ops with a single
            output argument is supported. */
         mask = -1;
         affected = -1;
         switch (op) {
         CASE_OP_32_64(ext8s):
             if ((temps[args[1]].mask & 0x80) != 0) {
                 break;
             }
         CASE_OP_32_64(ext8u):
             mask = 0xff;
             goto and_const;
         CASE_OP_32_64(ext16s):
             if ((temps[args[1]].mask & 0x8000) != 0) {
                 break;
             }
         CASE_OP_32_64(ext16u):
             mask = 0xffff;
             goto and_const;
         case INDEX_op_ext32s_i64:
             if ((temps[args[1]].mask & 0x80000000) != 0) {
                 break;
             }
         case INDEX_op_ext32u_i64:
             mask = 0xffffffffU;
             goto and_const;
 
         CASE_OP_32_64(and):
             mask = temps[args[2]].mask;
             if (temps[args[2]].state == TCG_TEMP_CONST) {
         and_const:
                 affected = temps[args[1]].mask & ~mask;
             }
             mask = temps[args[1]].mask & mask;
             break;
 
         CASE_OP_32_64(andc):
             /* Known-zeros does not imply known-ones.  Therefore unless
                args[2] is constant, we can't infer anything from it.  */
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 mask = ~temps[args[2]].mask;
                 goto and_const;
             }
             /* But we certainly know nothing outside args[1] may be set. */
             mask = temps[args[1]].mask;
             break;
 
         case INDEX_op_sar_i32:
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = temps[args[2]].val & 31;
                 mask = (int32_t)temps[args[1]].mask >> tmp;
             }
             break;
         case INDEX_op_sar_i64:
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = temps[args[2]].val & 63;
                 mask = (int64_t)temps[args[1]].mask >> tmp;
             }
             break;
 
         case INDEX_op_shr_i32:
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = temps[args[2]].val & 31;
                 mask = (uint32_t)temps[args[1]].mask >> tmp;
             }
             break;
         case INDEX_op_shr_i64:
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = temps[args[2]].val & 63;
                 mask = (uint64_t)temps[args[1]].mask >> tmp;
             }
             break;
 
         case INDEX_op_trunc_shr_i32:
             mask = (uint64_t)temps[args[1]].mask >> args[2];
             break;
 
         CASE_OP_32_64(shl):
             if (temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = temps[args[2]].val & (TCG_TARGET_REG_BITS - 1);
                 mask = temps[args[1]].mask << tmp;
             }
             break;
 
         CASE_OP_32_64(neg):
             /* Set to 1 all bits to the left of the rightmost.  */
             mask = 0-(temps[args[1]].mask & (0-temps[args[1]].mask));
             break;
 
         CASE_OP_32_64(deposit):
             mask = (tcg_target_ulong)deposit64(temps[args[1]].mask, args[3], args[4],
                              temps[args[2]].mask);
             break;
 
         CASE_OP_32_64(or):
         CASE_OP_32_64(xor):
             mask = temps[args[1]].mask | temps[args[2]].mask;
             break;
 
         CASE_OP_32_64(setcond):
         case INDEX_op_setcond2_i32:
             mask = 1;
             break;
 
         CASE_OP_32_64(movcond):
             mask = temps[args[3]].mask | temps[args[4]].mask;
             break;
 
         CASE_OP_32_64(ld8u):
             mask = 0xff;
             break;
         CASE_OP_32_64(ld16u):
             mask = 0xffff;
             break;
         case INDEX_op_ld32u_i64:
             mask = 0xffffffffu;
             break;
 
         CASE_OP_32_64(qemu_ld):
             {
                 TCGMemOp mop = args[nb_oargs + nb_iargs];
                 if (!(mop & MO_SIGN)) {
                     mask = (2ULL << ((8 << (mop & MO_SIZE)) - 1)) - 1;
                 }
             }
             break;
 
         default:
             break;
         }
 
         /* 32-bit ops generate 32-bit results.  For the result is zero test
            below, we can ignore high bits, but for further optimizations we
            need to record that the high bits contain garbage.  */
         partmask = mask;
         if (!(def->flags & TCG_OPF_64BIT)) {
             mask |= ~(tcg_target_ulong)0xffffffffu;
             partmask &= 0xffffffffu;
             affected &= 0xffffffffu;
         }
 
         if (partmask == 0) {
             assert(nb_oargs == 1);
             tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], 0);
             args += nb_args;
             gen_args += 2;
             continue;
         }
         if (affected == 0) {
             assert(nb_oargs == 1);
             if (temps_are_copies(s, args[0], args[1])) {
                 s->gen_opc_buf[op_index] = INDEX_op_nop;
             } else if (temps[args[1]].state != TCG_TEMP_CONST) {
                 tcg_opt_gen_mov(s, op_index, gen_args, op, args[0], args[1]);
                 gen_args += 2;
             } else {
                 tcg_opt_gen_movi(s, op_index, gen_args, op,
                                  args[0], temps[args[1]].val);
                 gen_args += 2;
             }
             args += nb_args;
             continue;
         }
 
         /* Simplify expression for "op r, a, 0 => movi r, 0" cases */
         switch (op) {
         CASE_OP_32_64(and):
         CASE_OP_32_64(mul):
         CASE_OP_32_64(muluh):
         CASE_OP_32_64(mulsh):
             if ((temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[2]].val == 0)) {
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], 0);
                 args += 3;
                 gen_args += 2;
                 continue;
             }
             break;
         default:
             break;
         }
 
         /* Simplify expression for "op r, a, a => mov r, a" cases */
         switch (op) {
         CASE_OP_32_64(or):
         CASE_OP_32_64(and):
             if (temps_are_copies(s, args[1], args[2])) {
                 if (temps_are_copies(s, args[0], args[1])) {
                     s->gen_opc_buf[op_index] = INDEX_op_nop;
                 } else {
                     tcg_opt_gen_mov(s, op_index, gen_args, op,
                                     args[0], args[1]);
                     gen_args += 2;
                 }
                 args += 3;
                 continue;
             }
             break;
         default:
             break;
         }
 
         /* Simplify expression for "op r, a, a => movi r, 0" cases */
         switch (op) {
         CASE_OP_32_64(andc):
         CASE_OP_32_64(sub):
         CASE_OP_32_64(xor):
             if (temps_are_copies(s, args[1], args[2])) {
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], 0);
                 gen_args += 2;
                 args += 3;
                 continue;
             }
             break;
         default:
             break;
         }
 
         /* Propagate constants through copy operations and do constant
            folding.  Constants will be substituted to arguments by register
            allocator where needed and possible.  Also detect copies. */
         switch (op) {
         CASE_OP_32_64(mov):
             if (temps_are_copies(s, args[0], args[1])) {
                 args += 2;
                 s->gen_opc_buf[op_index] = INDEX_op_nop;
                 break;
             }
             if (temps[args[1]].state != TCG_TEMP_CONST) {
                 tcg_opt_gen_mov(s, op_index, gen_args, op, args[0], args[1]);
                 gen_args += 2;
                 args += 2;
                 break;
             }
             /* Source argument is constant.  Rewrite the operation and
                let movi case handle it. */
             args[1] = temps[args[1]].val;
             /* fallthrough */
         CASE_OP_32_64(movi):
             tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], args[1]);
             gen_args += 2;
             args += 2;
             break;
 
         CASE_OP_32_64(not):
         CASE_OP_32_64(neg):
         CASE_OP_32_64(ext8s):
         CASE_OP_32_64(ext8u):
         CASE_OP_32_64(ext16s):
         CASE_OP_32_64(ext16u):
         case INDEX_op_ext32s_i64:
         case INDEX_op_ext32u_i64:
             if (temps[args[1]].state == TCG_TEMP_CONST) {
                 tmp = do_constant_folding(s, op, temps[args[1]].val, 0);
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
                 args += 2;
                 break;
             }
             goto do_default;
 
         case INDEX_op_trunc_shr_i32:
             if (temps[args[1]].state == TCG_TEMP_CONST) {
                 tmp = do_constant_folding(s, op, temps[args[1]].val, args[2]);
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
                 args += 3;
                 break;
             }
             goto do_default;
 
         CASE_OP_32_64(add):
         CASE_OP_32_64(sub):
         CASE_OP_32_64(mul):
         CASE_OP_32_64(or):
         CASE_OP_32_64(and):
         CASE_OP_32_64(xor):
         CASE_OP_32_64(shl):
         CASE_OP_32_64(shr):
         CASE_OP_32_64(sar):
         CASE_OP_32_64(rotl):
         CASE_OP_32_64(rotr):
         CASE_OP_32_64(andc):
         CASE_OP_32_64(orc):
         CASE_OP_32_64(eqv):
         CASE_OP_32_64(nand):
         CASE_OP_32_64(nor):
         CASE_OP_32_64(muluh):
         CASE_OP_32_64(mulsh):
         CASE_OP_32_64(div):
         CASE_OP_32_64(divu):
         CASE_OP_32_64(rem):
         CASE_OP_32_64(remu):
             if (temps[args[1]].state == TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = do_constant_folding(s, op, temps[args[1]].val,
                                           temps[args[2]].val);
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
                 args += 3;
                 break;
             }
             goto do_default;
 
         CASE_OP_32_64(deposit):
             if (temps[args[1]].state == TCG_TEMP_CONST
                 && temps[args[2]].state == TCG_TEMP_CONST) {
                 tmp = (TCGArg)deposit64(temps[args[1]].val, args[3], args[4],
                                 temps[args[2]].val);
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
                 args += 5;
                 break;
             }
             goto do_default;
 
         CASE_OP_32_64(setcond):
             tmp = do_constant_folding_cond(s, op, args[1], args[2], args[3]);
             if (tmp != 2) {
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
                 args += 4;
                 break;
             }
             goto do_default;
 
         CASE_OP_32_64(brcond):
             tmp = do_constant_folding_cond(s, op, args[0], args[1], args[2]);
             if (tmp != 2) {
                 if (tmp) {
                     reset_all_temps(s, nb_temps);
                     s->gen_opc_buf[op_index] = INDEX_op_br;
                     gen_args[0] = args[3];
                     gen_args += 1;
                 } else {
                     s->gen_opc_buf[op_index] = INDEX_op_nop;
                 }
                 args += 4;
                 break;
             }
             goto do_default;
 
         CASE_OP_32_64(movcond):
             tmp = do_constant_folding_cond(s, op, args[1], args[2], args[5]);
             if (tmp != 2) {
                 if (temps_are_copies(s, args[0], args[4-tmp])) {
                     s->gen_opc_buf[op_index] = INDEX_op_nop;
                 } else if (temps[args[4-tmp]].state == TCG_TEMP_CONST) {
                     tcg_opt_gen_movi(s, op_index, gen_args, op,
                                      args[0], temps[args[4-tmp]].val);
                     gen_args += 2;
                 } else {
                     tcg_opt_gen_mov(s, op_index, gen_args, op,
                                     args[0], args[4-tmp]);
                     gen_args += 2;
                 }
                 args += 6;
                 break;
             }
             goto do_default;
 
         case INDEX_op_add2_i32:
         case INDEX_op_sub2_i32:
             if (temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[3]].state == TCG_TEMP_CONST
                 && temps[args[4]].state == TCG_TEMP_CONST
                 && temps[args[5]].state == TCG_TEMP_CONST) {
                 uint32_t al = temps[args[2]].val;
                 uint32_t ah = temps[args[3]].val;
                 uint32_t bl = temps[args[4]].val;
                 uint32_t bh = temps[args[5]].val;
                 uint64_t a = ((uint64_t)ah << 32) | al;
                 uint64_t b = ((uint64_t)bh << 32) | bl;
                 TCGArg rl, rh;
 
                 if (op == INDEX_op_add2_i32) {
                     a += b;
                 } else {
                     a -= b;
                 }
 
                 /* We emit the extra nop when we emit the add2/sub2.  */
                 assert(s->gen_opc_buf[op_index + 1] == INDEX_op_nop);
 
                 rl = args[0];
                 rh = args[1];
                 tcg_opt_gen_movi(s, op_index, &gen_args[0],
                                  op, rl, (uint32_t)a);
                 tcg_opt_gen_movi(s, ++op_index, &gen_args[2],
                                  op, rh, (uint32_t)(a >> 32));
                 gen_args += 4;
                 args += 6;
                 break;
             }
             goto do_default;
 
         case INDEX_op_mulu2_i32:
             if (temps[args[2]].state == TCG_TEMP_CONST
                 && temps[args[3]].state == TCG_TEMP_CONST) {
                 uint32_t a = temps[args[2]].val;
                 uint32_t b = temps[args[3]].val;
                 uint64_t r = (uint64_t)a * b;
                 TCGArg rl, rh;
 
                 /* We emit the extra nop when we emit the mulu2.  */
                 assert(s->gen_opc_buf[op_index + 1] == INDEX_op_nop);
 
                 rl = args[0];
                 rh = args[1];
                 tcg_opt_gen_movi(s, op_index, &gen_args[0],
                                  op, rl, (uint32_t)r);
                 tcg_opt_gen_movi(s, ++op_index, &gen_args[2],
                                  op, rh, (uint32_t)(r >> 32));
                 gen_args += 4;
                 args += 4;
                 break;
             }
             goto do_default;
 
         case INDEX_op_brcond2_i32:
             tmp = do_constant_folding_cond2(s, &args[0], &args[2], args[4]);
             if (tmp != 2) {
                 if (tmp) {
             do_brcond_true:
                     reset_all_temps(s, nb_temps);
                     s->gen_opc_buf[op_index] = INDEX_op_br;
                     gen_args[0] = args[5];
                     gen_args += 1;
                 } else {
             do_brcond_false:
                     s->gen_opc_buf[op_index] = INDEX_op_nop;
                 }
             } else if ((args[4] == TCG_COND_LT || args[4] == TCG_COND_GE)
                        && temps[args[2]].state == TCG_TEMP_CONST
                        && temps[args[3]].state == TCG_TEMP_CONST
                        && temps[args[2]].val == 0
                        && temps[args[3]].val == 0) {
                 /* Simplify LT/GE comparisons vs zero to a single compare
                    vs the high word of the input.  */
             do_brcond_high:
                 reset_all_temps(s, nb_temps);
                 s->gen_opc_buf[op_index] = INDEX_op_brcond_i32;
                 gen_args[0] = args[1];
                 gen_args[1] = args[3];
                 gen_args[2] = args[4];
                 gen_args[3] = args[5];
                 gen_args += 4;
             } else if (args[4] == TCG_COND_EQ) {
                 /* Simplify EQ comparisons where one of the pairs
                    can be simplified.  */
                 tmp = do_constant_folding_cond(s, INDEX_op_brcond_i32,
                                                args[0], args[2], TCG_COND_EQ);
                 if (tmp == 0) {
                     goto do_brcond_false;
                 } else if (tmp == 1) {
                     goto do_brcond_high;
                 }
                 tmp = do_constant_folding_cond(s, INDEX_op_brcond_i32,
                                                args[1], args[3], TCG_COND_EQ);
                 if (tmp == 0) {
                     goto do_brcond_false;
                 } else if (tmp != 1) {
                     goto do_default;
                 }
             do_brcond_low:
                 reset_all_temps(s, nb_temps);
                 s->gen_opc_buf[op_index] = INDEX_op_brcond_i32;
                 gen_args[0] = args[0];
                 gen_args[1] = args[2];
                 gen_args[2] = args[4];
                 gen_args[3] = args[5];
                 gen_args += 4;
             } else if (args[4] == TCG_COND_NE) {
                 /* Simplify NE comparisons where one of the pairs
                    can be simplified.  */
                 tmp = do_constant_folding_cond(s, INDEX_op_brcond_i32,
                                                args[0], args[2], TCG_COND_NE);
                 if (tmp == 0) {
                     goto do_brcond_high;
                 } else if (tmp == 1) {
                     goto do_brcond_true;
                 }
                 tmp = do_constant_folding_cond(s, INDEX_op_brcond_i32,
                                                args[1], args[3], TCG_COND_NE);
                 if (tmp == 0) {
                     goto do_brcond_low;
                 } else if (tmp == 1) {
                     goto do_brcond_true;
                 }
                 goto do_default;
             } else {
                 goto do_default;
             }
             args += 6;
             break;
 
         case INDEX_op_setcond2_i32:
             tmp = do_constant_folding_cond2(s, &args[1], &args[3], args[5]);
             if (tmp != 2) {
             do_setcond_const:
                 tcg_opt_gen_movi(s, op_index, gen_args, op, args[0], tmp);
                 gen_args += 2;
             } else if ((args[5] == TCG_COND_LT || args[5] == TCG_COND_GE)
                        && temps[args[3]].state == TCG_TEMP_CONST
                        && temps[args[4]].state == TCG_TEMP_CONST
                        && temps[args[3]].val == 0
                        && temps[args[4]].val == 0) {
                 /* Simplify LT/GE comparisons vs zero to a single compare
                    vs the high word of the input.  */
             do_setcond_high:
                 s->gen_opc_buf[op_index] = INDEX_op_setcond_i32;
                 reset_temp(s, args[0]);
                 temps[args[0]].mask = 1;
                 gen_args[0] = args[0];
                 gen_args[1] = args[2];
                 gen_args[2] = args[4];
                 gen_args[3] = args[5];
                 gen_args += 4;
             } else if (args[5] == TCG_COND_EQ) {
                 /* Simplify EQ comparisons where one of the pairs
                    can be simplified.  */
                 tmp = do_constant_folding_cond(s, INDEX_op_setcond_i32,
                                                args[1], args[3], TCG_COND_EQ);
                 if (tmp == 0) {
                     goto do_setcond_const;
                 } else if (tmp == 1) {
                     goto do_setcond_high;
                 }
                 tmp = do_constant_folding_cond(s, INDEX_op_setcond_i32,
                                                args[2], args[4], TCG_COND_EQ);
                 if (tmp == 0) {
                     goto do_setcond_high;
                 } else if (tmp != 1) {
                     goto do_default;
                 }
             do_setcond_low:
                 reset_temp(s, args[0]);
                 temps[args[0]].mask = 1;
                 s->gen_opc_buf[op_index] = INDEX_op_setcond_i32;
                 gen_args[0] = args[0];
                 gen_args[1] = args[1];
                 gen_args[2] = args[3];
                 gen_args[3] = args[5];
                 gen_args += 4;
             } else if (args[5] == TCG_COND_NE) {
                 /* Simplify NE comparisons where one of the pairs
                    can be simplified.  */
                 tmp = do_constant_folding_cond(s, INDEX_op_setcond_i32,
                                                args[1], args[3], TCG_COND_NE);
                 if (tmp == 0) {
                     goto do_setcond_high;
                 } else if (tmp == 1) {
                     goto do_setcond_const;
                 }
                 tmp = do_constant_folding_cond(s, INDEX_op_setcond_i32,
                                                args[2], args[4], TCG_COND_NE);
                 if (tmp == 0) {
                     goto do_setcond_low;
                 } else if (tmp == 1) {
                     goto do_setcond_const;
                 }
                 goto do_default;
             } else {
                 goto do_default;
             }
             args += 6;
             break;
 
         case INDEX_op_call:
             if (!(args[nb_oargs + nb_iargs + 1]
                   & (TCG_CALL_NO_READ_GLOBALS | TCG_CALL_NO_WRITE_GLOBALS))) {
                 for (i = 0; i < nb_globals; i++) {
                     reset_temp(s, i);
                 }
             }
             goto do_reset_output;
 
         default:
         do_default:
             /* Default case: we know nothing about operation (or were unable
                to compute the operation result) so no propagation is done.
                We trash everything if the operation is the end of a basic
                block, otherwise we only trash the output args.  "mask" is
                the non-zero bits mask for the first output arg.  */
             if (def->flags & TCG_OPF_BB_END) {
                 reset_all_temps(s, nb_temps);
             } else {
         do_reset_output:
                 for (i = 0; i < nb_oargs; i++) {
+                    if (args[i] < 0 || args[i] >= TCG_MAX_TEMPS) {
+                        continue;
+                    }
                     reset_temp(s, args[i]);
                     /* Save the corresponding known-zero bits mask for the
                        first output argument (only one supported so far). */
                     if (i == 0) {
                         temps[args[i]].mask = mask;
                     }
                 }
             }
             for (i = 0; i < nb_args; i++) {
                 gen_args[i] = args[i];
             }
             args += nb_args;
             gen_args += nb_args;
             break;
         }
     }
 
     return gen_args;
 }
diff --git a/qemu/tcg/tcg.c b/qemu/tcg/tcg.c
index 93a327e8..b438b7e2 100644
--- a/qemu/tcg/tcg.c
+++ b/qemu/tcg/tcg.c
@@ -1514,278 +1514,281 @@ static inline void tcg_la_br_end(TCGContext *s, uint8_t *mem_temps)
 /* Liveness analysis : update the opc_dead_args array to tell if a
    given input arguments is dead. Instructions updating dead
    temporaries are removed. */
 static void tcg_liveness_analysis(TCGContext *s)
 {
     int i, op_index, nb_args, nb_iargs, nb_oargs, nb_ops;
     TCGOpcode op, op_new, op_new2;
     TCGArg *args, arg;
     const TCGOpDef *def;
     uint8_t *dead_temps, *mem_temps;
     uint16_t dead_args;
     uint8_t sync_args;
     bool have_op_new2;
 
     s->gen_opc_ptr++; /* skip end */
 
     nb_ops = s->gen_opc_ptr - s->gen_opc_buf;
 
     s->op_dead_args = tcg_malloc(s, nb_ops * sizeof(uint16_t));
     s->op_sync_args = tcg_malloc(s, nb_ops * sizeof(uint8_t));
 
     dead_temps = tcg_malloc(s, s->nb_temps);
     mem_temps = tcg_malloc(s, s->nb_temps);
     tcg_la_func_end(s, dead_temps, mem_temps);
 
     args = s->gen_opparam_ptr;
     op_index = nb_ops - 1;
     while (op_index >= 0) {
         op = s->gen_opc_buf[op_index];
         def = &s->tcg_op_defs[op];
         switch(op) {
         case INDEX_op_call:
             {
                 int call_flags;
 
                 nb_args = args[-1];
                 args -= nb_args;
                 arg = *args++;
                 nb_iargs = arg & 0xffff;
                 nb_oargs = arg >> 16;
                 call_flags = args[nb_oargs + nb_iargs + 1];
 
                 /* pure functions can be removed if their result is not
                    used */
                 if (call_flags & TCG_CALL_NO_SIDE_EFFECTS) {
                     for (i = 0; i < nb_oargs; i++) {
                         arg = args[i];
                         if (!dead_temps[arg] || mem_temps[arg]) {
                             goto do_not_remove_call;
                         }
                     }
                     tcg_set_nop(s, s->gen_opc_buf + op_index,
                                 args - 1, nb_args);
                 } else {
                 do_not_remove_call:
 
                     /* output args are dead */
                     dead_args = 0;
                     sync_args = 0;
                     for (i = 0; i < nb_oargs; i++) {
                         arg = args[i];
                         if (dead_temps[arg]) {
                             dead_args |= (1 << i);
                         }
                         if (mem_temps[arg]) {
                             sync_args |= (1 << i);
                         }
                         dead_temps[arg] = 1;
                         mem_temps[arg] = 0;
                     }
 
                     if (!(call_flags & TCG_CALL_NO_READ_GLOBALS)) {
                         /* globals should be synced to memory */
                         memset(mem_temps, 1, s->nb_globals);
                     }
                     if (!(call_flags & (TCG_CALL_NO_WRITE_GLOBALS |
                                         TCG_CALL_NO_READ_GLOBALS))) {
                         /* globals should go back to memory */
                         memset(dead_temps, 1, s->nb_globals);
                     }
 
                     /* input args are live */
                     for (i = nb_oargs; i < nb_iargs + nb_oargs; i++) {
                         arg = args[i];
                         if (arg != TCG_CALL_DUMMY_ARG) {
                             if (dead_temps[arg]) {
                                 dead_args |= (1 << i);
                             }
                             dead_temps[arg] = 0;
                         }
                     }
                     s->op_dead_args[op_index] = dead_args;
                     s->op_sync_args[op_index] = sync_args;
                 }
                 args--;
             }
             break;
         case INDEX_op_debug_insn_start:
             args -= def->nb_args;
             break;
         case INDEX_op_nopn:
             nb_args = args[-1];
             args -= nb_args;
             break;
         case INDEX_op_discard:
             args--;
             /* mark the temporary as dead */
             dead_temps[args[0]] = 1;
             mem_temps[args[0]] = 0;
             break;
         case INDEX_op_end:
             break;
 
         case INDEX_op_add2_i32:
             op_new = INDEX_op_add_i32;
             goto do_addsub2;
         case INDEX_op_sub2_i32:
             op_new = INDEX_op_sub_i32;
             goto do_addsub2;
         case INDEX_op_add2_i64:
             op_new = INDEX_op_add_i64;
             goto do_addsub2;
         case INDEX_op_sub2_i64:
             op_new = INDEX_op_sub_i64;
         do_addsub2:
             args -= 6;
             nb_iargs = 4;
             nb_oargs = 2;
             /* Test if the high part of the operation is dead, but not
                the low part.  The result can be optimized to a simple
                add or sub.  This happens often for x86_64 guest when the
                cpu mode is set to 32 bit.  */
             if (dead_temps[args[1]] && !mem_temps[args[1]]) {
                 if (dead_temps[args[0]] && !mem_temps[args[0]]) {
                     goto do_remove;
                 }
                 /* Create the single operation plus nop.  */
                 s->gen_opc_buf[op_index] = op = op_new;
                 args[1] = args[2];
                 args[2] = args[4];
                 assert(s->gen_opc_buf[op_index + 1] == INDEX_op_nop);
                 tcg_set_nop(s, s->gen_opc_buf + op_index + 1, args + 3, 3);
                 /* Fall through and mark the single-word operation live.  */
                 nb_iargs = 2;
                 nb_oargs = 1;
             }
             goto do_not_remove;
 
         case INDEX_op_mulu2_i32:
             op_new = INDEX_op_mul_i32;
             op_new2 = INDEX_op_muluh_i32;
             have_op_new2 = TCG_TARGET_HAS_muluh_i32;
             goto do_mul2;
         case INDEX_op_muls2_i32:
             op_new = INDEX_op_mul_i32;
             op_new2 = INDEX_op_mulsh_i32;
             have_op_new2 = TCG_TARGET_HAS_mulsh_i32;
             goto do_mul2;
         case INDEX_op_mulu2_i64:
             op_new = INDEX_op_mul_i64;
             op_new2 = INDEX_op_muluh_i64;
             have_op_new2 = TCG_TARGET_HAS_muluh_i64;
             goto do_mul2;
         case INDEX_op_muls2_i64:
             op_new = INDEX_op_mul_i64;
             op_new2 = INDEX_op_mulsh_i64;
             have_op_new2 = TCG_TARGET_HAS_mulsh_i64;
             goto do_mul2;
         do_mul2:
             args -= 4;
             nb_iargs = 2;
             nb_oargs = 2;
             if (dead_temps[args[1]] && !mem_temps[args[1]]) {
                 if (dead_temps[args[0]] && !mem_temps[args[0]]) {
                     /* Both parts of the operation are dead.  */
                     goto do_remove;
                 }
                 /* The high part of the operation is dead; generate the low. */
                 s->gen_opc_buf[op_index] = op = op_new;
                 args[1] = args[2];
                 args[2] = args[3];
             } else if (have_op_new2 && dead_temps[args[0]]
                        && !mem_temps[args[0]]) {
                 /* The low part of the operation is dead; generate the high.  */
                 s->gen_opc_buf[op_index] = op = op_new2;
                 args[0] = args[1];
                 args[1] = args[2];
                 args[2] = args[3];
             } else {
                 goto do_not_remove;
             }
             assert(s->gen_opc_buf[op_index + 1] == INDEX_op_nop);
             tcg_set_nop(s, s->gen_opc_buf + op_index + 1, args + 3, 1);
             /* Mark the single-word operation live.  */
             nb_oargs = 1;
             goto do_not_remove;
 
         default:
             /* XXX: optimize by hardcoding common cases (e.g. triadic ops) */
             args -= def->nb_args;
             nb_iargs = def->nb_iargs;
             nb_oargs = def->nb_oargs;
 
             /* Test if the operation can be removed because all
                its outputs are dead. We assume that nb_oargs == 0
                implies side effects */
             if (!(def->flags & TCG_OPF_SIDE_EFFECTS) && nb_oargs != 0) {
                 for(i = 0; i < nb_oargs; i++) {
+                    if (args[i] < 0 || args[i] >= TCG_MAX_TEMPS) {
+                        continue;
+                    }
                     arg = args[i];
                     if (!dead_temps[arg] || mem_temps[arg]) {
                         goto do_not_remove;
                     }
                 }
             do_remove:
                 tcg_set_nop(s, s->gen_opc_buf + op_index, args, def->nb_args);
 #ifdef CONFIG_PROFILER
                 s->del_op_count++;
 #endif
             } else {
             do_not_remove:
 
                 /* output args are dead */
                 dead_args = 0;
                 sync_args = 0;
                 for(i = 0; i < nb_oargs; i++) {
                     arg = args[i];
                     if (dead_temps[arg]) {
                         dead_args |= (1 << i);
                     }
                     if (mem_temps[arg]) {
                         sync_args |= (1 << i);
                     }
                     dead_temps[arg] = 1;
                     mem_temps[arg] = 0;
                 }
 
                 /* if end of basic block, update */
                 if (def->flags & TCG_OPF_BB_END) {
                     // Unicorn: do not optimize dead temps on brcond,
                     // this causes problem because check_exit_request() inserts
                     // brcond instruction in the middle of the TB,
                     // which incorrectly flags end-of-block
                     if (op != INDEX_op_brcond_i32)
                         tcg_la_bb_end(s, dead_temps, mem_temps);
                     // Unicorn: we do not touch dead temps for brcond,
                     // but we should refresh TCG globals In-Memory states,
                     // otherwise, important CPU states(especially conditional flags) might be forgotten,
                     // result in wrongly generated host code that run into wrong branch.
                     // Refer to https://github.com/unicorn-engine/unicorn/issues/287 for further information
                     else
                         tcg_la_br_end(s, mem_temps);
                 } else if (def->flags & TCG_OPF_SIDE_EFFECTS) {
                     /* globals should be synced to memory */
                     memset(mem_temps, 1, s->nb_globals);
                 }
 
                 /* input args are live */
                 for(i = nb_oargs; i < nb_oargs + nb_iargs; i++) {
                     arg = args[i];
                     if (dead_temps[arg]) {
                         dead_args |= (1 << i);
                     }
                     dead_temps[arg] = 0;
                 }
                 s->op_dead_args[op_index] = dead_args;
                 s->op_sync_args[op_index] = sync_args;
             }
             break;
         }
         op_index--;
     }
 
     if (args != s->gen_opparam_buf) {
         tcg_abort();
     }
 }
 #else
 /* dummy liveness analysis */
