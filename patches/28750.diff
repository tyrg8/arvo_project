commit 228e268227d6f67af600678166b673cca51480ea
Author: Antoine Pitrou <antoine@python.org>
Date:   Tue Jan 12 19:54:44 2021 +0100

    ARROW-11162: [C++][Parquet] Fix invalid cast on Decimal256 Parquet data
    
    The invalid cast would occur when a variable-length bytearray field would be
    decoded as Decimal256 Arrow data.
    
    Should fix the following issue:
    - https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=28750
    
    Found by OSS-Fuzz.
    
    Closes #9125 from pitrou/ARROW-11162-parquet-decimal256-fuzz
    
    Authored-by: Antoine Pitrou <antoine@python.org>
    Signed-off-by: Antoine Pitrou <antoine@python.org>

diff --git a/cpp/src/parquet/arrow/arrow_reader_writer_test.cc b/cpp/src/parquet/arrow/arrow_reader_writer_test.cc
index d7de2b0dc..1da379cf0 100644
--- a/cpp/src/parquet/arrow/arrow_reader_writer_test.cc
+++ b/cpp/src/parquet/arrow/arrow_reader_writer_test.cc
@@ -1,59 +1,60 @@
 // Licensed to the Apache Software Foundation (ASF) under one
 // or more contributor license agreements.  See the NOTICE file
 // distributed with this work for additional information
 // regarding copyright ownership.  The ASF licenses this file
 // to you under the Apache License, Version 2.0 (the
 // "License"); you may not use this file except in compliance
 // with the License.  You may obtain a copy of the License at
 //
 //   http://www.apache.org/licenses/LICENSE-2.0
 //
 // Unless required by applicable law or agreed to in writing,
 // software distributed under the License is distributed on an
 // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 // KIND, either express or implied.  See the License for the
 // specific language governing permissions and limitations
 // under the License.
 
 #ifdef _MSC_VER
 #pragma warning(push)
 // Disable forcing value to bool warnings
 #pragma warning(disable : 4800)
 #endif
 
 #include "gtest/gtest.h"
 
 #include <cstdint>
 #include <functional>
 #include <iostream>
 #include <sstream>
 #include <vector>
 
 #include "arrow/array/builder_binary.h"
 #include "arrow/array/builder_decimal.h"
 #include "arrow/array/builder_dict.h"
 #include "arrow/array/builder_primitive.h"
 #include "arrow/chunked_array.h"
 #include "arrow/compute/api.h"
 #include "arrow/record_batch.h"
 #include "arrow/scalar.h"
 #include "arrow/table.h"
 #include "arrow/testing/gtest_util.h"
 #include "arrow/testing/random.h"
 #include "arrow/testing/util.h"
 #include "arrow/type_traits.h"
+#include "arrow/util/checked_cast.h"
 #include "arrow/util/decimal.h"
 #include "arrow/util/logging.h"
 #include "arrow/util/range.h"
 
 #include "parquet/api/reader.h"
 #include "parquet/api/writer.h"
 
 #include "parquet/arrow/reader.h"
 #include "parquet/arrow/reader_internal.h"
 #include "parquet/arrow/schema.h"
 #include "parquet/arrow/test_util.h"
 #include "parquet/arrow/writer.h"
 #include "parquet/column_writer.h"
 #include "parquet/file_writer.h"
 #include "parquet/test_util.h"
@@ -77,6 +78,8 @@ using arrow::Status;
 using arrow::Table;
 using arrow::TimeUnit;
 using arrow::compute::DictionaryEncode;
+using arrow::internal::checked_cast;
+using arrow::internal::checked_pointer_cast;
 using arrow::io::BufferReader;
 
 using arrow::randint;
@@ -495,155 +498,219 @@ static std::shared_ptr<GroupNode> MakeSimpleSchema(const DataType& type,
 // Non-template base class for TestParquetIO, to avoid code duplication
 class ParquetIOTestBase : public ::testing::Test {
  public:
   virtual void SetUp() {}
 
   std::unique_ptr<ParquetFileWriter> MakeWriter(
       const std::shared_ptr<GroupNode>& schema) {
     sink_ = CreateOutputStream();
     return ParquetFileWriter::Open(sink_, schema);
   }
 
   void ReaderFromSink(std::unique_ptr<FileReader>* out) {
     ASSERT_OK_AND_ASSIGN(auto buffer, sink_->Finish());
     ASSERT_OK_NO_THROW(OpenFile(std::make_shared<BufferReader>(buffer),
                                 ::arrow::default_memory_pool(), out));
   }
 
   void ReadSingleColumnFile(std::unique_ptr<FileReader> file_reader,
                             std::shared_ptr<Array>* out) {
     std::unique_ptr<ColumnReader> column_reader;
     ASSERT_OK_NO_THROW(file_reader->GetColumn(0, &column_reader));
     ASSERT_NE(nullptr, column_reader.get());
 
     std::shared_ptr<ChunkedArray> chunked_out;
     ASSERT_OK(column_reader->NextBatch(SMALL_SIZE, &chunked_out));
 
     ASSERT_EQ(1, chunked_out->num_chunks());
     *out = chunked_out->chunk(0);
     ASSERT_NE(nullptr, out->get());
+    ASSERT_OK((*out)->ValidateFull());
   }
 
   void ReadSingleColumnFileStatistics(std::unique_ptr<FileReader> file_reader,
                                       std::shared_ptr<Scalar>* min,
                                       std::shared_ptr<Scalar>* max) {
     auto metadata = file_reader->parquet_reader()->metadata();
     ASSERT_EQ(1, metadata->num_row_groups());
     ASSERT_EQ(1, metadata->num_columns());
 
     auto row_group = metadata->RowGroup(0);
     ASSERT_EQ(1, row_group->num_columns());
 
     auto column = row_group->ColumnChunk(0);
     ASSERT_TRUE(column->is_stats_set());
     auto statistics = column->statistics();
 
     ASSERT_OK(StatisticsAsScalars(*statistics, min, max));
   }
 
   void ReadAndCheckSingleColumnFile(const Array& values) {
     std::shared_ptr<Array> out;
 
     std::unique_ptr<FileReader> reader;
     ReaderFromSink(&reader);
     ReadSingleColumnFile(std::move(reader), &out);
 
     AssertArraysEqual(values, *out);
   }
 
   void ReadTableFromFile(std::unique_ptr<FileReader> reader, bool expect_metadata,
                          std::shared_ptr<Table>* out) {
     ASSERT_OK_NO_THROW(reader->ReadTable(out));
     auto key_value_metadata =
         reader->parquet_reader()->metadata()->key_value_metadata().get();
     if (!expect_metadata) {
       ASSERT_EQ(nullptr, key_value_metadata);
     } else {
       ASSERT_NE(nullptr, key_value_metadata);
     }
     ASSERT_NE(nullptr, out->get());
   }
 
   void ReadTableFromFile(std::unique_ptr<FileReader> reader,
                          std::shared_ptr<Table>* out) {
     ReadTableFromFile(std::move(reader), /*expect_metadata=*/false, out);
   }
 
   void RoundTripSingleColumn(
       const std::shared_ptr<Array>& values, const std::shared_ptr<Array>& expected,
       const std::shared_ptr<::parquet::ArrowWriterProperties>& arrow_properties,
       bool nullable = true) {
     std::shared_ptr<Table> table = MakeSimpleTable(values, nullable);
     this->ResetSink();
     ASSERT_OK_NO_THROW(WriteTable(*table, ::arrow::default_memory_pool(), this->sink_,
                                   values->length(), default_writer_properties(),
                                   arrow_properties));
 
     std::shared_ptr<Table> out;
     std::unique_ptr<FileReader> reader;
     ASSERT_NO_FATAL_FAILURE(this->ReaderFromSink(&reader));
     const bool expect_metadata = arrow_properties->store_schema();
     ASSERT_NO_FATAL_FAILURE(
         this->ReadTableFromFile(std::move(reader), expect_metadata, &out));
     ASSERT_EQ(1, out->num_columns());
     ASSERT_EQ(table->num_rows(), out->num_rows());
 
     const auto chunked_array = out->column(0);
     ASSERT_EQ(1, chunked_array->num_chunks());
 
     AssertArraysEqual(*expected, *chunked_array->chunk(0), /*verbose=*/true);
   }
 
   // Prepare table of empty lists, with null values array (ARROW-2744)
   void PrepareEmptyListsTable(int64_t size, std::shared_ptr<Table>* out) {
     std::shared_ptr<Array> lists;
     ASSERT_OK(MakeEmptyListsArray(size, &lists));
     *out = MakeSimpleTable(lists, true /* nullable_lists */);
   }
 
   void ReadAndCheckSingleColumnTable(const std::shared_ptr<Array>& values) {
     std::shared_ptr<::arrow::Table> out;
     std::unique_ptr<FileReader> reader;
     ReaderFromSink(&reader);
     ReadTableFromFile(std::move(reader), &out);
     ASSERT_EQ(1, out->num_columns());
     ASSERT_EQ(values->length(), out->num_rows());
 
     std::shared_ptr<ChunkedArray> chunked_array = out->column(0);
     ASSERT_EQ(1, chunked_array->num_chunks());
     auto result = chunked_array->chunk(0);
 
     AssertArraysEqual(*values, *result);
   }
 
   void CheckRoundTrip(const std::shared_ptr<Table>& table) {
     CheckSimpleRoundtrip(table, table->num_rows());
   }
 
   template <typename ArrayType>
   void WriteColumn(const std::shared_ptr<GroupNode>& schema,
                    const std::shared_ptr<ArrayType>& values) {
     SchemaDescriptor descriptor;
     ASSERT_NO_THROW(descriptor.Init(schema));
     std::shared_ptr<::arrow::Schema> arrow_schema;
     ArrowReaderProperties props;
     ASSERT_OK_NO_THROW(FromParquetSchema(&descriptor, props, &arrow_schema));
 
     std::unique_ptr<FileWriter> writer;
     ASSERT_OK_NO_THROW(FileWriter::Make(::arrow::default_memory_pool(),
                                         MakeWriter(schema), arrow_schema,
                                         default_arrow_writer_properties(), &writer));
     ASSERT_OK_NO_THROW(writer->NewRowGroup(values->length()));
     ASSERT_OK_NO_THROW(writer->WriteColumnChunk(*values));
     ASSERT_OK_NO_THROW(writer->Close());
     // writer->Close() should be idempotent
     ASSERT_OK_NO_THROW(writer->Close());
   }
 
   void ResetSink() { sink_ = CreateOutputStream(); }
 
   std::shared_ptr<::arrow::io::BufferOutputStream> sink_;
 };
 
+class TestReadDecimals : public ParquetIOTestBase {
+ public:
+  void CheckReadFromByteArrays(const std::shared_ptr<const LogicalType>& logical_type,
+                               const std::vector<std::vector<uint8_t>>& values,
+                               const Array& expected) {
+    std::vector<ByteArray> byte_arrays(values.size());
+    std::transform(values.begin(), values.end(), byte_arrays.begin(),
+                   [](const std::vector<uint8_t>& bytes) {
+                     return ByteArray(static_cast<uint32_t>(bytes.size()), bytes.data());
+                   });
+
+    auto node = PrimitiveNode::Make("decimals", Repetition::REQUIRED, logical_type,
+                                    Type::BYTE_ARRAY);
+    auto schema =
+        GroupNode::Make("schema", Repetition::REQUIRED, std::vector<NodePtr>{node});
+
+    auto file_writer = MakeWriter(checked_pointer_cast<GroupNode>(schema));
+    auto column_writer = file_writer->AppendRowGroup()->NextColumn();
+    auto typed_writer = checked_cast<TypedColumnWriter<ByteArrayType>*>(column_writer);
+    typed_writer->WriteBatch(static_cast<int64_t>(byte_arrays.size()),
+                             /*def_levels=*/nullptr,
+                             /*rep_levels=*/nullptr, byte_arrays.data());
+    column_writer->Close();
+    file_writer->Close();
+
+    ReadAndCheckSingleColumnFile(expected);
+  }
+};
+
+// The Decimal roundtrip tests always go through the FixedLenByteArray path,
+// check the ByteArray case manually.
+
+TEST_F(TestReadDecimals, Decimal128ByteArray) {
+  const std::vector<std::vector<uint8_t>> big_endian_decimals = {
+      // 123456
+      {1, 226, 64},
+      // 987654
+      {15, 18, 6},
+      // -123456
+      {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 29, 192},
+  };
+
+  auto expected =
+      ArrayFromJSON(::arrow::decimal128(6, 3), R"(["123.456", "987.654", "-123.456"])");
+  CheckReadFromByteArrays(LogicalType::Decimal(6, 3), big_endian_decimals, *expected);
+}
+
+TEST_F(TestReadDecimals, Decimal256ByteArray) {
+  const std::vector<std::vector<uint8_t>> big_endian_decimals = {
+      // 123456
+      {1, 226, 64},
+      // 987654
+      {15, 18, 6},
+      // -123456
+      {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 29,  192},
+  };
+
+  auto expected =
+      ArrayFromJSON(::arrow::decimal256(40, 3), R"(["123.456", "987.654", "-123.456"])");
+  CheckReadFromByteArrays(LogicalType::Decimal(40, 3), big_endian_decimals, *expected);
+}
+
 template <typename TestType>
 class TestParquetIO : public ParquetIOTestBase {
  public:
diff --git a/cpp/src/parquet/arrow/reader_internal.cc b/cpp/src/parquet/arrow/reader_internal.cc
index 6c387df25..7ec869102 100644
--- a/cpp/src/parquet/arrow/reader_internal.cc
+++ b/cpp/src/parquet/arrow/reader_internal.cc
@@ -407,52 +407,52 @@ template <typename DecimalArrayType>
 struct DecimalConverter<DecimalArrayType, FLBAType> {
   static inline Status ConvertToDecimal(const Array& array,
                                         const std::shared_ptr<DataType>& type,
                                         MemoryPool* pool, std::shared_ptr<Array>* out) {
     const auto& fixed_size_binary_array =
         checked_cast<const ::arrow::FixedSizeBinaryArray&>(array);
 
     // The byte width of each decimal value
     const int32_t type_length =
-        static_cast<const ::arrow::DecimalType&>(*type).byte_width();
+        checked_cast<const ::arrow::DecimalType&>(*type).byte_width();
 
     // number of elements in the entire array
     const int64_t length = fixed_size_binary_array.length();
 
     // Get the byte width of the values in the FixedSizeBinaryArray. Most of the time
     // this will be different from the decimal array width because we write the minimum
     // number of bytes necessary to represent a given precision
     const int32_t byte_width =
         checked_cast<const ::arrow::FixedSizeBinaryType&>(*fixed_size_binary_array.type())
             .byte_width();
     // allocate memory for the decimal array
     ARROW_ASSIGN_OR_RAISE(auto data, ::arrow::AllocateBuffer(length * type_length, pool));
 
     // raw bytes that we can write to
     uint8_t* out_ptr = data->mutable_data();
 
     // convert each FixedSizeBinary value to valid decimal bytes
     const int64_t null_count = fixed_size_binary_array.null_count();
 
     using DecimalType = typename DecimalTypeTrait<DecimalArrayType>::value;
     if (null_count > 0) {
       for (int64_t i = 0; i < length; ++i, out_ptr += type_length) {
         if (!fixed_size_binary_array.IsNull(i)) {
           RETURN_NOT_OK(RawBytesToDecimalBytes<DecimalType>(
               fixed_size_binary_array.GetValue(i), byte_width, out_ptr));
         } else {
           std::memset(out_ptr, 0, type_length);
         }
       }
     } else {
       for (int64_t i = 0; i < length; ++i, out_ptr += type_length) {
         RETURN_NOT_OK(RawBytesToDecimalBytes<DecimalType>(
             fixed_size_binary_array.GetValue(i), byte_width, out_ptr));
       }
     }
 
     *out = std::make_shared<DecimalArrayType>(
         type, length, std::move(data), fixed_size_binary_array.null_bitmap(), null_count);
 
     return Status::OK();
   }
 };
@@ -461,48 +461,48 @@ template <typename DecimalArrayType>
 struct DecimalConverter<DecimalArrayType, ByteArrayType> {
   static inline Status ConvertToDecimal(const Array& array,
                                         const std::shared_ptr<DataType>& type,
                                         MemoryPool* pool, std::shared_ptr<Array>* out) {
-    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(array);
+    const auto& binary_array = checked_cast<const ::arrow::BinaryArray&>(array);
     const int64_t length = binary_array.length();
 
-    const auto& decimal_type = static_cast<const ::arrow::Decimal128Type&>(*type);
+    const auto& decimal_type = checked_cast<const ::arrow::DecimalType&>(*type);
     const int64_t type_length = decimal_type.byte_width();
 
     ARROW_ASSIGN_OR_RAISE(auto data, ::arrow::AllocateBuffer(length * type_length, pool));
 
     // raw bytes that we can write to
     uint8_t* out_ptr = data->mutable_data();
 
     const int64_t null_count = binary_array.null_count();
 
     // convert each BinaryArray value to valid decimal bytes
     for (int64_t i = 0; i < length; i++, out_ptr += type_length) {
       int32_t record_len = 0;
       const uint8_t* record_loc = binary_array.GetValue(i, &record_len);
 
       if (record_len < 0 || record_len > type_length) {
-        return Status::Invalid("Invalid BYTE_ARRAY length for Decimal128");
+        return Status::Invalid("Invalid BYTE_ARRAY length for ", type->ToString());
       }
 
       auto out_ptr_view = reinterpret_cast<uint64_t*>(out_ptr);
       out_ptr_view[0] = 0;
       out_ptr_view[1] = 0;
 
       // only convert rows that are not null if there are nulls, or
       // all rows, if there are not
       if ((null_count > 0 && !binary_array.IsNull(i)) || null_count <= 0) {
         using DecimalType = typename DecimalTypeTrait<DecimalArrayType>::value;
         RETURN_NOT_OK(
             RawBytesToDecimalBytes<DecimalType>(record_loc, record_len, out_ptr));
       }
     }
     *out = std::make_shared<DecimalArrayType>(type, length, std::move(data),
                                               binary_array.null_bitmap(), null_count);
     return Status::OK();
   }
 };
 
 /// \brief Convert an Int32 or Int64 array into a Decimal128Array
 /// The parquet spec allows systems to write decimals in int32, int64 if the values are
 /// small enough to fit in less 4 bytes or less than 8 bytes, respectively.
 /// This function implements the conversion from int32 and int64 arrays to decimal arrays.
@@ -510,57 +510,57 @@ template <
     typename ParquetIntegerType,
     typename = ::arrow::enable_if_t<std::is_same<ParquetIntegerType, Int32Type>::value ||
                                     std::is_same<ParquetIntegerType, Int64Type>::value>>
 static Status DecimalIntegerTransfer(RecordReader* reader, MemoryPool* pool,
                                      const std::shared_ptr<DataType>& type, Datum* out) {
   // Decimal128 and Decimal256 are only Arrow constructs.  Parquet does not
   // specifically distinguish between decimal byte widths.
   // Decimal256 isn't relevant here because the Arrow-Parquet C++ bindings never
   // write Decimal values as integers and if the decimal value can fit in an
   // integer it is wasteful to use Decimal256. Put another way, the only
   // way an integer column could be construed as Decimal256 is if an arrow
   // schema was stored as metadata in the file indicating the column was
   // Decimal256. The current Arrow-Parquet C++ bindings will never do this.
   DCHECK(type->id() == ::arrow::Type::DECIMAL128);
 
   const int64_t length = reader->values_written();
 
   using ElementType = typename ParquetIntegerType::c_type;
   static_assert(std::is_same<ElementType, int32_t>::value ||
                     std::is_same<ElementType, int64_t>::value,
                 "ElementType must be int32_t or int64_t");
 
   const auto values = reinterpret_cast<const ElementType*>(reader->values());
 
-  const auto& decimal_type = static_cast<const ::arrow::DecimalType&>(*type);
+  const auto& decimal_type = checked_cast<const ::arrow::DecimalType&>(*type);
   const int64_t type_length = decimal_type.byte_width();
 
   ARROW_ASSIGN_OR_RAISE(auto data, ::arrow::AllocateBuffer(length * type_length, pool));
   uint8_t* out_ptr = data->mutable_data();
 
   using ::arrow::BitUtil::FromLittleEndian;
 
   for (int64_t i = 0; i < length; ++i, out_ptr += type_length) {
     // sign/zero extend int32_t values, otherwise a no-op
     const auto value = static_cast<int64_t>(values[i]);
 
     ::arrow::Decimal128 decimal(value);
     decimal.ToBytes(out_ptr);
   }
 
   if (reader->nullable_values()) {
     std::shared_ptr<ResizableBuffer> is_valid = reader->ReleaseIsValid();
     *out = std::make_shared<Decimal128Array>(type, length, std::move(data), is_valid,
                                              reader->null_count());
   } else {
     *out = std::make_shared<Decimal128Array>(type, length, std::move(data));
   }
   return Status::OK();
 }
 
-/// \brief Convert an arrow::BinaryArray to an arrow::Decimal128Array
+/// \brief Convert an arrow::BinaryArray to an arrow::Decimal{128,256}Array
 /// We do this by:
 /// 1. Creating an arrow::BinaryArray from the RecordReader's builder
-/// 2. Allocating a buffer for the arrow::Decimal128Array
+/// 2. Allocating a buffer for the arrow::Decimal{128,256}Array
 /// 3. Converting the big-endian bytes in each BinaryArray entry to two integers
 ///    representing the high and low bits of each decimal value.
 template <typename DecimalArrayType, typename ParquetType>
@@ -595,120 +595,120 @@ Status TransferDecimal(RecordReader* reader, MemoryPool* pool,
 Status TransferColumnData(RecordReader* reader, std::shared_ptr<DataType> value_type,
                           const ColumnDescriptor* descr, MemoryPool* pool,
                           std::shared_ptr<ChunkedArray>* out) {
   Datum result;
   std::shared_ptr<ChunkedArray> chunked_result;
   switch (value_type->id()) {
     case ::arrow::Type::DICTIONARY: {
       RETURN_NOT_OK(TransferDictionary(reader, value_type, &chunked_result));
       result = chunked_result;
     } break;
     case ::arrow::Type::NA: {
       result = std::make_shared<::arrow::NullArray>(reader->values_written());
       break;
     }
     case ::arrow::Type::INT32:
     case ::arrow::Type::INT64:
     case ::arrow::Type::FLOAT:
     case ::arrow::Type::DOUBLE:
       result = TransferZeroCopy(reader, value_type);
       break;
     case ::arrow::Type::BOOL:
       RETURN_NOT_OK(TransferBool(reader, pool, &result));
       break;
       TRANSFER_INT32(UINT8, ::arrow::UInt8Type);
       TRANSFER_INT32(INT8, ::arrow::Int8Type);
       TRANSFER_INT32(UINT16, ::arrow::UInt16Type);
       TRANSFER_INT32(INT16, ::arrow::Int16Type);
       TRANSFER_INT32(UINT32, ::arrow::UInt32Type);
       TRANSFER_INT64(UINT64, ::arrow::UInt64Type);
       TRANSFER_INT32(DATE32, ::arrow::Date32Type);
       TRANSFER_INT32(TIME32, ::arrow::Time32Type);
       TRANSFER_INT64(TIME64, ::arrow::Time64Type);
     case ::arrow::Type::DATE64:
       RETURN_NOT_OK(TransferDate64(reader, pool, value_type, &result));
       break;
     case ::arrow::Type::FIXED_SIZE_BINARY:
     case ::arrow::Type::BINARY:
     case ::arrow::Type::STRING:
     case ::arrow::Type::LARGE_BINARY:
     case ::arrow::Type::LARGE_STRING: {
       RETURN_NOT_OK(TransferBinary(reader, pool, value_type, &chunked_result));
       result = chunked_result;
     } break;
     case ::arrow::Type::DECIMAL128: {
       switch (descr->physical_type()) {
         case ::parquet::Type::INT32: {
           auto fn = DecimalIntegerTransfer<Int32Type>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         case ::parquet::Type::INT64: {
           auto fn = &DecimalIntegerTransfer<Int64Type>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         case ::parquet::Type::BYTE_ARRAY: {
           auto fn = &TransferDecimal<Decimal128Array, ByteArrayType>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         case ::parquet::Type::FIXED_LEN_BYTE_ARRAY: {
           auto fn = &TransferDecimal<Decimal128Array, FLBAType>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         default:
           return Status::Invalid(
               "Physical type for decimal128 must be int32, int64, byte array, or fixed "
               "length binary");
       }
     } break;
     case ::arrow::Type::DECIMAL256:
       switch (descr->physical_type()) {
         case ::parquet::Type::BYTE_ARRAY: {
           auto fn = &TransferDecimal<Decimal256Array, ByteArrayType>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         case ::parquet::Type::FIXED_LEN_BYTE_ARRAY: {
           auto fn = &TransferDecimal<Decimal256Array, FLBAType>;
           RETURN_NOT_OK(fn(reader, pool, value_type, &result));
         } break;
         default:
           return Status::Invalid(
               "Physical type for decimal256 must be fixed length binary");
       }
       break;
 
     case ::arrow::Type::TIMESTAMP: {
       const ::arrow::TimestampType& timestamp_type =
-          static_cast<::arrow::TimestampType&>(*value_type);
+          checked_cast<::arrow::TimestampType&>(*value_type);
       switch (timestamp_type.unit()) {
         case ::arrow::TimeUnit::MILLI:
         case ::arrow::TimeUnit::MICRO: {
           result = TransferZeroCopy(reader, value_type);
         } break;
         case ::arrow::TimeUnit::NANO: {
           if (descr->physical_type() == ::parquet::Type::INT96) {
             RETURN_NOT_OK(TransferInt96(reader, pool, value_type, &result));
           } else {
             result = TransferZeroCopy(reader, value_type);
           }
         } break;
         default:
           return Status::NotImplemented("TimeUnit not supported");
       }
     } break;
     default:
       return Status::NotImplemented("No support for reading columns of type ",
                                     value_type->ToString());
   }
 
   if (result.kind() == Datum::ARRAY) {
     *out = std::make_shared<ChunkedArray>(result.make_array());
   } else if (result.kind() == Datum::CHUNKED_ARRAY) {
     *out = result.chunked_array();
   } else {
     DCHECK(false) << "Should be impossible, result was " << result.ToString();
   }
 
   return Status::OK();
 }
 
 }  // namespace arrow
 }  // namespace parquet
diff --git a/testing b/testing
index d6c4deb22..b4eeafdec 160000
--- a/testing
+++ b/testing
@@ -1 +1 @@
-Subproject commit d6c4deb22c4b4e9e3247a2f291046e3c671ad235
+Subproject commit b4eeafdec6fb5284c4aaf269f2ebdb3be2c63ed5
