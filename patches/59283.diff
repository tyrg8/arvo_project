commit 82c62642b3d8dbe79a5a584144943c1d91d43464
Author: Nemanja Stojoski <nemanja.stojoski@oracle.com>
Date:   Fri May 5 07:51:11 2023 +0000

    Bug#35362175 - List of failed MTR tests is not sorted
    
    Problem:
    Once the tests finish, the summary report is generated, with the list of
    failed tests. However, this list is not sorted, making it difficult to
    compare different runs of the script, for example from different
    branches.
    
    Solution:
    Sort the failed and unstable tests before printing them.
    
    Change-Id: Ib4b39cfb386eabb6cfe219e3f2684a4c8eb1beff

diff --git a/mysql-test/lib/mtr_report.pm b/mysql-test/lib/mtr_report.pm
index bdb4b50038b..8e02ffa153c 100644
--- a/mysql-test/lib/mtr_report.pm
+++ b/mysql-test/lib/mtr_report.pm
@@ -552,198 +552,198 @@ sub mtr_generate_secondary_engine_offload_count_report($) {
 # Goes through the list of completed tests and accumulates various
 # statistics, then prints them.
 sub mtr_report_stats ($$;$) {
   my ($prefix, $tests, $dont_error) = @_;
 
   # Find out how we where doing
   my $found_problems = 0;
   my $tot_failed     = 0;
   my $tot_passed     = 0;
   my $tot_reinits    = 0;
   my $tot_restarts   = 0;
   my $tot_skipdetect = 0;
   my $tot_skipped    = 0;
   my $tot_tests      = 0;
   my $tot_unstable   = 0;
 
   foreach my $tinfo (@$tests) {
     if ($tinfo->{failures}) {
       # Test has failed at least one time
       $tot_tests++;
       $tot_failed++;
 
       if ($::opt_report_unstable_tests and defined $tinfo->{retries}) {
         my $num_passed = $tinfo->{retries} - $tinfo->{failures} - 1;
         # Tests which exhibit both passing and failing behaviour with
         # the same code are unstable tests. The level of instability is
         # not restricted i.e. a failed test which is successful on at
         # least one retry is marked unstable.
         if ($num_passed > 0) {
           $tot_unstable++;
           $tinfo->{'result'} = 'MTR_RES_UNSTABLE';
         }
       }
     } elsif ($tinfo->{'result'} eq 'MTR_RES_SKIPPED') {
       # Test was skipped (disabled not counted)
       $tot_skipped++ unless $tinfo->{'disable'};
       $tot_skipdetect++ if $tinfo->{'skip_detected_by_test'};
     } elsif ($tinfo->{'result'} eq 'MTR_RES_PASSED') {
       # Test passed
       $tot_tests++;
       $tot_passed++;
     }
 
     if ($tinfo->{'restarted'}) {
       # Servers was restarted
       $tot_restarts++;
     }
 
     if ($tinfo->{'reinitialized'}) {
       # Server was reinitialized
       $tot_reinits++;
     }
 
     # Add counts for repeated runs, if any. Note that the last run has
     # already been counted above.
     my $num_repeat = $tinfo->{'repeat'} - 1;
     if ($num_repeat > 0) {
       $tot_tests += $num_repeat;
       my $rep_failed = $tinfo->{'rep_failures'} || 0;
       $tot_failed += $rep_failed;
       $tot_passed += $num_repeat - $rep_failed;
     }
 
     # Look for warnings produced by mysqltest
     my $base_file = mtr_match_extension($tinfo->{'result_file'}, "result");
 
     my $warning_file = "$base_file.warnings";
     if (-f $warning_file) {
       $found_problems = 1;
       mtr_warning("Check myqltest warnings in '$warning_file'");
     }
   }
 
   # Print out a summary report to screen
   print "The servers were restarted $tot_restarts times\n";
   print "The servers were reinitialized $tot_reinits times\n";
 
   if ($timer) {
     use English;
     mtr_report("Spent", sprintf("%.3f", $tot_real_time),
                "of",
                time - $BASETIME,
                "seconds executing testcases");
   }
 
   resfile_global("duration", time - $BASETIME) if $::opt_resfile;
   my $warnlog = "$::opt_vardir/log/warnings";
   if (-f $warnlog) {
     mtr_warning("Got errors/warnings while running tests, please examine",
                 "'$warnlog' for details.");
   }
 
   print "\n";
 
   # Print a list of check_testcases that failed(if any)
   if ($::opt_check_testcases) {
     my %check_testcases;
     foreach my $tinfo (@$tests) {
       if (defined $tinfo->{'check_testcase_failed'}) {
         $check_testcases{ $tinfo->{'name'} } = 1;
       }
     }
 
     if (keys %check_testcases) {
       print "Check of testcase failed for: ";
       print join(" ", keys %check_testcases);
       print "\n\n";
     }
   }
 
   # Print summary line prefix
   summary_print("$prefix: ");
 
   # Print a list of testcases that failed
   if ($tot_failed != 0) {
     my $ratio = $tot_passed * 100 / $tot_tests;
     summary_print(
          sprintf(
              "Failed $tot_failed/$tot_tests tests, %.2f%% were successful.\n\n",
              $ratio));
 
     # Hashes to keep track of reported failures
     my %seen          = ();
     my %seen_unstable = ();
 
     foreach my $tinfo (@$tests) {
       my $tname = $tinfo->{'name'};
       if (($tinfo->{failures} || $tinfo->{rep_failures})) {
         # Check for unstable tests
         if ($tinfo->{result} eq "MTR_RES_UNSTABLE" and !$seen_unstable{$tname})
         {
           # Report all unstable tests in the following format.
           # <test_name>(<number of failures>/<total attempts>).
           #
           # Marking the test as 'seen' in case of unstable tests might
           # cause hard-failures in other combination runs of the same
           # test to not be reported. Separate hash used to avoid
           # redundant mentions of an unstable test.
           $seen_unstable{$tname} =
             "(" . $tinfo->{failures} . "/" . ($tinfo->{retries} - 1) . ")";
         } elsif (!$seen{$tname}) {
           $seen{$tname} = 1;
         }
       }
     }
 
     # Print the list of tests that failed in a format that can be copy
     # pasted to rerun only failing tests.
     if (%seen) {
-      summary_print("Failing test(s): " . join(" ", keys %seen) . "\n\n");
+      summary_print("Failing test(s): " . join(" ", sort keys %seen) . "\n\n");
     }
 
     # Print unstable tests, if any
     if (%seen_unstable) {
       summary_print("Unstable test(s)(failures/attempts): " .
-                join(" ", map { $_ . $seen_unstable{$_} } keys %seen_unstable) .
+                join(" ", map { $_ . $seen_unstable{$_} } sort keys %seen_unstable) .
                 "\n\n");
     }
 
     # Print info about reporting the error
     print
       "The log files in var/log may give you some hint of what went wrong.\n\n",
       "If you want to report this error, please read first ",
       "the documentation\n",
       "at http://dev.mysql.com/doc/mysql/en/mysql-test-suite.html\n\n";
 
   } else {
     summary_print("All $tot_tests tests were successful.\n\n");
   }
   close($summary_report_file) if defined($summary_report_file);
 
   if ($xml_report_file) {
     mtr_generate_xml_report($tests);
     $xml_report_file->flush();
   }
 
   if ($::secondary_engine_support and $offload_count_file) {
     mtr_generate_secondary_engine_offload_count_report($tests);
     $offload_count_file->flush();
     $offload_count_file->close();
   }
 
   print "$tot_skipped tests were skipped, " .
     "$tot_skipdetect by the test itself.\n\n"
     if $tot_skipped;
 
   if ($tot_failed != 0 || $found_problems) {
     if ($tot_failed == $tot_unstable) {
       # Print a warning if all failures are due to unstable tests
       mtr_warning("There are failures due to unstable test cases.\n" .
                   "However, the tests are not hard-failing.");
     } else {
       mtr_error("there were failing test cases") unless $dont_error;
     }
   }
 }
 
 # Text formatting
