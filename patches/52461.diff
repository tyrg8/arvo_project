commit 396972bb695d14ac76a6fdd007c4578fc2d3a5cd
Author: Zaggy1024 <zaggy1024@gmail.com>
Date:   Thu Nov 24 21:53:24 2022 -0600

    LibVideo/VP9: Retain adjacent block contexts storage between frames
    
    Re-allocating the storage is unnecessary, since the size will rarely
    change during playback.

diff --git a/Userland/Libraries/LibVideo/VP9/Context.h b/Userland/Libraries/LibVideo/VP9/Context.h
index 69e6f06080..9e8d10a2af 100644
--- a/Userland/Libraries/LibVideo/VP9/Context.h
+++ b/Userland/Libraries/LibVideo/VP9/Context.h
@@ -253,73 +253,78 @@ struct ColorConfig {
 
 struct FrameContext {
 public:
+    FrameContext(Vector2D<FrameBlockContext>& contexts)
+        : m_block_contexts(contexts)
+    {
+    }
+
     u8 profile { 0 };
 
     FrameType type { FrameType::KeyFrame };
     bool is_inter_predicted() const { return type == FrameType::InterFrame; }
 
     bool error_resilient_mode { false };
     bool parallel_decoding_mode { false };
     bool should_replace_probability_context { false };
 
     bool shows_a_frame() const { return m_frame_show_mode != FrameShowMode::DoNotShowFrame; }
     bool shows_a_new_frame() const { return m_frame_show_mode == FrameShowMode::CreateAndShowNewFrame; }
     bool shows_existing_frame() const { return m_frame_show_mode == FrameShowMode::ShowExistingFrame; }
     void set_frame_hidden() { m_frame_show_mode = FrameShowMode::DoNotShowFrame; }
     void set_existing_frame_to_show(u8 index)
     {
         m_frame_show_mode = FrameShowMode::ShowExistingFrame;
         m_existing_frame_index = index;
     }
     u8 existing_frame_index() const { return m_existing_frame_index; }
 
     ColorConfig color_config {};
 
     u8 reference_frames_to_update_flags { 0 };
     bool should_update_reference_frame_at_index(u8 index) const { return (reference_frames_to_update_flags & (1 << index)) != 0; }
 
     u8 probability_context_index { 0 };
 
     Gfx::Size<u32> size() const { return m_size; }
     ErrorOr<void> set_size(Gfx::Size<u32> size)
     {
         m_size = size;
 
         // From spec, compute_image_size( )
         m_rows = (size.height() + 7u) >> 3u;
         m_columns = (size.width() + 7u) >> 3u;
         return m_block_contexts.try_resize(m_rows, m_columns);
     }
     u32 rows() const { return m_rows; }
     u32 columns() const { return m_columns; }
     u32 superblock_rows() const { return (rows() + 7u) >> 3u; }
     u32 superblock_columns() const { return (columns() + 7u) >> 3u; }
 
     Vector2D<FrameBlockContext> const& block_contexts() const { return m_block_contexts; }
 
     Gfx::Size<u32> render_size { 0, 0 };
     Gfx::Size<u16> log2_of_tile_counts { 0, 0 };
 
     // This group of fields is only needed for inter-predicted frames.
     Array<u8, 3> reference_frame_indices;
     Array<bool, LastFrame + 3> reference_frame_sign_biases;
     bool high_precision_motion_vectors_allowed { false };
     InterpolationFilter interpolation_filter { InterpolationFilter::Switchable };
 
     u8 loop_filter_level { 0 };
     u8 loop_filter_sharpness { 0 };
     bool loop_filter_delta_enabled { false };
     Array<i8, MAX_REF_FRAMES> loop_filter_reference_deltas;
     Array<i8, 2> loop_filter_mode_deltas;
 
     u8 base_quantizer_index { 0 };
     i8 y_dc_quantizer_index_delta { 0 };
     i8 uv_dc_quantizer_index_delta { 0 };
     i8 uv_ac_quantizer_index_delta { 0 };
     bool is_lossless() const
     {
         // From quantization_params( ) in the spec.
         return base_quantizer_index == 0 && y_dc_quantizer_index_delta == 0 && uv_dc_quantizer_index_delta == 0 && uv_ac_quantizer_index_delta == 0;
     }
 
     u16 header_size_in_bytes { 0 };
@@ -327,18 +332,18 @@ public:
 private:
     friend struct TileContext;
 
     FrameShowMode m_frame_show_mode { FrameShowMode::CreateAndShowNewFrame };
     u8 m_existing_frame_index { 0 };
 
     Gfx::Size<u32> m_size { 0, 0 };
     u32 m_rows { 0 };
     u32 m_columns { 0 };
     // FIXME: From spec: NOTE â€“ We are using a 2D array to store the SubModes for clarity. It is possible to reduce memory
     //        consumption by only storing one intra mode for each 8x8 horizontal and vertical position, i.e. to use two 1D
     //        arrays instead.
     //        I think should also apply to other fields that are only accessed relative to the current block. Worth looking
     //        into how much of this context needs to be stored for the whole frame vs a row or column from the current tile.
-    Vector2D<FrameBlockContext> m_block_contexts;
+    Vector2D<FrameBlockContext>& m_block_contexts;
 };
 
 struct TileContext {
diff --git a/Userland/Libraries/LibVideo/VP9/Parser.cpp b/Userland/Libraries/LibVideo/VP9/Parser.cpp
index fc735d1f55..34f5950a9f 100644
--- a/Userland/Libraries/LibVideo/VP9/Parser.cpp
+++ b/Userland/Libraries/LibVideo/VP9/Parser.cpp
@@ -147,125 +147,128 @@ DecoderErrorOr<ColorRange> Parser::read_color_range()
 /* (6.2) */
 DecoderErrorOr<FrameContext> Parser::uncompressed_header()
 {
-    FrameContext frame_context;
+    // NOTE: m_reusable_frame_block_contexts does not need to retain any data between frame decodes.
+    //       This is only stored so that we don't need to allocate a frame's block contexts on each
+    //       call to this function, since it will rarely change sizes.
+    FrameContext frame_context { m_reusable_frame_block_contexts };
     frame_context.color_config = m_previous_color_config;
 
     auto frame_marker = TRY_READ(m_bit_stream->read_bits(2));
     if (frame_marker != 2)
         return DecoderError::corrupted("uncompressed_header: Frame marker must be 2"sv);
 
     auto profile_low_bit = TRY_READ(m_bit_stream->read_bit());
     auto profile_high_bit = TRY_READ(m_bit_stream->read_bit());
     frame_context.profile = (profile_high_bit << 1u) + profile_low_bit;
     if (frame_context.profile == 3 && TRY_READ(m_bit_stream->read_bit()))
         return DecoderError::corrupted("uncompressed_header: Profile 3 reserved bit was non-zero"sv);
 
     if (TRY_READ(m_bit_stream->read_bit())) {
         frame_context.set_existing_frame_to_show(TRY_READ(m_bit_stream->read_bits(3)));
         return frame_context;
     }
 
     bool is_keyframe = !TRY_READ(m_bit_stream->read_bit());
 
     if (!TRY_READ(m_bit_stream->read_bit()))
         frame_context.set_frame_hidden();
 
     frame_context.error_resilient_mode = TRY_READ(m_bit_stream->read_bit());
 
     FrameType type;
 
     Gfx::Size<u32> frame_size;
     Gfx::Size<u32> render_size;
     u8 reference_frames_to_update_flags = 0xFF; // Save frame to all reference indices by default.
 
     enum class ResetProbabilities : u8 {
         No = 0,
         // 1 also means No here, but we don't need to do anything with the No case.
         OnlyCurrent = 2,
         All = 3,
     };
     ResetProbabilities reset_frame_context = ResetProbabilities::All;
 
     if (is_keyframe) {
         type = FrameType::KeyFrame;
         TRY(frame_sync_code());
         frame_context.color_config = TRY(parse_color_config(frame_context));
         frame_size = TRY(parse_frame_size());
         render_size = TRY(parse_render_size(frame_size));
     } else {
         if (!frame_context.shows_a_frame() && TRY_READ(m_bit_stream->read_bit())) {
             type = FrameType::IntraOnlyFrame;
         } else {
             type = FrameType::InterFrame;
             reset_frame_context = ResetProbabilities::No;
         }
 
         if (!frame_context.error_resilient_mode)
             reset_frame_context = static_cast<ResetProbabilities>(TRY_READ(m_bit_stream->read_bits(2)));
 
         if (type == FrameType::IntraOnlyFrame) {
             TRY(frame_sync_code());
 
             frame_context.color_config = frame_context.profile > 0 ? TRY(parse_color_config(frame_context)) : ColorConfig();
 
             reference_frames_to_update_flags = TRY_READ(m_bit_stream->read_f8());
             frame_size = TRY(parse_frame_size());
             render_size = TRY(parse_render_size(frame_size));
         } else {
             reference_frames_to_update_flags = TRY_READ(m_bit_stream->read_f8());
             for (auto i = 0; i < 3; i++) {
                 frame_context.reference_frame_indices[i] = TRY_READ(m_bit_stream->read_bits(3));
                 frame_context.reference_frame_sign_biases[LastFrame + i] = TRY_READ(m_bit_stream->read_bit());
             }
             frame_size = TRY(parse_frame_size_with_refs(frame_context.reference_frame_indices));
             render_size = TRY(parse_render_size(frame_size));
             frame_context.high_precision_motion_vectors_allowed = TRY_READ(m_bit_stream->read_bit());
             frame_context.interpolation_filter = TRY(read_interpolation_filter());
         }
     }
 
     bool should_replace_probability_context = false;
     bool parallel_decoding_mode = true;
     if (!frame_context.error_resilient_mode) {
         should_replace_probability_context = TRY_READ(m_bit_stream->read_bit());
         parallel_decoding_mode = TRY_READ(m_bit_stream->read_bit());
     }
 
     u8 probability_context_index = TRY_READ(m_bit_stream->read_bits(2));
     switch (reset_frame_context) {
     case ResetProbabilities::All:
         setup_past_independence();
         for (auto i = 0; i < 4; i++) {
             m_probability_tables->save_probs(i);
         }
         probability_context_index = 0;
         break;
     case ResetProbabilities::OnlyCurrent:
         setup_past_independence();
         m_probability_tables->save_probs(probability_context_index);
         probability_context_index = 0;
         break;
     default:
         break;
     }
 
     frame_context.type = type;
     DECODER_TRY_ALLOC(frame_context.set_size(frame_size));
     frame_context.render_size = render_size;
     TRY(compute_image_size(frame_context));
 
     frame_context.reference_frames_to_update_flags = reference_frames_to_update_flags;
     frame_context.parallel_decoding_mode = parallel_decoding_mode;
 
     frame_context.should_replace_probability_context = should_replace_probability_context;
     frame_context.probability_context_index = probability_context_index;
 
     TRY(loop_filter_params(frame_context));
     TRY(quantization_params(frame_context));
     TRY(segmentation_params());
     TRY(parse_tile_counts(frame_context));
 
     frame_context.header_size_in_bytes = TRY_READ(m_bit_stream->read_f16());
 
     return frame_context;
 }
diff --git a/Userland/Libraries/LibVideo/VP9/Parser.h b/Userland/Libraries/LibVideo/VP9/Parser.h
index 9a2c513383..b572508530 100644
--- a/Userland/Libraries/LibVideo/VP9/Parser.h
+++ b/Userland/Libraries/LibVideo/VP9/Parser.h
@@ -39,150 +39,151 @@ public:
 private:
     /* Annex B: Superframes are a method of storing multiple coded frames into a single chunk
      * See also section 5.26. */
     Vector<size_t> parse_superframe_sizes(ReadonlyBytes);
 
     DecoderErrorOr<FrameType> read_frame_type();
     DecoderErrorOr<ColorRange> read_color_range();
 
     /* Utilities */
     template<typename T>
     void clear_context(Vector<T>& context, size_t size);
     template<typename T>
     void clear_context(Vector<Vector<T>>& context, size_t outer_size, size_t inner_size);
 
     /* (6.1) Frame Syntax */
     bool trailing_bits();
     DecoderErrorOr<void> refresh_probs(FrameContext const&);
 
     /* (6.2) Uncompressed Header Syntax */
     DecoderErrorOr<FrameContext> uncompressed_header();
     DecoderErrorOr<void> frame_sync_code();
     DecoderErrorOr<ColorConfig> parse_color_config(FrameContext const&);
     DecoderErrorOr<void> set_frame_size_and_compute_image_size();
     DecoderErrorOr<Gfx::Size<u32>> parse_frame_size();
     DecoderErrorOr<Gfx::Size<u32>> parse_frame_size_with_refs(Array<u8, 3> const& reference_indices);
     DecoderErrorOr<Gfx::Size<u32>> parse_render_size(Gfx::Size<u32> frame_size);
     DecoderErrorOr<void> compute_image_size(FrameContext&);
     DecoderErrorOr<InterpolationFilter> read_interpolation_filter();
     DecoderErrorOr<void> loop_filter_params(FrameContext&);
     DecoderErrorOr<void> quantization_params(FrameContext&);
     DecoderErrorOr<i8> read_delta_q();
     DecoderErrorOr<void> segmentation_params();
     DecoderErrorOr<u8> read_prob();
     DecoderErrorOr<void> parse_tile_counts(FrameContext&);
     void setup_past_independence();
 
     /* (6.3) Compressed Header Syntax */
     DecoderErrorOr<void> compressed_header(FrameContext&);
     DecoderErrorOr<void> read_tx_mode(FrameContext const&);
     DecoderErrorOr<void> tx_mode_probs();
     DecoderErrorOr<u8> diff_update_prob(u8 prob);
     DecoderErrorOr<u8> decode_term_subexp();
     u8 inv_remap_prob(u8 delta_prob, u8 prob);
     u8 inv_recenter_nonneg(u8 v, u8 m);
     DecoderErrorOr<void> read_coef_probs();
     DecoderErrorOr<void> read_skip_prob();
     DecoderErrorOr<void> read_inter_mode_probs();
     DecoderErrorOr<void> read_interp_filter_probs();
     DecoderErrorOr<void> read_is_inter_probs();
     DecoderErrorOr<void> frame_reference_mode(FrameContext&);
     DecoderErrorOr<void> frame_reference_mode_probs();
     DecoderErrorOr<void> read_y_mode_probs();
     DecoderErrorOr<void> read_partition_probs();
     DecoderErrorOr<void> mv_probs(FrameContext const&);
     DecoderErrorOr<u8> update_mv_prob(u8 prob);
     void setup_compound_reference_mode(FrameContext&);
 
     /* (6.4) Decode Tiles Syntax */
     DecoderErrorOr<void> decode_tiles(FrameContext&);
     void clear_above_context(FrameContext&);
     u32 get_tile_offset(u32 tile_num, u32 mis, u32 tile_size_log2);
     DecoderErrorOr<void> decode_tile(TileContext&);
     void clear_left_context(TileContext&);
     DecoderErrorOr<void> decode_partition(TileContext&, u32 row, u32 column, BlockSubsize subsize);
     DecoderErrorOr<void> decode_block(TileContext&, u32 row, u32 column, BlockSubsize subsize);
     DecoderErrorOr<void> mode_info(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<void> intra_frame_mode_info(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<void> set_intra_segment_id(BlockContext&);
     DecoderErrorOr<bool> read_should_skip_residuals(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     bool seg_feature_active(BlockContext const&, u8 feature);
     DecoderErrorOr<TXSize> read_tx_size(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context, bool allow_select);
     DecoderErrorOr<void> inter_frame_mode_info(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<void> set_inter_segment_id(BlockContext&);
     u8 get_segment_id(BlockContext const&);
     DecoderErrorOr<bool> read_is_inter(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<void> intra_block_mode_info(BlockContext&);
     DecoderErrorOr<void> inter_block_mode_info(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<void> read_ref_frames(BlockContext&, FrameBlockContext above_context, FrameBlockContext left_context);
     DecoderErrorOr<MotionVectorPair> get_motion_vector(BlockContext const&, BlockMotionVectorCandidates const&);
     DecoderErrorOr<MotionVector> read_motion_vector(BlockContext const&, BlockMotionVectorCandidates const&, u8 reference_index);
     DecoderErrorOr<i32> read_single_motion_vector_component(u8 component);
     DecoderErrorOr<bool> residual(BlockContext&, bool has_block_above, bool has_block_left);
     DecoderErrorOr<bool> tokens(BlockContext&, size_t plane, u32 x, u32 y, TXSize tx_size, u32 block_index);
     u32 const* get_scan(BlockContext const&, size_t plane, TXSize tx_size, u32 block_index);
     DecoderErrorOr<i32> read_coef(u8 bit_depth, Token token);
 
     /* (6.5) Motion Vector Prediction */
     MotionVectorPair find_reference_motion_vectors(BlockContext const&, ReferenceFrameType, i32 block);
     void select_best_sub_block_reference_motion_vectors(BlockContext const&, BlockMotionVectorCandidates&, i32 block, u8 ref_list);
     size_t get_image_index(FrameContext const&, u32 row, u32 column) const;
     MotionVectorCandidate get_motion_vector_from_current_or_previous_frame(BlockContext const&, MotionVector candidate_vector, u8 ref_list, bool use_prev);
     void add_motion_vector_if_reference_frame_type_is_same(BlockContext const&, MotionVector candidate_vector, ReferenceFrameType ref_frame, Vector<MotionVector, 2>& list, bool use_prev);
     void add_motion_vector_if_reference_frame_type_is_different(BlockContext const&, MotionVector candidate_vector, ReferenceFrameType ref_frame, Vector<MotionVector, 2>& list, bool use_prev);
 
     Gfx::Point<size_t> get_decoded_point_for_plane(FrameContext const&, u32 row, u32 column, u8 plane);
     Gfx::Size<size_t> get_decoded_size_for_plane(FrameContext const&, u8 plane);
 
     bool m_is_first_compute_image_size_invoke { true };
     Gfx::Size<u32> m_previous_frame_size { 0, 0 };
     bool m_previous_show_frame { false };
     ColorConfig m_previous_color_config;
     FrameType m_previous_frame_type { FrameType::KeyFrame };
     Array<i8, MAX_REF_FRAMES> m_previous_loop_filter_ref_deltas;
     Array<i8, 2> m_previous_loop_filter_mode_deltas;
     u8 m_segmentation_tree_probs[7];
     u8 m_segmentation_pred_prob[3];
     bool m_feature_enabled[8][4];
     u8 m_feature_data[8][4];
     bool m_segmentation_enabled { false };
     bool m_segmentation_update_map { false };
     bool m_segmentation_temporal_update { false };
     bool m_segmentation_abs_or_delta_update { false };
 
     // FIXME: Move above and left contexts to structs
     Array<Vector<bool>, 3> m_above_nonzero_context;
     Array<Vector<bool>, 3> m_left_nonzero_context;
     Vector<u8> m_above_seg_pred_context;
     Vector<u8> m_left_seg_pred_context;
     Vector<u8> m_above_partition_context;
     Vector<u8> m_left_partition_context;
 
     // FIXME: Move these to a struct to store together in one array.
     Gfx::Size<u32> m_ref_frame_size[NUM_REF_FRAMES];
     bool m_ref_subsampling_x[NUM_REF_FRAMES];
     bool m_ref_subsampling_y[NUM_REF_FRAMES];
     u8 m_ref_bit_depth[NUM_REF_FRAMES];
 
     Vector<u16> m_frame_store[NUM_REF_FRAMES][3];
 
     u8 m_tx_type { 0 };
     u8 m_token_cache[1024];
     i32 m_tokens[1024];
     bool m_use_hp { false };
     TXMode m_tx_mode;
     ReferenceMode m_reference_mode;
     ReferenceFrameType m_comp_fixed_ref;
     ReferenceFramePair m_comp_var_ref;
 
     bool m_use_prev_frame_mvs;
+    Vector2D<FrameBlockContext> m_reusable_frame_block_contexts;
     Vector2D<PersistentBlockContext> m_previous_block_contexts;
     // Indexed by ReferenceFrame enum.
     u8 m_mode_context[4] { INVALID_CASE };
 
     OwnPtr<BitStream> m_bit_stream;
     OwnPtr<ProbabilityTables> m_probability_tables;
     OwnPtr<SyntaxElementCounter> m_syntax_element_counter;
     Decoder& m_decoder;
 };
 
 }
