commit 869248c053856e654002f0650b02d22648b563ba
Author: Leo Izen <leo.izen@gmail.com>
Date:   Mon Apr 17 15:29:55 2023 -0400

    avcodec/mjpegdec: fix remaining RGB JPEGs
    
    The change introduced in b18a9c29713abc3a1b081de3f320ab53a47120c6
    created a regression for non-subsampled progressive RGB jpegs. This
    should fix that.
    
    Additionally, this should fix other RGB JPEGs broken before the recent
    patches, such as those in Trac issue #10190.

diff --git a/libavcodec/mjpegdec.c b/libavcodec/mjpegdec.c
index c41d4bce5e..9b55002c4b 100644
--- a/libavcodec/mjpegdec.c
+++ b/libavcodec/mjpegdec.c
@@ -300,490 +300,490 @@ int ff_mjpeg_decode_dht(MJpegDecodeContext *s)
 int ff_mjpeg_decode_sof(MJpegDecodeContext *s)
 {
     int len, nb_components, i, width, height, bits, ret, size_change;
     unsigned pix_fmt_id;
     int h_count[MAX_COMPONENTS] = { 0 };
     int v_count[MAX_COMPONENTS] = { 0 };
 
     s->cur_scan = 0;
     memset(s->upscale_h, 0, sizeof(s->upscale_h));
     memset(s->upscale_v, 0, sizeof(s->upscale_v));
 
     len     = get_bits(&s->gb, 16);
     bits    = get_bits(&s->gb, 8);
 
     if (bits > 16 || bits < 1) {
         av_log(s->avctx, AV_LOG_ERROR, "bits %d is invalid\n", bits);
         return AVERROR_INVALIDDATA;
     }
 
     if (s->avctx->bits_per_raw_sample != bits) {
         av_log(s->avctx, s->avctx->bits_per_raw_sample > 0 ? AV_LOG_INFO : AV_LOG_DEBUG, "Changing bps from %d to %d\n", s->avctx->bits_per_raw_sample, bits);
         s->avctx->bits_per_raw_sample = bits;
         init_idct(s->avctx);
     }
     if (s->pegasus_rct)
         bits = 9;
     if (bits == 9 && !s->pegasus_rct)
         s->rct  = 1;    // FIXME ugly
 
     if(s->lossless && s->avctx->lowres){
         av_log(s->avctx, AV_LOG_ERROR, "lowres is not possible with lossless jpeg\n");
         return -1;
     }
 
     height = get_bits(&s->gb, 16);
     width  = get_bits(&s->gb, 16);
 
     // HACK for odd_height.mov
     if (s->interlaced && s->width == width && s->height == height + 1)
         height= s->height;
 
     av_log(s->avctx, AV_LOG_DEBUG, "sof0: picture: %dx%d\n", width, height);
     if (av_image_check_size(width, height, 0, s->avctx) < 0)
         return AVERROR_INVALIDDATA;
     if (s->buf_size && (width + 7) / 8 * ((height + 7) / 8) > s->buf_size * 4LL)
         return AVERROR_INVALIDDATA;
 
     nb_components = get_bits(&s->gb, 8);
     if (nb_components <= 0 ||
         nb_components > MAX_COMPONENTS)
         return -1;
     if (s->interlaced && (s->bottom_field == !s->interlace_polarity)) {
         if (nb_components != s->nb_components) {
             av_log(s->avctx, AV_LOG_ERROR,
                    "nb_components changing in interlaced picture\n");
             return AVERROR_INVALIDDATA;
         }
     }
     if (s->ls && !(bits <= 8 || nb_components == 1)) {
         avpriv_report_missing_feature(s->avctx,
                                       "JPEG-LS that is not <= 8 "
                                       "bits/component or 16-bit gray");
         return AVERROR_PATCHWELCOME;
     }
     if (len != 8 + 3 * nb_components) {
         av_log(s->avctx, AV_LOG_ERROR, "decode_sof0: error, len(%d) mismatch %d components\n", len, nb_components);
         return AVERROR_INVALIDDATA;
     }
 
     s->nb_components = nb_components;
     s->h_max         = 1;
     s->v_max         = 1;
     for (i = 0; i < nb_components; i++) {
         /* component id */
         s->component_id[i] = get_bits(&s->gb, 8);
         h_count[i]         = get_bits(&s->gb, 4);
         v_count[i]         = get_bits(&s->gb, 4);
         /* compute hmax and vmax (only used in interleaved case) */
         if (h_count[i] > s->h_max)
             s->h_max = h_count[i];
         if (v_count[i] > s->v_max)
             s->v_max = v_count[i];
         s->quant_index[i] = get_bits(&s->gb, 8);
         if (s->quant_index[i] >= 4) {
             av_log(s->avctx, AV_LOG_ERROR, "quant_index is invalid\n");
             return AVERROR_INVALIDDATA;
         }
         if (!h_count[i] || !v_count[i]) {
             av_log(s->avctx, AV_LOG_ERROR,
                    "Invalid sampling factor in component %d %d:%d\n",
                    i, h_count[i], v_count[i]);
             return AVERROR_INVALIDDATA;
         }
 
         av_log(s->avctx, AV_LOG_DEBUG, "component %d %d:%d id: %d quant:%d\n",
                i, h_count[i], v_count[i],
                s->component_id[i], s->quant_index[i]);
     }
     if (   nb_components == 4
         && s->component_id[0] == 'C'
         && s->component_id[1] == 'M'
         && s->component_id[2] == 'Y'
         && s->component_id[3] == 'K')
         s->adobe_transform = 0;
 
     if (s->ls && (s->h_max > 1 || s->v_max > 1)) {
         avpriv_report_missing_feature(s->avctx, "Subsampling in JPEG-LS");
         return AVERROR_PATCHWELCOME;
     }
 
     if (s->bayer) {
         if (nb_components == 2) {
             /* Bayer images embedded in DNGs can contain 2 interleaved components and the
                width stored in their SOF3 markers is the width of each one.  We only output
                a single component, therefore we need to adjust the output image width.  We
                handle the deinterleaving (but not the debayering) in this file. */
             width *= 2;
         }
         /* They can also contain 1 component, which is double the width and half the height
             of the final image (rows are interleaved).  We don't handle the decoding in this
             file, but leave that to the TIFF/DNG decoder. */
     }
 
     /* if different size, realloc/alloc picture */
     if (width != s->width || height != s->height || bits != s->bits ||
         memcmp(s->h_count, h_count, sizeof(h_count))                ||
         memcmp(s->v_count, v_count, sizeof(v_count))) {
         size_change = 1;
 
         s->width      = width;
         s->height     = height;
         s->bits       = bits;
         memcpy(s->h_count, h_count, sizeof(h_count));
         memcpy(s->v_count, v_count, sizeof(v_count));
         s->interlaced = 0;
         s->got_picture = 0;
 
         /* test interlaced mode */
         if (s->first_picture   &&
             (s->multiscope != 2 || s->avctx->pkt_timebase.den >= 25 * s->avctx->pkt_timebase.num) &&
             s->orig_height != 0 &&
             s->height < ((s->orig_height * 3) / 4)) {
             s->interlaced                    = 1;
             s->bottom_field                  = s->interlace_polarity;
             s->picture_ptr->interlaced_frame = 1;
             s->picture_ptr->top_field_first  = !s->interlace_polarity;
             height *= 2;
         }
 
         ret = ff_set_dimensions(s->avctx, width, height);
         if (ret < 0)
             return ret;
 
         if (s->avctx->codec_id != AV_CODEC_ID_SMVJPEG &&
             (s->avctx->codec_tag == MKTAG('A', 'V', 'R', 'n') ||
              s->avctx->codec_tag == MKTAG('A', 'V', 'D', 'J')) &&
             s->orig_height < height)
             s->avctx->height = AV_CEIL_RSHIFT(s->orig_height, s->avctx->lowres);
 
         s->first_picture = 0;
     } else {
         size_change = 0;
     }
 
     if (s->avctx->codec_id == AV_CODEC_ID_SMVJPEG) {
         s->avctx->height = s->avctx->coded_height / s->smv_frames_per_jpeg;
         if (s->avctx->height <= 0)
             return AVERROR_INVALIDDATA;
     }
 
     if (s->got_picture && s->interlaced && (s->bottom_field == !s->interlace_polarity)) {
         if (s->progressive) {
             avpriv_request_sample(s->avctx, "progressively coded interlaced picture");
             return AVERROR_INVALIDDATA;
         }
     } else {
         if (s->v_max == 1 && s->h_max == 1 && s->lossless==1 && (nb_components==3 || nb_components==4))
             s->rgb = 1;
         else if (!s->lossless)
             s->rgb = 0;
         /* XXX: not complete test ! */
         pix_fmt_id = ((unsigned)s->h_count[0] << 28) | (s->v_count[0] << 24) |
                      (s->h_count[1] << 20) | (s->v_count[1] << 16) |
                      (s->h_count[2] << 12) | (s->v_count[2] <<  8) |
                      (s->h_count[3] <<  4) |  s->v_count[3];
         av_log(s->avctx, AV_LOG_DEBUG, "pix fmt id %x\n", pix_fmt_id);
         /* NOTE we do not allocate pictures large enough for the possible
          * padding of h/v_count being 4 */
         if (!(pix_fmt_id & 0xD0D0D0D0))
             pix_fmt_id -= (pix_fmt_id & 0xF0F0F0F0) >> 1;
         if (!(pix_fmt_id & 0x0D0D0D0D))
             pix_fmt_id -= (pix_fmt_id & 0x0F0F0F0F) >> 1;
 
         for (i = 0; i < 8; i++) {
             int j = 6 + (i&1) - (i&6);
             int is = (pix_fmt_id >> (4*i)) & 0xF;
             int js = (pix_fmt_id >> (4*j)) & 0xF;
 
             if (is == 1 && js != 2 && (i < 2 || i > 5))
                 js = (pix_fmt_id >> ( 8 + 4*(i&1))) & 0xF;
             if (is == 1 && js != 2 && (i < 2 || i > 5))
                 js = (pix_fmt_id >> (16 + 4*(i&1))) & 0xF;
 
             if (is == 1 && js == 2) {
                 if (i & 1) s->upscale_h[j/2] = 1;
                 else       s->upscale_v[j/2] = 1;
             }
         }
 
         if (s->bayer) {
             if (pix_fmt_id != 0x11110000 && pix_fmt_id != 0x11000000)
                 goto unk_pixfmt;
         }
 
         switch (pix_fmt_id) {
         case 0x11110000: /* for bayer-encoded huffman lossless JPEGs embedded in DNGs */
             if (!s->bayer)
                 goto unk_pixfmt;
             s->avctx->pix_fmt = AV_PIX_FMT_GRAY16LE;
             break;
         case 0x11111100:
             if (s->rgb)
                 s->avctx->pix_fmt = s->bits <= 9 ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_BGR48;
             else {
                 if (   s->adobe_transform == 0
                     || s->component_id[0] == 'R' && s->component_id[1] == 'G' && s->component_id[2] == 'B') {
                     s->avctx->pix_fmt = s->bits <= 8 ? AV_PIX_FMT_GBRP : AV_PIX_FMT_GBRP16;
                 } else {
                     if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;
                     else              s->avctx->pix_fmt = AV_PIX_FMT_YUV444P16;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
                 }
             }
             av_assert0(s->nb_components == 3);
             break;
         case 0x11111111:
             if (s->rgb)
                 s->avctx->pix_fmt = s->bits <= 9 ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA64;
             else {
                 if (s->adobe_transform == 0 && s->bits <= 8) {
                     s->avctx->pix_fmt = AV_PIX_FMT_GBRAP;
                 } else {
                     s->avctx->pix_fmt = s->bits <= 8 ? AV_PIX_FMT_YUVA444P : AV_PIX_FMT_YUVA444P16;
                     s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
                 }
             }
             av_assert0(s->nb_components == 4);
             break;
         case 0x22111122:
         case 0x22111111:
             if (s->adobe_transform == 0 && s->bits <= 8) {
                 s->avctx->pix_fmt = AV_PIX_FMT_GBRAP;
                 s->upscale_v[1] = s->upscale_v[2] = 1;
                 s->upscale_h[1] = s->upscale_h[2] = 1;
             } else if (s->adobe_transform == 2 && s->bits <= 8) {
                 s->avctx->pix_fmt = AV_PIX_FMT_YUVA444P;
                 s->upscale_v[1] = s->upscale_v[2] = 1;
                 s->upscale_h[1] = s->upscale_h[2] = 1;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             } else {
                 if (s->bits <= 8) s->avctx->pix_fmt = AV_PIX_FMT_YUVA420P;
                 else              s->avctx->pix_fmt = AV_PIX_FMT_YUVA420P16;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             }
             av_assert0(s->nb_components == 4);
             break;
         case 0x12121100:
         case 0x22122100:
         case 0x21211100:
         case 0x21112100:
         case 0x22211200:
         case 0x22221100:
         case 0x22112200:
         case 0x11222200:
             if (s->bits > 8)
                 goto unk_pixfmt;
             if (s->adobe_transform == 0 || s->component_id[0] == 'R' &&
                     s->component_id[1] == 'G' && s->component_id[2] == 'B') {
                 s->avctx->pix_fmt = AV_PIX_FMT_GBRP;
             } else {
                 s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             }
             break;
         case 0x11000000:
         case 0x13000000:
         case 0x14000000:
         case 0x31000000:
         case 0x33000000:
         case 0x34000000:
         case 0x41000000:
         case 0x43000000:
         case 0x44000000:
             if(s->bits <= 8)
                 s->avctx->pix_fmt = s->force_pal8 ? AV_PIX_FMT_PAL8 : AV_PIX_FMT_GRAY8;
             else
                 s->avctx->pix_fmt = AV_PIX_FMT_GRAY16;
             break;
         case 0x12111100:
         case 0x14121200:
         case 0x14111100:
         case 0x22211100:
         case 0x22112100:
             if (s->component_id[0] == 'R' && s->component_id[1] == 'G' && s->component_id[2] == 'B') {
                 if (s->bits <= 8) s->avctx->pix_fmt = AV_PIX_FMT_GBRP;
                 else
                     goto unk_pixfmt;
-                s->upscale_v[0] = s->upscale_v[1] = 1;
+                s->upscale_v[1] = s->upscale_v[2] = 1;
             } else {
                 if (pix_fmt_id == 0x14111100)
                     s->upscale_v[1] = s->upscale_v[2] = 1;
                 if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P;
                 else
                     goto unk_pixfmt;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             }
             break;
         case 0x21111100:
             if (s->component_id[0] == 'R' && s->component_id[1] == 'G' && s->component_id[2] == 'B') {
                 if (s->bits <= 8) s->avctx->pix_fmt = AV_PIX_FMT_GBRP;
                 else
                     goto unk_pixfmt;
-                s->upscale_h[0] = s->upscale_h[1] = 1;
+                s->upscale_h[1] = s->upscale_h[2] = 1;
             } else {
                 if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P;
                 else              s->avctx->pix_fmt = AV_PIX_FMT_YUV422P16;
                 s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             }
             break;
         case 0x31111100:
             if (s->bits > 8)
                 goto unk_pixfmt;
             s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;
             s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             s->upscale_h[1] = s->upscale_h[2] = 2;
             break;
         case 0x22121100:
         case 0x22111200:
             if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P;
             else
                 goto unk_pixfmt;
             s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             break;
         case 0x22111100:
         case 0x23111100:
         case 0x42111100:
         case 0x24111100:
             if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P;
             else              s->avctx->pix_fmt = AV_PIX_FMT_YUV420P16;
             s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             if (pix_fmt_id == 0x42111100) {
                 if (s->bits > 8)
                     goto unk_pixfmt;
                 s->upscale_h[1] = s->upscale_h[2] = 1;
             } else if (pix_fmt_id == 0x24111100) {
                 if (s->bits > 8)
                     goto unk_pixfmt;
                 s->upscale_v[1] = s->upscale_v[2] = 1;
             } else if (pix_fmt_id == 0x23111100) {
                 if (s->bits > 8)
                     goto unk_pixfmt;
                 s->upscale_v[1] = s->upscale_v[2] = 2;
             }
             break;
         case 0x41111100:
             if (s->bits <= 8) s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV411P : AV_PIX_FMT_YUVJ411P;
             else
                 goto unk_pixfmt;
             s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;
             break;
         default:
     unk_pixfmt:
             avpriv_report_missing_feature(s->avctx, "Pixel format 0x%x bits:%d", pix_fmt_id, s->bits);
             memset(s->upscale_h, 0, sizeof(s->upscale_h));
             memset(s->upscale_v, 0, sizeof(s->upscale_v));
             return AVERROR_PATCHWELCOME;
         }
         if ((AV_RB32(s->upscale_h) || AV_RB32(s->upscale_v)) && s->avctx->lowres) {
             avpriv_report_missing_feature(s->avctx, "Lowres for weird subsampling");
             return AVERROR_PATCHWELCOME;
         }
         if (s->ls) {
             memset(s->upscale_h, 0, sizeof(s->upscale_h));
             memset(s->upscale_v, 0, sizeof(s->upscale_v));
             if (s->nb_components == 3) {
                 s->avctx->pix_fmt = AV_PIX_FMT_RGB24;
             } else if (s->nb_components != 1) {
                 av_log(s->avctx, AV_LOG_ERROR, "Unsupported number of components %d\n", s->nb_components);
                 return AVERROR_PATCHWELCOME;
             } else if ((s->palette_index || s->force_pal8) && s->bits <= 8)
                 s->avctx->pix_fmt = AV_PIX_FMT_PAL8;
             else if (s->bits <= 8)
                 s->avctx->pix_fmt = AV_PIX_FMT_GRAY8;
             else
                 s->avctx->pix_fmt = AV_PIX_FMT_GRAY16;
         }
 
         s->pix_desc = av_pix_fmt_desc_get(s->avctx->pix_fmt);
         if (!s->pix_desc) {
             av_log(s->avctx, AV_LOG_ERROR, "Could not get a pixel format descriptor.\n");
             return AVERROR_BUG;
         }
 
         if (s->avctx->pix_fmt == s->hwaccel_sw_pix_fmt && !size_change) {
             s->avctx->pix_fmt = s->hwaccel_pix_fmt;
         } else {
             enum AVPixelFormat pix_fmts[] = {
 #if CONFIG_MJPEG_NVDEC_HWACCEL
                 AV_PIX_FMT_CUDA,
 #endif
 #if CONFIG_MJPEG_VAAPI_HWACCEL
                 AV_PIX_FMT_VAAPI,
 #endif
                 s->avctx->pix_fmt,
                 AV_PIX_FMT_NONE,
             };
             s->hwaccel_pix_fmt = ff_get_format(s->avctx, pix_fmts);
             if (s->hwaccel_pix_fmt < 0)
                 return AVERROR(EINVAL);
 
             s->hwaccel_sw_pix_fmt = s->avctx->pix_fmt;
             s->avctx->pix_fmt     = s->hwaccel_pix_fmt;
         }
 
         if (s->avctx->skip_frame == AVDISCARD_ALL) {
             s->picture_ptr->pict_type = AV_PICTURE_TYPE_I;
             s->picture_ptr->key_frame = 1;
             s->got_picture            = 1;
             return 0;
         }
 
         av_frame_unref(s->picture_ptr);
         if (ff_get_buffer(s->avctx, s->picture_ptr, AV_GET_BUFFER_FLAG_REF) < 0)
             return -1;
         s->picture_ptr->pict_type = AV_PICTURE_TYPE_I;
         s->picture_ptr->key_frame = 1;
         s->got_picture            = 1;
 
         // Lets clear the palette to avoid leaving uninitialized values in it
         if (s->avctx->pix_fmt == AV_PIX_FMT_PAL8)
             memset(s->picture_ptr->data[1], 0, 1024);
 
         for (i = 0; i < 4; i++)
             s->linesize[i] = s->picture_ptr->linesize[i] << s->interlaced;
 
         ff_dlog(s->avctx, "%d %d %d %d %d %d\n",
                 s->width, s->height, s->linesize[0], s->linesize[1],
                 s->interlaced, s->avctx->height);
 
     }
 
     if ((s->rgb && !s->lossless && !s->ls) ||
         (!s->rgb && s->ls && s->nb_components > 1) ||
         (s->avctx->pix_fmt == AV_PIX_FMT_PAL8 && !s->ls)
     ) {
         av_log(s->avctx, AV_LOG_ERROR, "Unsupported coding and pixel format combination\n");
         return AVERROR_PATCHWELCOME;
     }
 
     /* totally blank picture as progressive JPEG will only add details to it */
     if (s->progressive) {
         int bw = (width  + s->h_max * 8 - 1) / (s->h_max * 8);
         int bh = (height + s->v_max * 8 - 1) / (s->v_max * 8);
         for (i = 0; i < s->nb_components; i++) {
             int size = bw * bh * s->h_count[i] * s->v_count[i];
             av_freep(&s->blocks[i]);
             av_freep(&s->last_nnz[i]);
             s->blocks[i]       = av_calloc(size, sizeof(**s->blocks));
             s->last_nnz[i]     = av_calloc(size, sizeof(**s->last_nnz));
             if (!s->blocks[i] || !s->last_nnz[i])
                 return AVERROR(ENOMEM);
             s->block_stride[i] = bw * s->h_count[i];
         }
         memset(s->coefs_finished, 0, sizeof(s->coefs_finished));
     }
 
     if (s->avctx->hwaccel) {
         s->hwaccel_picture_private =
             av_mallocz(s->avctx->hwaccel->frame_priv_data_size);
         if (!s->hwaccel_picture_private)
             return AVERROR(ENOMEM);
 
         ret = s->avctx->hwaccel->start_frame(s->avctx, s->raw_image_buffer,
                                              s->raw_image_buffer_size);
         if (ret < 0)
             return ret;
     }
 
     return 0;
 }
@@ -1643,105 +1643,102 @@ static void mjpeg_idct_scan_progressive_ac(MJpegDecodeContext *s)
 int ff_mjpeg_decode_sos(MJpegDecodeContext *s, const uint8_t *mb_bitmask,
                         int mb_bitmask_size, const AVFrame *reference)
 {
     int len, nb_components, i, h, v, predictor, point_transform;
     int index, id, ret;
     const int block_size = s->lossless ? 1 : 8;
     int ilv, prev_shift;
 
     if (!s->got_picture) {
         av_log(s->avctx, AV_LOG_WARNING,
                 "Can not process SOS before SOF, skipping\n");
         return -1;
     }
 
     if (reference) {
         if (reference->width  != s->picture_ptr->width  ||
             reference->height != s->picture_ptr->height ||
             reference->format != s->picture_ptr->format) {
             av_log(s->avctx, AV_LOG_ERROR, "Reference mismatching\n");
             return AVERROR_INVALIDDATA;
         }
     }
 
     /* XXX: verify len field validity */
     len = get_bits(&s->gb, 16);
     nb_components = get_bits(&s->gb, 8);
     if (nb_components == 0 || nb_components > MAX_COMPONENTS) {
         avpriv_report_missing_feature(s->avctx,
                                       "decode_sos: nb_components (%d)",
                                       nb_components);
         return AVERROR_PATCHWELCOME;
     }
     if (len != 6 + 2 * nb_components) {
         av_log(s->avctx, AV_LOG_ERROR, "decode_sos: invalid len (%d)\n", len);
         return AVERROR_INVALIDDATA;
     }
     for (i = 0; i < nb_components; i++) {
         id = get_bits(&s->gb, 8);
         av_log(s->avctx, AV_LOG_DEBUG, "component: %d\n", id);
         /* find component index */
         for (index = 0; index < s->nb_components; index++)
             if (id == s->component_id[index])
                 break;
         if (index == s->nb_components) {
             av_log(s->avctx, AV_LOG_ERROR,
                    "decode_sos: index(%d) out of components\n", index);
             return AVERROR_INVALIDDATA;
         }
         /* Metasoft MJPEG codec has Cb and Cr swapped */
         if (s->avctx->codec_tag == MKTAG('M', 'T', 'S', 'J')
             && nb_components == 3 && s->nb_components == 3 && i)
             index = 3 - i;
 
         s->quant_sindex[i] = s->quant_index[index];
         s->nb_blocks[i] = s->h_count[index] * s->v_count[index];
         s->h_scount[i]  = s->h_count[index];
         s->v_scount[i]  = s->v_count[index];
 
-        if(nb_components == 3 && s->nb_components == 3 && s->avctx->pix_fmt == AV_PIX_FMT_GBRP)
-            index = (index+2)%3;
-
         s->comp_index[i] = index;
 
         s->dc_index[i] = get_bits(&s->gb, 4);
         s->ac_index[i] = get_bits(&s->gb, 4);
 
         if (s->dc_index[i] <  0 || s->ac_index[i] < 0 ||
             s->dc_index[i] >= 4 || s->ac_index[i] >= 4)
             goto out_of_range;
         if (!s->vlcs[0][s->dc_index[i]].table || !(s->progressive ? s->vlcs[2][s->ac_index[0]].table : s->vlcs[1][s->ac_index[i]].table))
             goto out_of_range;
     }
 
     predictor = get_bits(&s->gb, 8);       /* JPEG Ss / lossless JPEG predictor /JPEG-LS NEAR */
     ilv = get_bits(&s->gb, 8);             /* JPEG Se / JPEG-LS ILV */
     if(s->avctx->codec_tag != AV_RL32("CJPG")){
         prev_shift      = get_bits(&s->gb, 4); /* Ah */
         point_transform = get_bits(&s->gb, 4); /* Al */
     }else
         prev_shift = point_transform = 0;
 
     if (nb_components > 1) {
         /* interleaved stream */
         s->mb_width  = (s->width  + s->h_max * block_size - 1) / (s->h_max * block_size);
         s->mb_height = (s->height + s->v_max * block_size - 1) / (s->v_max * block_size);
     } else if (!s->ls) { /* skip this for JPEG-LS */
         h = s->h_max / s->h_scount[0];
         v = s->v_max / s->v_scount[0];
         s->mb_width     = (s->width  + h * block_size - 1) / (h * block_size);
         s->mb_height    = (s->height + v * block_size - 1) / (v * block_size);
         s->nb_blocks[0] = 1;
         s->h_scount[0]  = 1;
         s->v_scount[0]  = 1;
     }
 
     if (s->avctx->debug & FF_DEBUG_PICT_INFO)
         av_log(s->avctx, AV_LOG_DEBUG, "%s %s p:%d >>:%d ilv:%d bits:%d skip:%d %s comp:%d\n",
                s->lossless ? "lossless" : "sequential DCT", s->rgb ? "RGB" : "",
                predictor, point_transform, ilv, s->bits, s->mjpb_skiptosod,
                s->pegasus_rct ? "PRCT" : (s->rct ? "RCT" : ""), nb_components);
 
 
     /* mjpeg-b can have padding bytes between sos and image data, skip them */
     for (i = s->mjpb_skiptosod; i > 0; i--)
         skip_bits(&s->gb, 8);
@@ -2598,277 +2595,277 @@ fail:
     s->got_picture = 0;
     return ret;
 the_end:
 
     is16bit = av_pix_fmt_desc_get(s->avctx->pix_fmt)->comp[0].step > 1;
 
     if (AV_RB32(s->upscale_h)) {
         int p;
         av_assert0(avctx->pix_fmt == AV_PIX_FMT_YUVJ444P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV444P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVJ440P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV440P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA444P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVJ420P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV420P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV420P16||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA420P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA420P16||
                    avctx->pix_fmt == AV_PIX_FMT_GBRP     ||
                    avctx->pix_fmt == AV_PIX_FMT_GBRAP
                   );
         ret = av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);
         if (ret)
             return ret;
 
         av_assert0(s->nb_components == av_pix_fmt_count_planes(s->picture_ptr->format));
         for (p = 0; p<s->nb_components; p++) {
             uint8_t *line = s->picture_ptr->data[p];
             int w = s->width;
             int h = s->height;
             if (!s->upscale_h[p])
                 continue;
             if (p==1 || p==2) {
                 w = AV_CEIL_RSHIFT(w, hshift);
                 h = AV_CEIL_RSHIFT(h, vshift);
             }
             if (s->upscale_v[p] == 1)
                 h = (h+1)>>1;
             av_assert0(w > 0);
             for (i = 0; i < h; i++) {
                 if (s->upscale_h[p] == 1) {
                     if (is16bit) ((uint16_t*)line)[w - 1] = ((uint16_t*)line)[(w - 1) / 2];
                     else                      line[w - 1] = line[(w - 1) / 2];
                     for (index = w - 2; index > 0; index--) {
                         if (is16bit)
                             ((uint16_t*)line)[index] = (((uint16_t*)line)[index / 2] + ((uint16_t*)line)[(index + 1) / 2]) >> 1;
                         else
                             line[index] = (line[index / 2] + line[(index + 1) / 2]) >> 1;
                     }
                 } else if (s->upscale_h[p] == 2) {
                     if (is16bit) {
                         ((uint16_t*)line)[w - 1] = ((uint16_t*)line)[(w - 1) / 3];
                         if (w > 1)
                             ((uint16_t*)line)[w - 2] = ((uint16_t*)line)[w - 1];
                     } else {
                         line[w - 1] = line[(w - 1) / 3];
                         if (w > 1)
                             line[w - 2] = line[w - 1];
                     }
                     for (index = w - 3; index > 0; index--) {
                         line[index] = (line[index / 3] + line[(index + 1) / 3] + line[(index + 2) / 3] + 1) / 3;
                     }
                 }
                 line += s->linesize[p];
             }
         }
     }
     if (AV_RB32(s->upscale_v)) {
         int p;
         av_assert0(avctx->pix_fmt == AV_PIX_FMT_YUVJ444P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV444P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVJ422P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV422P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVJ420P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV420P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUV440P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVJ440P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA444P ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA420P  ||
                    avctx->pix_fmt == AV_PIX_FMT_YUVA420P16||
                    avctx->pix_fmt == AV_PIX_FMT_GBRP     ||
                    avctx->pix_fmt == AV_PIX_FMT_GBRAP
                    );
         ret = av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);
         if (ret)
             return ret;
 
         av_assert0(s->nb_components == av_pix_fmt_count_planes(s->picture_ptr->format));
         for (p = 0; p < s->nb_components; p++) {
             uint8_t *dst;
             int w = s->width;
             int h = s->height;
             if (!s->upscale_v[p])
                 continue;
             if (p==1 || p==2) {
                 w = AV_CEIL_RSHIFT(w, hshift);
                 h = AV_CEIL_RSHIFT(h, vshift);
             }
             dst = &((uint8_t *)s->picture_ptr->data[p])[(h - 1) * s->linesize[p]];
             for (i = h - 1; i; i--) {
                 uint8_t *src1 = &((uint8_t *)s->picture_ptr->data[p])[i * s->upscale_v[p] / (s->upscale_v[p] + 1) * s->linesize[p]];
                 uint8_t *src2 = &((uint8_t *)s->picture_ptr->data[p])[(i + 1) * s->upscale_v[p] / (s->upscale_v[p] + 1) * s->linesize[p]];
                 if (s->upscale_v[p] != 2 && (src1 == src2 || i == h - 1)) {
                     memcpy(dst, src1, w);
                 } else {
                     for (index = 0; index < w; index++)
                         dst[index] = (src1[index] + src2[index]) >> 1;
                 }
                 dst -= s->linesize[p];
             }
         }
     }
     if (s->flipped && !s->rgb) {
         ret = av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);
         if (ret)
             return ret;
 
         av_assert0(s->nb_components == av_pix_fmt_count_planes(frame->format));
         for (index=0; index<s->nb_components; index++) {
             int h = frame->height;
             if (index && index < 3)
                 h = AV_CEIL_RSHIFT(h, vshift);
             if (frame->data[index]) {
                 frame->data[index]     += (h - 1) * frame->linesize[index];
                 frame->linesize[index] *= -1;
             }
         }
     }
 
-    if (s->avctx->pix_fmt == AV_PIX_FMT_GBRP && s->progressive) {
+    if (s->avctx->pix_fmt == AV_PIX_FMT_GBRP) {
         av_assert0(s->nb_components == 3);
         FFSWAP(uint8_t *, frame->data[0], frame->data[2]);
         FFSWAP(uint8_t *, frame->data[0], frame->data[1]);
         FFSWAP(int, frame->linesize[0], frame->linesize[2]);
         FFSWAP(int, frame->linesize[0], frame->linesize[1]);
     }
 
     if (s->adobe_transform == 0 && s->avctx->pix_fmt == AV_PIX_FMT_GBRAP) {
         int w = s->picture_ptr->width;
         int h = s->picture_ptr->height;
         av_assert0(s->nb_components == 4);
         for (i=0; i<h; i++) {
             int j;
             uint8_t *dst[4];
             for (index=0; index<4; index++) {
                 dst[index] =   s->picture_ptr->data[index]
                              + s->picture_ptr->linesize[index]*i;
             }
             for (j=0; j<w; j++) {
                 int k = dst[3][j];
                 int r = dst[0][j] * k;
                 int g = dst[1][j] * k;
                 int b = dst[2][j] * k;
                 dst[0][j] = g*257 >> 16;
                 dst[1][j] = b*257 >> 16;
                 dst[2][j] = r*257 >> 16;
                 dst[3][j] = 255;
             }
         }
     }
     if (s->adobe_transform == 2 && s->avctx->pix_fmt == AV_PIX_FMT_YUVA444P) {
         int w = s->picture_ptr->width;
         int h = s->picture_ptr->height;
         av_assert0(s->nb_components == 4);
         for (i=0; i<h; i++) {
             int j;
             uint8_t *dst[4];
             for (index=0; index<4; index++) {
                 dst[index] =   s->picture_ptr->data[index]
                              + s->picture_ptr->linesize[index]*i;
             }
             for (j=0; j<w; j++) {
                 int k = dst[3][j];
                 int r = (255 - dst[0][j]) * k;
                 int g = (128 - dst[1][j]) * k;
                 int b = (128 - dst[2][j]) * k;
                 dst[0][j] = r*257 >> 16;
                 dst[1][j] = (g*257 >> 16) + 128;
                 dst[2][j] = (b*257 >> 16) + 128;
                 dst[3][j] = 255;
             }
         }
     }
 
     if (s->stereo3d) {
         AVStereo3D *stereo = av_stereo3d_create_side_data(frame);
         if (stereo) {
             stereo->type  = s->stereo3d->type;
             stereo->flags = s->stereo3d->flags;
         }
         av_freep(&s->stereo3d);
     }
 
     if (s->iccnum != 0 && s->iccnum == s->iccread) {
         AVFrameSideData *sd;
         size_t offset = 0;
         int total_size = 0;
         int i;
 
         /* Sum size of all parts. */
         for (i = 0; i < s->iccnum; i++)
             total_size += s->iccentries[i].length;
 
         sd = av_frame_new_side_data(frame, AV_FRAME_DATA_ICC_PROFILE, total_size);
         if (!sd) {
             av_log(s->avctx, AV_LOG_ERROR, "Could not allocate frame side data\n");
             return AVERROR(ENOMEM);
         }
 
         /* Reassemble the parts, which are now in-order. */
         for (i = 0; i < s->iccnum; i++) {
             memcpy(sd->data + offset, s->iccentries[i].data, s->iccentries[i].length);
             offset += s->iccentries[i].length;
         }
     }
 
     if (e = av_dict_get(s->exif_metadata, "Orientation", e, AV_DICT_IGNORE_SUFFIX)) {
         char *value = e->value + strspn(e->value, " \n\t\r"), *endptr;
         int orientation = strtol(value, &endptr, 0);
 
         if (!*endptr) {
             AVFrameSideData *sd = NULL;
 
             if (orientation >= 2 && orientation <= 8) {
                 int32_t *matrix;
 
                 sd = av_frame_new_side_data(frame, AV_FRAME_DATA_DISPLAYMATRIX, sizeof(int32_t) * 9);
                 if (!sd) {
                     av_log(s->avctx, AV_LOG_ERROR, "Could not allocate frame side data\n");
                     return AVERROR(ENOMEM);
                 }
 
                 matrix = (int32_t *)sd->data;
 
                 switch (orientation) {
                 case 2:
                     av_display_rotation_set(matrix, 0.0);
                     av_display_matrix_flip(matrix, 1, 0);
                     break;
                 case 3:
                     av_display_rotation_set(matrix, 180.0);
                     break;
                 case 4:
                     av_display_rotation_set(matrix, 180.0);
                     av_display_matrix_flip(matrix, 1, 0);
                     break;
                 case 5:
                     av_display_rotation_set(matrix, 90.0);
                     av_display_matrix_flip(matrix, 1, 0);
                     break;
                 case 6:
                     av_display_rotation_set(matrix, 90.0);
                     break;
                 case 7:
                     av_display_rotation_set(matrix, -90.0);
                     av_display_matrix_flip(matrix, 1, 0);
                     break;
                 case 8:
                     av_display_rotation_set(matrix, -90.0);
                     break;
                 default:
                     av_assert0(0);
                 }
             }
         }
     }
 
     av_dict_copy(&frame->metadata, s->exif_metadata, 0);
     av_dict_free(&s->exif_metadata);
 
     if (avctx->codec_id != AV_CODEC_ID_SMVJPEG &&
         (avctx->codec_tag == MKTAG('A', 'V', 'R', 'n') ||
          avctx->codec_tag == MKTAG('A', 'V', 'D', 'J')) &&
         avctx->coded_height > s->orig_height) {
         frame->height   = AV_CEIL_RSHIFT(avctx->coded_height, avctx->lowres);
         frame->crop_top = frame->height - avctx->height;
     }
