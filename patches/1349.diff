commit c4b08c8a4e54b752641d0792d9a73e16e62a0bbc
Author: James Almer <jamrial@gmail.com>
Date:   Sat Apr 29 22:01:03 2017 -0300

    avcodec/hevcdec: remove HEVCContext usage from hevc_sei
    
    Based on the H264 SEI implementation.
    
    Reviewed-by: Hendrik Leppkes <h.leppkes@gmail.com>
    Reviewed-by: Aaron Levinson <alevinsn@aracnet.com>
    Signed-off-by: James Almer <jamrial@gmail.com>

diff --git a/libavcodec/hevc_parser.c b/libavcodec/hevc_parser.c
index 310428d0ff..f82f9fdf5e 100644
--- a/libavcodec/hevc_parser.c
+++ b/libavcodec/hevc_parser.c
@@ -178,227 +178,228 @@ static int hevc_find_frame_end(AVCodecParserContext *s, const uint8_t *buf,
 #if ADVANCED_PARSER
 /**
  * Parse NAL units of found picture and decode some basic information.
  *
  * @param s parser context.
  * @param avctx codec context.
  * @param buf buffer with field/frame data.
  * @param buf_size size of the buffer.
  */
 static inline int parse_nal_units(AVCodecParserContext *s, const uint8_t *buf,
                            int buf_size, AVCodecContext *avctx)
 {
     HEVCParserContext *ctx = s->priv_data;
     HEVCContext       *h   = &ctx->h;
     GetBitContext      *gb;
     SliceHeader        *sh = &h->sh;
     HEVCParamSets *ps = &h->ps;
+    HEVCSEIContext *sei = &h->sei;
     H2645Packet   *pkt = &ctx->pkt;
     const uint8_t *buf_end = buf + buf_size;
     int state = -1, i;
     H2645NAL *nal;
     int is_global = buf == avctx->extradata;
 
     if (!h->HEVClc)
         h->HEVClc = av_mallocz(sizeof(HEVCLocalContext));
     if (!h->HEVClc)
         return AVERROR(ENOMEM);
 
     gb = &h->HEVClc->gb;
 
     /* set some sane default values */
     s->pict_type         = AV_PICTURE_TYPE_I;
     s->key_frame         = 0;
     s->picture_structure = AV_PICTURE_STRUCTURE_UNKNOWN;
 
     h->avctx = avctx;
 
-    ff_hevc_reset_sei(h);
+    ff_hevc_reset_sei(sei);
 
     if (!buf_size)
         return 0;
 
     if (pkt->nals_allocated < 1) {
         H2645NAL *tmp = av_realloc_array(pkt->nals, 1, sizeof(*tmp));
         if (!tmp)
             return AVERROR(ENOMEM);
         pkt->nals = tmp;
         memset(pkt->nals, 0, sizeof(*tmp));
         pkt->nals_allocated = 1;
     }
 
     nal = &pkt->nals[0];
 
     for (;;) {
         int src_length, consumed;
         int ret;
         int num = 0, den = 0;
         buf = avpriv_find_start_code(buf, buf_end, &state);
         if (--buf + 2 >= buf_end)
             break;
         src_length = buf_end - buf;
 
         h->nal_unit_type = (*buf >> 1) & 0x3f;
         h->temporal_id   = (*(buf + 1) & 0x07) - 1;
         if (h->nal_unit_type <= HEVC_NAL_CRA_NUT) {
             // Do not walk the whole buffer just to decode slice segment header
             if (src_length > 20)
                 src_length = 20;
         }
 
         consumed = ff_h2645_extract_rbsp(buf, src_length, nal, 1);
         if (consumed < 0)
             return consumed;
 
         ret = init_get_bits8(gb, nal->data + 2, nal->size);
         if (ret < 0)
             return ret;
 
         switch (h->nal_unit_type) {
         case HEVC_NAL_VPS:
             ff_hevc_decode_nal_vps(gb, avctx, ps);
             break;
         case HEVC_NAL_SPS:
             ff_hevc_decode_nal_sps(gb, avctx, ps, 1);
             break;
         case HEVC_NAL_PPS:
             ff_hevc_decode_nal_pps(gb, avctx, ps);
             break;
         case HEVC_NAL_SEI_PREFIX:
         case HEVC_NAL_SEI_SUFFIX:
-            ff_hevc_decode_nal_sei(h);
+            ff_hevc_decode_nal_sei(gb, avctx, sei, ps, h->nal_unit_type);
             break;
         case HEVC_NAL_TRAIL_N:
         case HEVC_NAL_TRAIL_R:
         case HEVC_NAL_TSA_N:
         case HEVC_NAL_TSA_R:
         case HEVC_NAL_STSA_N:
         case HEVC_NAL_STSA_R:
         case HEVC_NAL_RADL_N:
         case HEVC_NAL_RADL_R:
         case HEVC_NAL_RASL_N:
         case HEVC_NAL_RASL_R:
         case HEVC_NAL_BLA_W_LP:
         case HEVC_NAL_BLA_W_RADL:
         case HEVC_NAL_BLA_N_LP:
         case HEVC_NAL_IDR_W_RADL:
         case HEVC_NAL_IDR_N_LP:
         case HEVC_NAL_CRA_NUT:
 
             if (is_global) {
                 av_log(avctx, AV_LOG_ERROR, "Invalid NAL unit: %d\n", h->nal_unit_type);
                 return AVERROR_INVALIDDATA;
             }
 
             sh->first_slice_in_pic_flag = get_bits1(gb);
-            s->picture_structure = h->picture_struct;
-            s->field_order = h->picture_struct;
+            s->picture_structure = h->sei.picture_timing.picture_struct;
+            s->field_order = h->sei.picture_timing.picture_struct;
 
             if (IS_IRAP(h)) {
                 s->key_frame = 1;
                 sh->no_output_of_prior_pics_flag = get_bits1(gb);
             }
 
             sh->pps_id = get_ue_golomb(gb);
             if (sh->pps_id >= HEVC_MAX_PPS_COUNT || !ps->pps_list[sh->pps_id]) {
                 av_log(avctx, AV_LOG_ERROR, "PPS id out of range: %d\n", sh->pps_id);
                 return AVERROR_INVALIDDATA;
             }
             ps->pps = (HEVCPPS*)ps->pps_list[sh->pps_id]->data;
 
             if (ps->pps->sps_id >= HEVC_MAX_SPS_COUNT || !ps->sps_list[ps->pps->sps_id]) {
                 av_log(avctx, AV_LOG_ERROR, "SPS id out of range: %d\n", ps->pps->sps_id);
                 return AVERROR_INVALIDDATA;
             }
             if (ps->sps != (HEVCSPS*)ps->sps_list[ps->pps->sps_id]->data) {
                 ps->sps = (HEVCSPS*)ps->sps_list[ps->pps->sps_id]->data;
                 ps->vps = (HEVCVPS*)ps->vps_list[ps->sps->vps_id]->data;
             }
 
             s->coded_width  = ps->sps->width;
             s->coded_height = ps->sps->height;
             s->width        = ps->sps->output_width;
             s->height       = ps->sps->output_height;
             s->format       = ps->sps->pix_fmt;
             avctx->profile  = ps->sps->ptl.general_ptl.profile_idc;
             avctx->level    = ps->sps->ptl.general_ptl.level_idc;
 
             if (ps->vps->vps_timing_info_present_flag) {
                 num = ps->vps->vps_num_units_in_tick;
                 den = ps->vps->vps_time_scale;
             } else if (ps->sps->vui.vui_timing_info_present_flag) {
                 num = ps->sps->vui.vui_num_units_in_tick;
                 den = ps->sps->vui.vui_time_scale;
             }
 
             if (num != 0 && den != 0)
                 av_reduce(&avctx->framerate.den, &avctx->framerate.num,
                           num, den, 1 << 30);
 
             if (!sh->first_slice_in_pic_flag) {
                 int slice_address_length;
 
                 if (ps->pps->dependent_slice_segments_enabled_flag)
                     sh->dependent_slice_segment_flag = get_bits1(gb);
                 else
                     sh->dependent_slice_segment_flag = 0;
 
                 slice_address_length = av_ceil_log2_c(ps->sps->ctb_width *
                                                       ps->sps->ctb_height);
                 sh->slice_segment_addr = get_bitsz(gb, slice_address_length);
                 if (sh->slice_segment_addr >= ps->sps->ctb_width * ps->sps->ctb_height) {
                     av_log(avctx, AV_LOG_ERROR, "Invalid slice segment address: %u.\n",
                            sh->slice_segment_addr);
                     return AVERROR_INVALIDDATA;
                 }
             } else
                 sh->dependent_slice_segment_flag = 0;
 
             if (sh->dependent_slice_segment_flag)
                 break;
 
             for (i = 0; i < ps->pps->num_extra_slice_header_bits; i++)
                 skip_bits(gb, 1); // slice_reserved_undetermined_flag[]
 
             sh->slice_type = get_ue_golomb(gb);
             if (!(sh->slice_type == HEVC_SLICE_I || sh->slice_type == HEVC_SLICE_P ||
                   sh->slice_type == HEVC_SLICE_B)) {
                 av_log(avctx, AV_LOG_ERROR, "Unknown slice type: %d.\n",
                        sh->slice_type);
                 return AVERROR_INVALIDDATA;
             }
             s->pict_type = sh->slice_type == HEVC_SLICE_B ? AV_PICTURE_TYPE_B :
                            sh->slice_type == HEVC_SLICE_P ? AV_PICTURE_TYPE_P :
                                                        AV_PICTURE_TYPE_I;
 
             if (ps->pps->output_flag_present_flag)
                 sh->pic_output_flag = get_bits1(gb);
 
             if (ps->sps->separate_colour_plane_flag)
                 sh->colour_plane_id = get_bits(gb, 2);
 
             if (!IS_IDR(h)) {
                 sh->pic_order_cnt_lsb = get_bits(gb, ps->sps->log2_max_poc_lsb);
                 s->output_picture_number = h->poc = ff_hevc_compute_poc(h, sh->pic_order_cnt_lsb);
             } else
                 s->output_picture_number = h->poc = 0;
 
             if (h->temporal_id == 0 &&
                 h->nal_unit_type != HEVC_NAL_TRAIL_N &&
                 h->nal_unit_type != HEVC_NAL_TSA_N &&
                 h->nal_unit_type != HEVC_NAL_STSA_N &&
                 h->nal_unit_type != HEVC_NAL_RADL_N &&
                 h->nal_unit_type != HEVC_NAL_RASL_N &&
                 h->nal_unit_type != HEVC_NAL_RADL_R &&
                 h->nal_unit_type != HEVC_NAL_RASL_R)
                 h->pocTid0 = h->poc;
 
             return 0; /* no need to evaluate the rest */
         }
         buf += consumed;
     }
     /* didn't find a picture! */
     if (!is_global)
         av_log(h->avctx, AV_LOG_ERROR, "missing picture in access unit\n");
     return -1;
 }
 #endif
diff --git a/libavcodec/hevc_refs.c b/libavcodec/hevc_refs.c
index 9103c84686..6810ffaf17 100644
--- a/libavcodec/hevc_refs.c
+++ b/libavcodec/hevc_refs.c
@@ -82,45 +82,45 @@ void ff_hevc_flush_dpb(HEVCContext *s)
 static HEVCFrame *alloc_frame(HEVCContext *s)
 {
     int i, j, ret;
     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
         HEVCFrame *frame = &s->DPB[i];
         if (frame->frame->buf[0])
             continue;
 
         ret = ff_thread_get_buffer(s->avctx, &frame->tf,
                                    AV_GET_BUFFER_FLAG_REF);
         if (ret < 0)
             return NULL;
 
         frame->rpl_buf = av_buffer_allocz(s->pkt.nb_nals * sizeof(RefPicListTab));
         if (!frame->rpl_buf)
             goto fail;
 
         frame->tab_mvf_buf = av_buffer_pool_get(s->tab_mvf_pool);
         if (!frame->tab_mvf_buf)
             goto fail;
         frame->tab_mvf = (MvField *)frame->tab_mvf_buf->data;
 
         frame->rpl_tab_buf = av_buffer_pool_get(s->rpl_tab_pool);
         if (!frame->rpl_tab_buf)
             goto fail;
         frame->rpl_tab   = (RefPicListTab **)frame->rpl_tab_buf->data;
         frame->ctb_count = s->ps.sps->ctb_width * s->ps.sps->ctb_height;
         for (j = 0; j < frame->ctb_count; j++)
             frame->rpl_tab[j] = (RefPicListTab *)frame->rpl_buf->data;
 
-        frame->frame->top_field_first  = s->picture_struct == AV_PICTURE_STRUCTURE_TOP_FIELD;
-        frame->frame->interlaced_frame = (s->picture_struct == AV_PICTURE_STRUCTURE_TOP_FIELD) || (s->picture_struct == AV_PICTURE_STRUCTURE_BOTTOM_FIELD);
+        frame->frame->top_field_first  = s->sei.picture_timing.picture_struct == AV_PICTURE_STRUCTURE_TOP_FIELD;
+        frame->frame->interlaced_frame = (s->sei.picture_timing.picture_struct == AV_PICTURE_STRUCTURE_TOP_FIELD) || (s->sei.picture_timing.picture_struct == AV_PICTURE_STRUCTURE_BOTTOM_FIELD);
 
         if (s->avctx->hwaccel) {
             const AVHWAccel *hwaccel = s->avctx->hwaccel;
             av_assert0(!frame->hwaccel_picture_private);
             if (hwaccel->frame_priv_data_size) {
                 frame->hwaccel_priv_buf = av_buffer_allocz(hwaccel->frame_priv_data_size);
                 if (!frame->hwaccel_priv_buf)
                     goto fail;
                 frame->hwaccel_picture_private = frame->hwaccel_priv_buf->data;
             }
         }
 
         return frame;
diff --git a/libavcodec/hevc_sei.c b/libavcodec/hevc_sei.c
index bb299d5a9f..679a18b3d8 100644
--- a/libavcodec/hevc_sei.c
+++ b/libavcodec/hevc_sei.c
@@ -53,321 +53,310 @@ enum HEVC_SEI_TYPE {
     SEI_TYPE_CONTENT_LIGHT_LEVEL_INFO             = 144,
 };
 
-static int decode_nal_sei_decoded_picture_hash(HEVCContext *s)
+static int decode_nal_sei_decoded_picture_hash(HEVCSEIPictureHash *s, GetBitContext *gb)
 {
     int cIdx, i;
     uint8_t hash_type;
     //uint16_t picture_crc;
     //uint32_t picture_checksum;
-    GetBitContext *gb = &s->HEVClc->gb;
     hash_type = get_bits(gb, 8);
 
     for (cIdx = 0; cIdx < 3/*((s->sps->chroma_format_idc == 0) ? 1 : 3)*/; cIdx++) {
         if (hash_type == 0) {
             s->is_md5 = 1;
             for (i = 0; i < 16; i++)
                 s->md5[cIdx][i] = get_bits(gb, 8);
         } else if (hash_type == 1) {
             // picture_crc = get_bits(gb, 16);
             skip_bits(gb, 16);
         } else if (hash_type == 2) {
             // picture_checksum = get_bits_long(gb, 32);
             skip_bits(gb, 32);
         }
     }
     return 0;
 }
 
-static int decode_nal_sei_mastering_display_info(HEVCContext *s)
+static int decode_nal_sei_mastering_display_info(HEVCSEIMasteringDisplay *s, GetBitContext *gb)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
     int i;
     // Mastering primaries
     for (i = 0; i < 3; i++) {
         s->display_primaries[i][0] = get_bits(gb, 16);
         s->display_primaries[i][1] = get_bits(gb, 16);
     }
     // White point (x, y)
     s->white_point[0] = get_bits(gb, 16);
     s->white_point[1] = get_bits(gb, 16);
 
     // Max and min luminance of mastering display
-    s->max_mastering_luminance = get_bits_long(gb, 32);
-    s->min_mastering_luminance = get_bits_long(gb, 32);
+    s->max_luminance = get_bits_long(gb, 32);
+    s->min_luminance = get_bits_long(gb, 32);
 
     // As this SEI message comes before the first frame that references it,
     // initialize the flag to 2 and decrement on IRAP access unit so it
     // persists for the coded video sequence (e.g., between two IRAPs)
-    s->sei_mastering_display_info_present = 2;
+    s->present = 2;
     return 0;
 }
 
-static int decode_nal_sei_content_light_info(HEVCContext *s)
+static int decode_nal_sei_content_light_info(HEVCSEIContentLight *s, GetBitContext *gb)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
     // Max and average light levels
     s->max_content_light_level     = get_bits_long(gb, 16);
     s->max_pic_average_light_level = get_bits_long(gb, 16);
     // As this SEI message comes before the first frame that references it,
     // initialize the flag to 2 and decrement on IRAP access unit so it
     // persists for the coded video sequence (e.g., between two IRAPs)
-    s-> sei_content_light_present = 2;
+    s->present = 2;
     return  0;
 }
 
-static int decode_nal_sei_frame_packing_arrangement(HEVCContext *s)
+static int decode_nal_sei_frame_packing_arrangement(HEVCSEIFramePacking *s, GetBitContext *gb)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
-
     get_ue_golomb_long(gb);             // frame_packing_arrangement_id
-    s->sei_frame_packing_present = !get_bits1(gb);
+    s->present = !get_bits1(gb);
 
-    if (s->sei_frame_packing_present) {
-        s->frame_packing_arrangement_type = get_bits(gb, 7);
+    if (s->present) {
+        s->arrangement_type               = get_bits(gb, 7);
         s->quincunx_subsampling           = get_bits1(gb);
         s->content_interpretation_type    = get_bits(gb, 6);
 
         // the following skips spatial_flipping_flag frame0_flipped_flag
         // field_views_flag current_frame_is_frame0_flag
         // frame0_self_contained_flag frame1_self_contained_flag
         skip_bits(gb, 6);
 
-        if (!s->quincunx_subsampling && s->frame_packing_arrangement_type != 5)
+        if (!s->quincunx_subsampling && s->arrangement_type != 5)
             skip_bits(gb, 16);  // frame[01]_grid_position_[xy]
         skip_bits(gb, 8);       // frame_packing_arrangement_reserved_byte
         skip_bits1(gb);         // frame_packing_arrangement_persistence_flag
     }
     skip_bits1(gb);             // upsampled_aspect_ratio_flag
     return 0;
 }
 
-static int decode_nal_sei_display_orientation(HEVCContext *s)
+static int decode_nal_sei_display_orientation(HEVCSEIDisplayOrientation *s, GetBitContext *gb)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
-
-    s->sei_display_orientation_present = !get_bits1(gb);
+    s->present = !get_bits1(gb);
 
-    if (s->sei_display_orientation_present) {
-        s->sei_hflip = get_bits1(gb);     // hor_flip
-        s->sei_vflip = get_bits1(gb);     // ver_flip
+    if (s->present) {
+        s->hflip = get_bits1(gb);     // hor_flip
+        s->vflip = get_bits1(gb);     // ver_flip
 
-        s->sei_anticlockwise_rotation = get_bits(gb, 16);
+        s->anticlockwise_rotation = get_bits(gb, 16);
         skip_bits1(gb);     // display_orientation_persistence_flag
     }
 
     return 0;
 }
 
-static int decode_pic_timing(HEVCContext *s)
+static int decode_pic_timing(HEVCSEIContext *s, GetBitContext *gb, const HEVCParamSets *ps,
+                             void *logctx)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
+    HEVCSEIPictureTiming *h = &s->picture_timing;
     HEVCSPS *sps;
 
-    if (!s->ps.sps_list[s->active_seq_parameter_set_id])
+    if (!ps->sps_list[s->active_seq_parameter_set_id])
         return(AVERROR(ENOMEM));
-    sps = (HEVCSPS*)s->ps.sps_list[s->active_seq_parameter_set_id]->data;
+    sps = (HEVCSPS*)ps->sps_list[s->active_seq_parameter_set_id]->data;
 
     if (sps->vui.frame_field_info_present_flag) {
         int pic_struct = get_bits(gb, 4);
-        s->picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN;
+        h->picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN;
         if (pic_struct == 2) {
-            av_log(s->avctx, AV_LOG_DEBUG, "BOTTOM Field\n");
-            s->picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;
+            av_log(logctx, AV_LOG_DEBUG, "BOTTOM Field\n");
+            h->picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;
         } else if (pic_struct == 1) {
-            av_log(s->avctx, AV_LOG_DEBUG, "TOP Field\n");
-            s->picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD;
+            av_log(logctx, AV_LOG_DEBUG, "TOP Field\n");
+            h->picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD;
         }
         get_bits(gb, 2);                   // source_scan_type
         get_bits(gb, 1);                   // duplicate_flag
     }
     return 1;
 }
 
-static int decode_registered_user_data_closed_caption(HEVCContext *s, int size)
+static int decode_registered_user_data_closed_caption(HEVCSEIA53Caption *s, GetBitContext *gb,
+                                                      int size)
 {
     int flag;
     int user_data_type_code;
     int cc_count;
 
-    GetBitContext *gb = &s->HEVClc->gb;
-
     if (size < 3)
        return AVERROR(EINVAL);
 
     user_data_type_code = get_bits(gb, 8);
     if (user_data_type_code == 0x3) {
         skip_bits(gb, 1); // reserved
 
         flag = get_bits(gb, 1); // process_cc_data_flag
         if (flag) {
             skip_bits(gb, 1);
             cc_count = get_bits(gb, 5);
             skip_bits(gb, 8); // reserved
             size -= 2;
 
             if (cc_count && size >= cc_count * 3) {
                 const uint64_t new_size = (s->a53_caption_size + cc_count
                                            * UINT64_C(3));
                 int i, ret;
 
                 if (new_size > INT_MAX)
                     return AVERROR(EINVAL);
 
                 /* Allow merging of the cc data from two fields. */
                 ret = av_reallocp(&s->a53_caption, new_size);
                 if (ret < 0)
                     return ret;
 
                 for (i = 0; i < cc_count; i++) {
                     s->a53_caption[s->a53_caption_size++] = get_bits(gb, 8);
                     s->a53_caption[s->a53_caption_size++] = get_bits(gb, 8);
                     s->a53_caption[s->a53_caption_size++] = get_bits(gb, 8);
                 }
                 skip_bits(gb, 8); // marker_bits
             }
         }
     } else {
         int i;
         for (i = 0; i < size - 1; i++)
             skip_bits(gb, 8);
     }
 
     return 0;
 }
 
-static int decode_nal_sei_user_data_registered_itu_t_t35(HEVCContext *s, int size)
+static int decode_nal_sei_user_data_registered_itu_t_t35(HEVCSEIContext *s, GetBitContext *gb,
+                                                         int size)
 {
     uint32_t country_code;
     uint32_t user_identifier;
 
-    GetBitContext *gb = &s->HEVClc->gb;
-
     if (size < 7)
         return AVERROR(EINVAL);
     size -= 7;
 
     country_code = get_bits(gb, 8);
     if (country_code == 0xFF) {
         skip_bits(gb, 8);
         size--;
     }
 
     skip_bits(gb, 8);
     skip_bits(gb, 8);
 
     user_identifier = get_bits_long(gb, 32);
 
     switch (user_identifier) {
         case MKBETAG('G', 'A', '9', '4'):
-            return decode_registered_user_data_closed_caption(s, size);
+            return decode_registered_user_data_closed_caption(&s->a53_caption, gb, size);
         default:
             skip_bits_long(gb, size * 8);
             break;
     }
     return 0;
 }
 
-static int active_parameter_sets(HEVCContext *s)
+static int active_parameter_sets(HEVCSEIContext *s, GetBitContext *gb, void *logctx)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
     int num_sps_ids_minus1;
     int i;
     unsigned active_seq_parameter_set_id;
 
     get_bits(gb, 4); // active_video_parameter_set_id
     get_bits(gb, 1); // self_contained_cvs_flag
     get_bits(gb, 1); // num_sps_ids_minus1
     num_sps_ids_minus1 = get_ue_golomb_long(gb); // num_sps_ids_minus1
 
     if (num_sps_ids_minus1 < 0 || num_sps_ids_minus1 > 15) {
-        av_log(s->avctx, AV_LOG_ERROR, "num_sps_ids_minus1 %d invalid\n", num_sps_ids_minus1);
+        av_log(logctx, AV_LOG_ERROR, "num_sps_ids_minus1 %d invalid\n", num_sps_ids_minus1);
         return AVERROR_INVALIDDATA;
     }
 
     active_seq_parameter_set_id = get_ue_golomb_long(gb);
     if (active_seq_parameter_set_id >= HEVC_MAX_SPS_COUNT) {
-        av_log(s->avctx, AV_LOG_ERROR, "active_parameter_set_id %d invalid\n", active_seq_parameter_set_id);
+        av_log(logctx, AV_LOG_ERROR, "active_parameter_set_id %d invalid\n", active_seq_parameter_set_id);
         return AVERROR_INVALIDDATA;
     }
     s->active_seq_parameter_set_id = active_seq_parameter_set_id;
 
     for (i = 1; i <= num_sps_ids_minus1; i++)
         get_ue_golomb_long(gb); // active_seq_parameter_set_id[i]
 
     return 0;
 }
 
-static int decode_nal_sei_prefix(HEVCContext *s, int type, int size)
+static int decode_nal_sei_prefix(GetBitContext *gb, HEVCSEIContext *s, const HEVCParamSets *ps,
+                                 int type, int size, void *logctx)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
-
     switch (type) {
     case 256:  // Mismatched value from HM 8.1
-        return decode_nal_sei_decoded_picture_hash(s);
+        return decode_nal_sei_decoded_picture_hash(&s->picture_hash, gb);
     case SEI_TYPE_FRAME_PACKING:
-        return decode_nal_sei_frame_packing_arrangement(s);
+        return decode_nal_sei_frame_packing_arrangement(&s->frame_packing, gb);
     case SEI_TYPE_DISPLAY_ORIENTATION:
-        return decode_nal_sei_display_orientation(s);
+        return decode_nal_sei_display_orientation(&s->display_orientation, gb);
     case SEI_TYPE_PICTURE_TIMING:
         {
-            int ret = decode_pic_timing(s);
-            av_log(s->avctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
+            int ret = decode_pic_timing(s, gb, ps, logctx);
+            av_log(logctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
             skip_bits(gb, 8 * size);
             return ret;
         }
     case SEI_TYPE_MASTERING_DISPLAY_INFO:
-        return decode_nal_sei_mastering_display_info(s);
+        return decode_nal_sei_mastering_display_info(&s->mastering_display, gb);
     case SEI_TYPE_CONTENT_LIGHT_LEVEL_INFO:
-        return decode_nal_sei_content_light_info(s);
+        return decode_nal_sei_content_light_info(&s->content_light, gb);
     case SEI_TYPE_ACTIVE_PARAMETER_SETS:
-        active_parameter_sets(s);
-        av_log(s->avctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
+        active_parameter_sets(s, gb, logctx);
+        av_log(logctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
         return 0;
     case SEI_TYPE_USER_DATA_REGISTERED_ITU_T_T35:
-        return decode_nal_sei_user_data_registered_itu_t_t35(s, size);
+        return decode_nal_sei_user_data_registered_itu_t_t35(s, gb, size);
     default:
-        av_log(s->avctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
+        av_log(logctx, AV_LOG_DEBUG, "Skipped PREFIX SEI %d\n", type);
         skip_bits_long(gb, 8 * size);
         return 0;
     }
 }
 
-static int decode_nal_sei_suffix(HEVCContext *s, int type, int size)
+static int decode_nal_sei_suffix(GetBitContext *gb, HEVCSEIContext *s,
+                                 int type, int size, void *logctx)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
-
     switch (type) {
     case SEI_TYPE_DECODED_PICTURE_HASH:
-        return decode_nal_sei_decoded_picture_hash(s);
+        return decode_nal_sei_decoded_picture_hash(&s->picture_hash, gb);
     default:
-        av_log(s->avctx, AV_LOG_DEBUG, "Skipped SUFFIX SEI %d\n", type);
+        av_log(logctx, AV_LOG_DEBUG, "Skipped SUFFIX SEI %d\n", type);
         skip_bits_long(gb, 8 * size);
         return 0;
     }
 }
 
-static int decode_nal_sei_message(HEVCContext *s)
+static int decode_nal_sei_message(GetBitContext *gb, HEVCSEIContext *s,
+                                  const HEVCParamSets *ps, int nal_unit_type,
+                                  void *logctx)
 {
-    GetBitContext *gb = &s->HEVClc->gb;
-
     int payload_type = 0;
     int payload_size = 0;
     int byte = 0xFF;
-    av_log(s->avctx, AV_LOG_DEBUG, "Decoding SEI\n");
+    av_log(logctx, AV_LOG_DEBUG, "Decoding SEI\n");
 
     while (byte == 0xFF) {
         byte          = get_bits(gb, 8);
         payload_type += byte;
     }
     byte = 0xFF;
     while (byte == 0xFF) {
         byte          = get_bits(gb, 8);
         payload_size += byte;
     }
-    if (s->nal_unit_type == HEVC_NAL_SEI_PREFIX) {
-        return decode_nal_sei_prefix(s, payload_type, payload_size);
+    if (nal_unit_type == HEVC_NAL_SEI_PREFIX) {
+        return decode_nal_sei_prefix(gb, s, ps, payload_type, payload_size, logctx);
     } else { /* nal_unit_type == NAL_SEI_SUFFIX */
-        return decode_nal_sei_suffix(s, payload_type, payload_size);
+        return decode_nal_sei_suffix(gb, s, payload_type, payload_size, logctx);
     }
 }
 
@@ -376,20 +365,21 @@ static int more_rbsp_data(GetBitContext *gb)
     return get_bits_left(gb) > 0 && show_bits(gb, 8) != 0x80;
 }
 
-int ff_hevc_decode_nal_sei(HEVCContext *s)
+int ff_hevc_decode_nal_sei(GetBitContext *gb, void *logctx, HEVCSEIContext *s,
+                           const HEVCParamSets *ps, int type)
 {
     int ret;
 
     do {
-        ret = decode_nal_sei_message(s);
+        ret = decode_nal_sei_message(gb, s, ps, type, logctx);
         if (ret < 0)
             return(AVERROR(ENOMEM));
-    } while (more_rbsp_data(&s->HEVClc->gb));
+    } while (more_rbsp_data(gb));
     return 1;
 }
 
-void ff_hevc_reset_sei(HEVCContext *s)
+void ff_hevc_reset_sei(HEVCSEIContext *s)
 {
-    s->a53_caption_size = 0;
-    av_freep(&s->a53_caption);
+    s->a53_caption.a53_caption_size = 0;
+    av_freep(&s->a53_caption.a53_caption);
 }
diff --git a/libavcodec/hevcdec.c b/libavcodec/hevcdec.c
index 2fb08d81d2..2a02edab28 100644
--- a/libavcodec/hevcdec.c
+++ b/libavcodec/hevcdec.c
@@ -2558,128 +2558,130 @@ error:
 static int set_side_data(HEVCContext *s)
 {
     AVFrame *out = s->ref->frame;
 
-    if (s->sei_frame_packing_present &&
-        s->frame_packing_arrangement_type >= 3 &&
-        s->frame_packing_arrangement_type <= 5 &&
-        s->content_interpretation_type > 0 &&
-        s->content_interpretation_type < 3) {
+    if (s->sei.frame_packing.present &&
+        s->sei.frame_packing.arrangement_type >= 3 &&
+        s->sei.frame_packing.arrangement_type <= 5 &&
+        s->sei.frame_packing.content_interpretation_type > 0 &&
+        s->sei.frame_packing.content_interpretation_type < 3) {
         AVStereo3D *stereo = av_stereo3d_create_side_data(out);
         if (!stereo)
             return AVERROR(ENOMEM);
 
-        switch (s->frame_packing_arrangement_type) {
+        switch (s->sei.frame_packing.arrangement_type) {
         case 3:
-            if (s->quincunx_subsampling)
+            if (s->sei.frame_packing.quincunx_subsampling)
                 stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;
             else
                 stereo->type = AV_STEREO3D_SIDEBYSIDE;
             break;
         case 4:
             stereo->type = AV_STEREO3D_TOPBOTTOM;
             break;
         case 5:
             stereo->type = AV_STEREO3D_FRAMESEQUENCE;
             break;
         }
 
-        if (s->content_interpretation_type == 2)
+        if (s->sei.frame_packing.content_interpretation_type == 2)
             stereo->flags = AV_STEREO3D_FLAG_INVERT;
     }
 
-    if (s->sei_display_orientation_present &&
-        (s->sei_anticlockwise_rotation || s->sei_hflip || s->sei_vflip)) {
-        double angle = s->sei_anticlockwise_rotation * 360 / (double) (1 << 16);
+    if (s->sei.display_orientation.present &&
+        (s->sei.display_orientation.anticlockwise_rotation ||
+         s->sei.display_orientation.hflip || s->sei.display_orientation.vflip)) {
+        double angle = s->sei.display_orientation.anticlockwise_rotation * 360 / (double) (1 << 16);
         AVFrameSideData *rotation = av_frame_new_side_data(out,
                                                            AV_FRAME_DATA_DISPLAYMATRIX,
                                                            sizeof(int32_t) * 9);
         if (!rotation)
             return AVERROR(ENOMEM);
 
         av_display_rotation_set((int32_t *)rotation->data, angle);
         av_display_matrix_flip((int32_t *)rotation->data,
-                               s->sei_hflip, s->sei_vflip);
+                               s->sei.display_orientation.hflip,
+                               s->sei.display_orientation.vflip);
     }
 
     // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1
     // so the side data persists for the entire coded video sequence.
-    if (s->sei_mastering_display_info_present > 0 &&
+    if (s->sei.mastering_display.present > 0 &&
         IS_IRAP(s) && s->no_rasl_output_flag) {
-        s->sei_mastering_display_info_present--;
+        s->sei.mastering_display.present--;
     }
-    if (s->sei_mastering_display_info_present) {
+    if (s->sei.mastering_display.present) {
         // HEVC uses a g,b,r ordering, which we convert to a more natural r,g,b
         const int mapping[3] = {2, 0, 1};
         const int chroma_den = 50000;
         const int luma_den = 10000;
         int i;
         AVMasteringDisplayMetadata *metadata =
             av_mastering_display_metadata_create_side_data(out);
         if (!metadata)
             return AVERROR(ENOMEM);
 
         for (i = 0; i < 3; i++) {
             const int j = mapping[i];
-            metadata->display_primaries[i][0].num = s->display_primaries[j][0];
+            metadata->display_primaries[i][0].num = s->sei.mastering_display.display_primaries[j][0];
             metadata->display_primaries[i][0].den = chroma_den;
-            metadata->display_primaries[i][1].num = s->display_primaries[j][1];
+            metadata->display_primaries[i][1].num = s->sei.mastering_display.display_primaries[j][1];
             metadata->display_primaries[i][1].den = chroma_den;
         }
-        metadata->white_point[0].num = s->white_point[0];
+        metadata->white_point[0].num = s->sei.mastering_display.white_point[0];
         metadata->white_point[0].den = chroma_den;
-        metadata->white_point[1].num = s->white_point[1];
+        metadata->white_point[1].num = s->sei.mastering_display.white_point[1];
         metadata->white_point[1].den = chroma_den;
 
-        metadata->max_luminance.num = s->max_mastering_luminance;
+        metadata->max_luminance.num = s->sei.mastering_display.max_luminance;
         metadata->max_luminance.den = luma_den;
-        metadata->min_luminance.num = s->min_mastering_luminance;
+        metadata->min_luminance.num = s->sei.mastering_display.min_luminance;
         metadata->min_luminance.den = luma_den;
         metadata->has_luminance = 1;
         metadata->has_primaries = 1;
 
         av_log(s->avctx, AV_LOG_DEBUG, "Mastering Display Metadata:\n");
         av_log(s->avctx, AV_LOG_DEBUG,
                "r(%5.4f,%5.4f) g(%5.4f,%5.4f) b(%5.4f %5.4f) wp(%5.4f, %5.4f)\n",
                av_q2d(metadata->display_primaries[0][0]),
                av_q2d(metadata->display_primaries[0][1]),
                av_q2d(metadata->display_primaries[1][0]),
                av_q2d(metadata->display_primaries[1][1]),
                av_q2d(metadata->display_primaries[2][0]),
                av_q2d(metadata->display_primaries[2][1]),
                av_q2d(metadata->white_point[0]), av_q2d(metadata->white_point[1]));
         av_log(s->avctx, AV_LOG_DEBUG,
                "min_luminance=%f, max_luminance=%f\n",
                av_q2d(metadata->min_luminance), av_q2d(metadata->max_luminance));
     }
     // Decrement the mastering display flag when IRAP frame has no_rasl_output_flag=1
     // so the side data persists for the entire coded video sequence.
-    if (s->sei_content_light_present > 0 &&
+    if (s->sei.content_light.present > 0 &&
         IS_IRAP(s) && s->no_rasl_output_flag) {
-        s->sei_content_light_present--;
+        s->sei.content_light.present--;
     }
-    if (s->sei_content_light_present) {
+    if (s->sei.content_light.present) {
         AVContentLightMetadata *metadata =
             av_content_light_metadata_create_side_data(out);
         if (!metadata)
             return AVERROR(ENOMEM);
-        metadata->MaxCLL  = s->max_content_light_level;
-        metadata->MaxFALL = s->max_pic_average_light_level;
+        metadata->MaxCLL  = s->sei.content_light.max_content_light_level;
+        metadata->MaxFALL = s->sei.content_light.max_pic_average_light_level;
 
         av_log(s->avctx, AV_LOG_DEBUG, "Content Light Level Metadata:\n");
         av_log(s->avctx, AV_LOG_DEBUG, "MaxCLL=%d, MaxFALL=%d\n",
                metadata->MaxCLL, metadata->MaxFALL);
     }
 
-    if (s->a53_caption) {
+    if (s->sei.a53_caption.a53_caption) {
         AVFrameSideData* sd = av_frame_new_side_data(out,
                                                      AV_FRAME_DATA_A53_CC,
-                                                     s->a53_caption_size);
+                                                     s->sei.a53_caption.a53_caption_size);
         if (sd)
-            memcpy(sd->data, s->a53_caption, s->a53_caption_size);
-        av_freep(&s->a53_caption);
-        s->a53_caption_size = 0;
+            memcpy(sd->data, s->sei.a53_caption.a53_caption, s->sei.a53_caption.a53_caption_size);
+        av_freep(&s->sei.a53_caption.a53_caption);
+        s->sei.a53_caption.a53_caption_size = 0;
         s->avctx->properties |= FF_CODEC_PROPERTY_CLOSED_CAPTIONS;
     }
 
     return 0;
 }
@@ -2746,136 +2748,136 @@ fail:
 static int decode_nal_unit(HEVCContext *s, const H2645NAL *nal)
 {
     HEVCLocalContext *lc = s->HEVClc;
     GetBitContext *gb    = &lc->gb;
     int ctb_addr_ts, ret;
 
     *gb              = nal->gb;
     s->nal_unit_type = nal->type;
     s->temporal_id   = nal->temporal_id;
 
     switch (s->nal_unit_type) {
     case HEVC_NAL_VPS:
         ret = ff_hevc_decode_nal_vps(gb, s->avctx, &s->ps);
         if (ret < 0)
             goto fail;
         break;
     case HEVC_NAL_SPS:
         ret = ff_hevc_decode_nal_sps(gb, s->avctx, &s->ps,
                                      s->apply_defdispwin);
         if (ret < 0)
             goto fail;
         break;
     case HEVC_NAL_PPS:
         ret = ff_hevc_decode_nal_pps(gb, s->avctx, &s->ps);
         if (ret < 0)
             goto fail;
         break;
     case HEVC_NAL_SEI_PREFIX:
     case HEVC_NAL_SEI_SUFFIX:
-        ret = ff_hevc_decode_nal_sei(s);
+        ret = ff_hevc_decode_nal_sei(gb, s->avctx, &s->sei, &s->ps, s->nal_unit_type);
         if (ret < 0)
             goto fail;
         break;
     case HEVC_NAL_TRAIL_R:
     case HEVC_NAL_TRAIL_N:
     case HEVC_NAL_TSA_N:
     case HEVC_NAL_TSA_R:
     case HEVC_NAL_STSA_N:
     case HEVC_NAL_STSA_R:
     case HEVC_NAL_BLA_W_LP:
     case HEVC_NAL_BLA_W_RADL:
     case HEVC_NAL_BLA_N_LP:
     case HEVC_NAL_IDR_W_RADL:
     case HEVC_NAL_IDR_N_LP:
     case HEVC_NAL_CRA_NUT:
     case HEVC_NAL_RADL_N:
     case HEVC_NAL_RADL_R:
     case HEVC_NAL_RASL_N:
     case HEVC_NAL_RASL_R:
         ret = hls_slice_header(s);
         if (ret < 0)
             return ret;
 
         if (s->sh.first_slice_in_pic_flag) {
             if (s->max_ra == INT_MAX) {
                 if (s->nal_unit_type == HEVC_NAL_CRA_NUT || IS_BLA(s)) {
                     s->max_ra = s->poc;
                 } else {
                     if (IS_IDR(s))
                         s->max_ra = INT_MIN;
                 }
             }
 
             if ((s->nal_unit_type == HEVC_NAL_RASL_R || s->nal_unit_type == HEVC_NAL_RASL_N) &&
                 s->poc <= s->max_ra) {
                 s->is_decoded = 0;
                 break;
             } else {
                 if (s->nal_unit_type == HEVC_NAL_RASL_R && s->poc > s->max_ra)
                     s->max_ra = INT_MIN;
             }
 
             ret = hevc_frame_start(s);
             if (ret < 0)
                 return ret;
         } else if (!s->ref) {
             av_log(s->avctx, AV_LOG_ERROR, "First slice in a frame missing.\n");
             goto fail;
         }
 
         if (s->nal_unit_type != s->first_nal_type) {
             av_log(s->avctx, AV_LOG_ERROR,
                    "Non-matching NAL types of the VCL NALUs: %d %d\n",
                    s->first_nal_type, s->nal_unit_type);
             return AVERROR_INVALIDDATA;
         }
 
         if (!s->sh.dependent_slice_segment_flag &&
             s->sh.slice_type != HEVC_SLICE_I) {
             ret = ff_hevc_slice_rpl(s);
             if (ret < 0) {
                 av_log(s->avctx, AV_LOG_WARNING,
                        "Error constructing the reference lists for the current slice.\n");
                 goto fail;
             }
         }
 
         if (s->sh.first_slice_in_pic_flag && s->avctx->hwaccel) {
             ret = s->avctx->hwaccel->start_frame(s->avctx, NULL, 0);
             if (ret < 0)
                 goto fail;
         }
 
         if (s->avctx->hwaccel) {
             ret = s->avctx->hwaccel->decode_slice(s->avctx, nal->raw_data, nal->raw_size);
             if (ret < 0)
                 goto fail;
         } else {
             if (s->threads_number > 1 && s->sh.num_entry_point_offsets > 0)
                 ctb_addr_ts = hls_slice_data_wpp(s, nal);
             else
                 ctb_addr_ts = hls_slice_data(s);
             if (ctb_addr_ts >= (s->ps.sps->ctb_width * s->ps.sps->ctb_height)) {
                 s->is_decoded = 1;
             }
 
             if (ctb_addr_ts < 0) {
                 ret = ctb_addr_ts;
                 goto fail;
             }
         }
         break;
     case HEVC_NAL_EOS_NUT:
     case HEVC_NAL_EOB_NUT:
         s->seq_decode = (s->seq_decode + 1) & 0xff;
         s->max_ra     = INT_MAX;
         break;
     case HEVC_NAL_AUD:
     case HEVC_NAL_FD_NUT:
         break;
     default:
         av_log(s->avctx, AV_LOG_INFO,
                "Skipping NAL unit %d\n", s->nal_unit_type);
     }
 
     return 0;
@@ -2936,65 +2938,65 @@ static void print_md5(void *log_ctx, int level, uint8_t md5[16])
 static int verify_md5(HEVCContext *s, AVFrame *frame)
 {
     const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);
     int pixel_shift;
     int i, j;
 
     if (!desc)
         return AVERROR(EINVAL);
 
     pixel_shift = desc->comp[0].depth > 8;
 
     av_log(s->avctx, AV_LOG_DEBUG, "Verifying checksum for frame with POC %d: ",
            s->poc);
 
     /* the checksums are LE, so we have to byteswap for >8bpp formats
      * on BE arches */
 #if HAVE_BIGENDIAN
     if (pixel_shift && !s->checksum_buf) {
         av_fast_malloc(&s->checksum_buf, &s->checksum_buf_size,
                        FFMAX3(frame->linesize[0], frame->linesize[1],
                               frame->linesize[2]));
         if (!s->checksum_buf)
             return AVERROR(ENOMEM);
     }
 #endif
 
     for (i = 0; frame->data[i]; i++) {
         int width  = s->avctx->coded_width;
         int height = s->avctx->coded_height;
         int w = (i == 1 || i == 2) ? (width  >> desc->log2_chroma_w) : width;
         int h = (i == 1 || i == 2) ? (height >> desc->log2_chroma_h) : height;
         uint8_t md5[16];
 
-        av_md5_init(s->md5_ctx);
+        av_md5_init(s->sei.picture_hash.md5_ctx);
         for (j = 0; j < h; j++) {
             const uint8_t *src = frame->data[i] + j * frame->linesize[i];
 #if HAVE_BIGENDIAN
             if (pixel_shift) {
                 s->bdsp.bswap16_buf((uint16_t *) s->checksum_buf,
                                     (const uint16_t *) src, w);
                 src = s->checksum_buf;
             }
 #endif
-            av_md5_update(s->md5_ctx, src, w << pixel_shift);
+            av_md5_update(s->sei.picture_hash.md5_ctx, src, w << pixel_shift);
         }
-        av_md5_final(s->md5_ctx, md5);
+        av_md5_final(s->sei.picture_hash.md5_ctx, md5);
 
-        if (!memcmp(md5, s->md5[i], 16)) {
+        if (!memcmp(md5, s->sei.picture_hash.md5[i], 16)) {
             av_log   (s->avctx, AV_LOG_DEBUG, "plane %d - correct ", i);
             print_md5(s->avctx, AV_LOG_DEBUG, md5);
             av_log   (s->avctx, AV_LOG_DEBUG, "; ");
         } else {
             av_log   (s->avctx, AV_LOG_ERROR, "mismatching checksum of plane %d - ", i);
             print_md5(s->avctx, AV_LOG_ERROR, md5);
             av_log   (s->avctx, AV_LOG_ERROR, " != ");
-            print_md5(s->avctx, AV_LOG_ERROR, s->md5[i]);
+            print_md5(s->avctx, AV_LOG_ERROR, s->sei.picture_hash.md5[i]);
             av_log   (s->avctx, AV_LOG_ERROR, "\n");
             return AVERROR_INVALIDDATA;
         }
     }
 
     av_log(s->avctx, AV_LOG_DEBUG, "\n");
 
     return 0;
 }
@@ -3024,62 +3026,62 @@ static int hevc_decode_extradata(HEVCContext *s, uint8_t *buf, int length)
 static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
                              AVPacket *avpkt)
 {
     int ret;
     int new_extradata_size;
     uint8_t *new_extradata;
     HEVCContext *s = avctx->priv_data;
 
     if (!avpkt->size) {
         ret = ff_hevc_output_frame(s, data, 1);
         if (ret < 0)
             return ret;
 
         *got_output = ret;
         return 0;
     }
 
     new_extradata = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA,
                                             &new_extradata_size);
     if (new_extradata && new_extradata_size > 0) {
         ret = hevc_decode_extradata(s, new_extradata, new_extradata_size);
         if (ret < 0)
             return ret;
     }
 
     s->ref = NULL;
     ret    = decode_nal_units(s, avpkt->data, avpkt->size);
     if (ret < 0)
         return ret;
 
     if (avctx->hwaccel) {
         if (s->ref && (ret = avctx->hwaccel->end_frame(avctx)) < 0) {
             av_log(avctx, AV_LOG_ERROR,
                    "hardware accelerator failed to decode picture\n");
             ff_hevc_unref_frame(s, s->ref, ~0);
             return ret;
         }
     } else {
         /* verify the SEI checksum */
         if (avctx->err_recognition & AV_EF_CRCCHECK && s->is_decoded &&
-            s->is_md5) {
+            s->sei.picture_hash.is_md5) {
             ret = verify_md5(s, s->ref->frame);
             if (ret < 0 && avctx->err_recognition & AV_EF_EXPLODE) {
                 ff_hevc_unref_frame(s, s->ref, ~0);
                 return ret;
             }
         }
     }
-    s->is_md5 = 0;
+    s->sei.picture_hash.is_md5 = 0;
 
     if (s->is_decoded) {
         av_log(avctx, AV_LOG_DEBUG, "Decoded frame with POC %d.\n", s->poc);
         s->is_decoded = 0;
     }
 
     if (s->output_frame->buf[0]) {
         av_frame_move_ref(data, s->output_frame);
         *got_output = 1;
     }
 
     return avpkt->size;
 }
@@ -3128,51 +3130,51 @@ fail:
 static av_cold int hevc_decode_free(AVCodecContext *avctx)
 {
     HEVCContext       *s = avctx->priv_data;
     int i;
 
     pic_arrays_free(s);
 
-    av_freep(&s->md5_ctx);
+    av_freep(&s->sei.picture_hash.md5_ctx);
 
     av_freep(&s->cabac_state);
 
     for (i = 0; i < 3; i++) {
         av_freep(&s->sao_pixel_buffer_h[i]);
         av_freep(&s->sao_pixel_buffer_v[i]);
     }
     av_frame_free(&s->output_frame);
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
         ff_hevc_unref_frame(s, &s->DPB[i], ~0);
         av_frame_free(&s->DPB[i].frame);
     }
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->ps.vps_list); i++)
         av_buffer_unref(&s->ps.vps_list[i]);
     for (i = 0; i < FF_ARRAY_ELEMS(s->ps.sps_list); i++)
         av_buffer_unref(&s->ps.sps_list[i]);
     for (i = 0; i < FF_ARRAY_ELEMS(s->ps.pps_list); i++)
         av_buffer_unref(&s->ps.pps_list[i]);
     s->ps.sps = NULL;
     s->ps.pps = NULL;
     s->ps.vps = NULL;
 
     av_freep(&s->sh.entry_point_offset);
     av_freep(&s->sh.offset);
     av_freep(&s->sh.size);
 
     for (i = 1; i < s->threads_number; i++) {
         HEVCLocalContext *lc = s->HEVClcList[i];
         if (lc) {
             av_freep(&s->HEVClcList[i]);
             av_freep(&s->sList[i]);
         }
     }
     if (s->HEVClc == s->HEVClcList[0])
         s->HEVClc = NULL;
     av_freep(&s->HEVClcList[0]);
 
     ff_h2645_packet_uninit(&s->pkt);
 
     return 0;
 }
@@ -3180,43 +3182,43 @@ static av_cold int hevc_decode_free(AVCodecContext *avctx)
 static av_cold int hevc_init_context(AVCodecContext *avctx)
 {
     HEVCContext *s = avctx->priv_data;
     int i;
 
     s->avctx = avctx;
 
     s->HEVClc = av_mallocz(sizeof(HEVCLocalContext));
     if (!s->HEVClc)
         goto fail;
     s->HEVClcList[0] = s->HEVClc;
     s->sList[0] = s;
 
     s->cabac_state = av_malloc(HEVC_CONTEXTS);
     if (!s->cabac_state)
         goto fail;
 
     s->output_frame = av_frame_alloc();
     if (!s->output_frame)
         goto fail;
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
         s->DPB[i].frame = av_frame_alloc();
         if (!s->DPB[i].frame)
             goto fail;
         s->DPB[i].tf.f = s->DPB[i].frame;
     }
 
     s->max_ra = INT_MAX;
 
-    s->md5_ctx = av_md5_alloc();
-    if (!s->md5_ctx)
+    s->sei.picture_hash.md5_ctx = av_md5_alloc();
+    if (!s->sei.picture_hash.md5_ctx)
         goto fail;
 
     ff_bswapdsp_init(&s->bdsp);
 
     s->context_initialized = 1;
     s->eos = 0;
 
-    ff_hevc_reset_sei(s);
+    ff_hevc_reset_sei(&s->sei);
 
     return 0;
 
@@ -3304,37 +3306,37 @@ static int hevc_update_thread_context(AVCodecContext *dst,
 static av_cold int hevc_decode_init(AVCodecContext *avctx)
 {
     HEVCContext *s = avctx->priv_data;
     int ret;
 
     avctx->internal->allocate_progress = 1;
 
     ret = hevc_init_context(avctx);
     if (ret < 0)
         return ret;
 
     s->enable_parallel_tiles = 0;
-    s->picture_struct = 0;
+    s->sei.picture_timing.picture_struct = 0;
     s->eos = 1;
 
     atomic_init(&s->wpp_err, 0);
 
     if(avctx->active_thread_type & FF_THREAD_SLICE)
         s->threads_number = avctx->thread_count;
     else
         s->threads_number = 1;
 
     if (avctx->extradata_size > 0 && avctx->extradata) {
         ret = hevc_decode_extradata(s, avctx->extradata, avctx->extradata_size);
         if (ret < 0) {
             hevc_decode_free(avctx);
             return ret;
         }
     }
 
     if((avctx->active_thread_type & FF_THREAD_FRAME) && avctx->thread_count > 1)
             s->threads_type = FF_THREAD_FRAME;
         else
             s->threads_type = FF_THREAD_SLICE;
 
     return 0;
 }
diff --git a/libavcodec/hevcdec.h b/libavcodec/hevcdec.h
index dfb12eff8b..4f863a7f6e 100644
--- a/libavcodec/hevcdec.h
+++ b/libavcodec/hevcdec.h
@@ -464,147 +464,167 @@ typedef struct HEVCLocalContext {
     int boundary_flags;
 } HEVCLocalContext;
 
+typedef struct HEVCSEIPictureHash {
+    struct AVMD5 *md5_ctx;
+    uint8_t       md5[3][16];
+    uint8_t is_md5;
+} HEVCSEIPictureHash;
+
+typedef struct HEVCSEIFramePacking {
+    int present;
+    int arrangement_type;
+    int content_interpretation_type;
+    int quincunx_subsampling;
+} HEVCSEIFramePacking;
+
+typedef struct HEVCSEIDisplayOrientation {
+    int present;
+    int anticlockwise_rotation;
+    int hflip, vflip;
+} HEVCSEIDisplayOrientation;
+
+typedef struct HEVCSEIPictureTiming {
+    int picture_struct;
+} HEVCSEIPictureTiming;
+
+typedef struct HEVCSEIA53Caption {
+    int a53_caption_size;
+    uint8_t *a53_caption;
+} HEVCSEIA53Caption;
+
+typedef struct HEVCSEIMasteringDisplay {
+    int present;
+    uint16_t display_primaries[3][2];
+    uint16_t white_point[2];
+    uint32_t max_luminance;
+    uint32_t min_luminance;
+} HEVCSEIMasteringDisplay;
+
+typedef struct HEVCSEIContentLight {
+    int present;
+    uint16_t max_content_light_level;
+    uint16_t max_pic_average_light_level;
+} HEVCSEIContentLight;
+
+typedef struct HEVCSEIContext {
+    HEVCSEIPictureHash picture_hash;
+    HEVCSEIFramePacking frame_packing;
+    HEVCSEIDisplayOrientation display_orientation;
+    HEVCSEIPictureTiming picture_timing;
+    HEVCSEIA53Caption a53_caption;
+    HEVCSEIMasteringDisplay mastering_display;
+    HEVCSEIContentLight content_light;
+    int active_seq_parameter_set_id;
+} HEVCSEIContext;
+
 typedef struct HEVCContext {
     const AVClass *c;  // needed by private avoptions
     AVCodecContext *avctx;
 
     struct HEVCContext  *sList[MAX_NB_THREADS];
 
     HEVCLocalContext    *HEVClcList[MAX_NB_THREADS];
     HEVCLocalContext    *HEVClc;
 
     uint8_t             threads_type;
     uint8_t             threads_number;
 
     int                 width;
     int                 height;
 
     uint8_t *cabac_state;
 
     /** 1 if the independent slice segment header was successfully parsed */
     uint8_t slice_initialized;
 
     AVFrame *frame;
     AVFrame *output_frame;
     uint8_t *sao_pixel_buffer_h[3];
     uint8_t *sao_pixel_buffer_v[3];
 
     HEVCParamSets ps;
 
     AVBufferPool *tab_mvf_pool;
     AVBufferPool *rpl_tab_pool;
 
     ///< candidate references for the current frame
     RefPicList rps[5];
 
     SliceHeader sh;
     SAOParams *sao;
     DBParams *deblock;
     enum HEVCNALUnitType nal_unit_type;
     int temporal_id;  ///< temporal_id_plus1 - 1
     HEVCFrame *ref;
     HEVCFrame DPB[32];
     int poc;
     int pocTid0;
     int slice_idx; ///< number of the slice being currently decoded
     int eos;       ///< current packet contains an EOS/EOB NAL
     int last_eos;  ///< last packet contains an EOS/EOB NAL
     int max_ra;
     int bs_width;
     int bs_height;
 
     int is_decoded;
     int no_rasl_output_flag;
 
     HEVCPredContext hpc;
     HEVCDSPContext hevcdsp;
     VideoDSPContext vdsp;
     BswapDSPContext bdsp;
     int8_t *qp_y_tab;
     uint8_t *horizontal_bs;
     uint8_t *vertical_bs;
 
     int32_t *tab_slice_address;
 
     //  CU
     uint8_t *skip_flag;
     uint8_t *tab_ct_depth;
     // PU
     uint8_t *tab_ipm;
 
     uint8_t *cbf_luma; // cbf_luma of colocated TU
     uint8_t *is_pcm;
 
     // CTB-level flags affecting loop filter operation
     uint8_t *filter_slice_edges;
 
     /** used on BE to byteswap the lines for checksumming */
     uint8_t *checksum_buf;
     int      checksum_buf_size;
 
     /**
      * Sequence counters for decoded and output frames, so that old
      * frames are output first after a POC reset
      */
     uint16_t seq_decode;
     uint16_t seq_output;
 
     int enable_parallel_tiles;
     atomic_int wpp_err;
 
     const uint8_t *data;
 
     H2645Packet pkt;
     // type of the first VCL NAL of the current frame
     enum HEVCNALUnitType first_nal_type;
 
-    // for checking the frame checksums
-    struct AVMD5 *md5_ctx;
-    uint8_t       md5[3][16];
-    uint8_t is_md5;
-
     uint8_t context_initialized;
     int is_nalff;           ///< this flag is != 0 if bitstream is encapsulated
                             ///< as a format defined in 14496-15
     int apply_defdispwin;
 
-    int active_seq_parameter_set_id;
-
     int nal_length_size;    ///< Number of bytes used for nal length (1, 2 or 4)
     int nuh_layer_id;
 
-    /** frame packing arrangement variables */
-    int sei_frame_packing_present;
-    int frame_packing_arrangement_type;
-    int content_interpretation_type;
-    int quincunx_subsampling;
-
-    /** display orientation */
-    int sei_display_orientation_present;
-    int sei_anticlockwise_rotation;
-    int sei_hflip, sei_vflip;
-
-    int picture_struct;
-
-    uint8_t* a53_caption;
-    int a53_caption_size;
-
-    /** mastering display */
-    int sei_mastering_display_info_present;
-    uint16_t display_primaries[3][2];
-    uint16_t white_point[2];
-    uint32_t max_mastering_luminance;
-    uint32_t min_mastering_luminance;
-
-    /* content light level */
-    int sei_content_light_present;
-    uint16_t max_content_light_level;
-    uint16_t max_pic_average_light_level;
-
+    HEVCSEIContext sei;
 } HEVCContext;
 
-int ff_hevc_decode_nal_sei(HEVCContext *s);
+int ff_hevc_decode_nal_sei(GetBitContext *gb, void *logctx, HEVCSEIContext *s,
+                           const HEVCParamSets *ps, int type);
 
 /**
  * Mark all frames in DPB as unused for reference.
  */
@@ -711,11 +731,11 @@ void ff_hevc_hls_mvd_coding(HEVCContext *s, int x0, int y0, int log2_cb_size);
 /**
  * Reset SEI values that are stored on the Context.
  * e.g. Caption data that was extracted during NAL
  * parsing.
  *
  * @param s HEVCContext.
  */
-void ff_hevc_reset_sei(HEVCContext *s);
+void ff_hevc_reset_sei(HEVCSEIContext *s);
 
 extern const uint8_t ff_hevc_qpel_extra_before[4];
 extern const uint8_t ff_hevc_qpel_extra_after[4];
