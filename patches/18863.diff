commit ec955675542b4c9c2f565558b76493dba37516e9
Merge: 1fbc8b3 32862fa
Author: Dirk Farin <dirk.farin@gmail.com>
Date:   Fri Jan 29 11:56:59 2021 +0100

    Merge pull request #435 from strukturag/cpplint-python3
    
    Support both python and python3 for running cpplint.

diff --git a/scripts/cpplint.py b/scripts/cpplint.py
index 42e3da3..0d4a799 100755
--- a/scripts/cpplint.py
+++ b/scripts/cpplint.py
@@ -55,7 +55,7 @@ import sys
 import unicodedata
 
 
-_USAGE = """
+_USAGE = r"""
 Syntax: cpplint.py [--verbose=#] [--output=vs7] [--filter=-x,+y,...]
                    [--counting=total|toplevel|detailed] [--root=subdir]
                    [--linelength=digits]
@@ -175,75 +175,76 @@ Syntax: cpplint.py [--verbose=#] [--output=vs7] [--filter=-x,+y,...]
 # We categorize each error message we print.  Here are the categories.
 # We want an explicit list so we can list them all in cpplint --filter=.
 # If you add a new error message with a new category, add it to the list
 # here!  cpplint_unittest.py should tell you if you forget to do this.
 _ERROR_CATEGORIES = [
     'build/class',
     'build/c++11',
     'build/c++14',
     'build/c++tr1',
     'build/deprecated',
     'build/endif_comment',
     'build/explicit_make_pair',
     'build/forward_decl',
     'build/header_guard',
     'build/include',
     'build/include_alpha',
+    'build/include_directory',
     'build/include_order',
     'build/include_what_you_use',
     'build/namespaces',
     'build/printf_format',
     'build/storage_class',
     'legal/copyright',
     'readability/alt_tokens',
     'readability/braces',
     'readability/casting',
     'readability/check',
     'readability/constructors',
     'readability/fn_size',
     'readability/inheritance',
     'readability/multiline_comment',
     'readability/multiline_string',
     'readability/namespace',
     'readability/nolint',
     'readability/nul',
     'readability/strings',
     'readability/todo',
     'readability/utf8',
     'runtime/arrays',
     'runtime/casting',
     'runtime/explicit',
     'runtime/int',
     'runtime/init',
     'runtime/invalid_increment',
     'runtime/member_string_references',
     'runtime/memset',
     'runtime/indentation_namespace',
     'runtime/operator',
     'runtime/printf',
     'runtime/printf_format',
     'runtime/references',
     'runtime/string',
     'runtime/threadsafe_fn',
     'runtime/vlog',
     'whitespace/blank_line',
     'whitespace/braces',
     'whitespace/comma',
     'whitespace/comments',
     'whitespace/empty_conditional_body',
     'whitespace/empty_if_body',
     'whitespace/empty_loop_body',
     'whitespace/end_of_line',
     'whitespace/ending_newline',
     'whitespace/forcolon',
     'whitespace/indent',
     'whitespace/line_length',
     'whitespace/newline',
     'whitespace/operators',
     'whitespace/parens',
     'whitespace/semicolon',
     'whitespace/tab',
     'whitespace/todo',
     ]
 
 # These error categories are no longer enforced by cpplint, but for backwards-
 # compatibility they may still appear in NOLINT comments.
@@ -275,156 +276,157 @@ _DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [
 # C++ headers
 _CPP_HEADERS = frozenset([
     # Legacy
     'algobase.h',
     'algo.h',
     'alloc.h',
     'builtinbuf.h',
     'bvector.h',
     'complex.h',
     'defalloc.h',
     'deque.h',
     'editbuf.h',
     'fstream.h',
     'function.h',
     'hash_map',
     'hash_map.h',
     'hash_set',
     'hash_set.h',
     'hashtable.h',
     'heap.h',
     'indstream.h',
     'iomanip.h',
     'iostream.h',
     'istream.h',
     'iterator.h',
     'list.h',
     'map.h',
     'multimap.h',
     'multiset.h',
     'ostream.h',
     'pair.h',
     'parsestream.h',
     'pfstream.h',
     'procbuf.h',
     'pthread_alloc',
     'pthread_alloc.h',
     'rope',
     'rope.h',
     'ropeimpl.h',
     'set.h',
     'slist',
     'slist.h',
     'stack.h',
     'stdiostream.h',
     'stl_alloc.h',
     'stl_relops.h',
     'streambuf.h',
     'stream.h',
     'strfile.h',
     'strstream.h',
     'tempbuf.h',
     'tree.h',
     'type_traits.h',
     'vector.h',
     # 17.6.1.2 C++ library headers
     'algorithm',
     'array',
     'atomic',
     'bitset',
     'chrono',
     'codecvt',
     'complex',
     'condition_variable',
     'deque',
     'exception',
     'forward_list',
     'fstream',
     'functional',
     'future',
     'initializer_list',
     'iomanip',
     'ios',
     'iosfwd',
     'iostream',
     'istream',
     'iterator',
     'limits',
     'list',
     'locale',
     'map',
     'memory',
     'mutex',
     'new',
     'numeric',
     'ostream',
     'queue',
     'random',
     'ratio',
     'regex',
     'scoped_allocator',
     'set',
     'sstream',
     'stack',
     'stdexcept',
     'streambuf',
     'string',
+    'string_view',
     'strstream',
     'system_error',
     'thread',
     'tuple',
     'typeindex',
     'typeinfo',
     'type_traits',
     'unordered_map',
     'unordered_set',
     'utility',
     'valarray',
     'vector',
     # 17.6.1.2 C++ headers for C library facilities
     'cassert',
     'ccomplex',
     'cctype',
     'cerrno',
     'cfenv',
     'cfloat',
     'cinttypes',
     'ciso646',
     'climits',
     'clocale',
     'cmath',
     'csetjmp',
     'csignal',
     'cstdalign',
     'cstdarg',
     'cstdbool',
     'cstddef',
     'cstdint',
     'cstdio',
     'cstdlib',
     'cstring',
     'ctgmath',
     'ctime',
     'cuchar',
     'cwchar',
     'cwctype',
     ])
 
 # Type names
 _TYPES = re.compile(
     r'^(?:'
     # [dcl.type.simple]
     r'(char(16_t|32_t)?)|wchar_t|'
     r'bool|short|int|long|signed|unsigned|float|double|'
     # [support.types]
     r'(ptrdiff_t|size_t|max_align_t|nullptr_t)|'
     # [cstdint.syn]
     r'(u?int(_fast|_least)?(8|16|32|64)_t)|'
     r'(u?int(max|ptr)_t)|'
     r')$')
 
 
-# These headers are excluded from [build/include] and [build/include_order]
-# checks:
+# These headers are excluded from [build/include], [build/include_directory],
+# and [build/include_order] checks:
 # - Anything not following google file name conventions (containing an
 #   uppercase character, such as Python.h or nsStringAPI.h, for example).
 # - Lua headers.
@@ -825,90 +827,90 @@ class _IncludeState(object):
 class _CppLintState(object):
   """Maintains module-wide state.."""
 
   def __init__(self):
     self.verbose_level = 1  # global setting.
     self.error_count = 0    # global count of reported errors
     # filters to apply when emitting error messages
     self.filters = _DEFAULT_FILTERS[:]
     # backup of filter list. Used to restore the state after each file.
     self._filters_backup = self.filters[:]
     self.counting = 'total'  # In what way are we counting errors?
     self.errors_by_category = {}  # string to int dict storing error counts
 
     # output format:
     # "emacs" - format that emacs can parse (default)
     # "vs7" - format that Microsoft Visual Studio 7 can parse
     self.output_format = 'emacs'
 
   def SetOutputFormat(self, output_format):
     """Sets the output format for errors."""
     self.output_format = output_format
 
   def SetVerboseLevel(self, level):
     """Sets the module's verbosity, and returns the previous setting."""
     last_verbose_level = self.verbose_level
     self.verbose_level = level
     return last_verbose_level
 
   def SetCountingStyle(self, counting_style):
     """Sets the module's counting options."""
     self.counting = counting_style
 
   def SetFilters(self, filters):
     """Sets the error-message filters.
 
     These filters are applied when deciding whether to emit a given
     error message.
 
     Args:
       filters: A string of comma-separated filters (eg "+whitespace/indent").
                Each filter should start with + or -; else we die.
 
     Raises:
       ValueError: The comma-separated filters did not all start with '+' or '-'.
                   E.g. "-,+whitespace,-whitespace/indent,whitespace/badfilter"
     """
     # Default filters always have less priority than the flag ones.
     self.filters = _DEFAULT_FILTERS[:]
     self.AddFilters(filters)
 
   def AddFilters(self, filters):
     """ Adds more filters to the existing list of error-message filters. """
     for filt in filters.split(','):
       clean_filt = filt.strip()
       if clean_filt:
         self.filters.append(clean_filt)
     for filt in self.filters:
       if not (filt.startswith('+') or filt.startswith('-')):
         raise ValueError('Every filter in --filters must start with + or -'
                          ' (%s does not)' % filt)
 
   def BackupFilters(self):
     """ Saves the current filter list to backup storage."""
     self._filters_backup = self.filters[:]
 
   def RestoreFilters(self):
     """ Restores filters previously backed up."""
     self.filters = self._filters_backup[:]
 
   def ResetErrorCounts(self):
     """Sets the module's error statistic back to zero."""
     self.error_count = 0
     self.errors_by_category = {}
 
   def IncrementErrorCount(self, category):
     """Bumps the module's error statistic."""
     self.error_count += 1
     if self.counting in ('toplevel', 'detailed'):
       if self.counting != 'detailed':
         category = category.split('/')[0]
       if category not in self.errors_by_category:
         self.errors_by_category[category] = 0
       self.errors_by_category[category] += 1
 
   def PrintErrorCounts(self):
     """Print a summary of errors by category, and the total."""
-    for category, count in self.errors_by_category.iteritems():
+    for category, count in self.errors_by_category.items():
       sys.stderr.write('Category \'%s\' errors found: %d\n' %
                        (category, count))
     sys.stderr.write('Total errors found: %d\n' % self.error_count)
@@ -1045,92 +1047,92 @@ class _IncludeError(Exception):
 class FileInfo(object):
   """Provides utility functions for filenames.
 
   FileInfo provides easy access to the components of a file's path
   relative to the project root.
   """
 
   def __init__(self, filename):
     self._filename = filename
 
   def FullName(self):
     """Make Windows paths like Unix."""
     return os.path.abspath(self._filename).replace('\\', '/')
 
   def RepositoryName(self):
-    """FullName after removing the local path to the repository.
+    r"""FullName after removing the local path to the repository.
 
     If we have a real absolute path name here we can try to do something smart:
     detecting the root of the checkout and truncating /path/to/checkout from
     the name so that we get header guards that don't include things like
     "C:\Documents and Settings\..." or "/home/username/..." in them and thus
     people on different computers who have checked the source out to different
     locations won't see bogus errors.
     """
     fullname = self.FullName()
 
     if os.path.exists(fullname):
       project_dir = os.path.dirname(fullname)
 
       if _project_root:
         prefix = os.path.commonprefix([_project_root, project_dir])
         return fullname[len(prefix) + 1:]
 
       if os.path.exists(os.path.join(project_dir, ".svn")):
         # If there's a .svn file in the current directory, we recursively look
         # up the directory tree for the top of the SVN checkout
         root_dir = project_dir
         one_up_dir = os.path.dirname(root_dir)
         while os.path.exists(os.path.join(one_up_dir, ".svn")):
           root_dir = os.path.dirname(root_dir)
           one_up_dir = os.path.dirname(one_up_dir)
 
         prefix = os.path.commonprefix([root_dir, project_dir])
         return fullname[len(prefix) + 1:]
 
       # Not SVN <= 1.6? Try to find a git, hg, or svn top level directory by
       # searching up from the current path.
       root_dir = os.path.dirname(fullname)
       while (root_dir != os.path.dirname(root_dir) and
              not os.path.exists(os.path.join(root_dir, ".git")) and
              not os.path.exists(os.path.join(root_dir, ".hg")) and
              not os.path.exists(os.path.join(root_dir, ".svn"))):
         root_dir = os.path.dirname(root_dir)
 
       if (os.path.exists(os.path.join(root_dir, ".git")) or
           os.path.exists(os.path.join(root_dir, ".hg")) or
           os.path.exists(os.path.join(root_dir, ".svn"))):
         prefix = os.path.commonprefix([root_dir, project_dir])
         return fullname[len(prefix) + 1:]
 
     # Don't know what to do; header guard warnings may be wrong...
     return fullname
 
   def Split(self):
     """Splits the file into the directory, basename, and extension.
 
     For 'chrome/browser/browser.cc', Split() would
     return ('chrome/browser', 'browser', '.cc')
 
     Returns:
       A tuple of (directory, basename, extension).
     """
 
     googlename = self.RepositoryName()
     project, rest = os.path.split(googlename)
     return (project,) + os.path.splitext(rest)
 
   def BaseName(self):
     """File base name - text after the final slash, before the final period."""
     return self.Split()[1]
 
   def Extension(self):
     """File extension - text following the final period."""
     return self.Split()[2]
 
   def NoExtension(self):
     """File has no source file extension."""
     return '/'.join(self.Split()[0:2])
 
   def IsSource(self):
     """File has a source file extension."""
     return _IsSourceExtension(self.Extension()[1:])
@@ -1470,76 +1472,76 @@ class CleansedLines(object):
 def FindEndOfExpressionInLine(line, startpos, stack):
   """Find the position just after the end of current parenthesized expression.
 
   Args:
     line: a CleansedLines line.
     startpos: start searching at this position.
     stack: nesting stack at startpos.
 
   Returns:
     On finding matching end: (index just after matching end, None)
     On finding an unclosed expression: (-1, None)
     Otherwise: (-1, new stack at end of this line)
   """
-  for i in xrange(startpos, len(line)):
+  for i in range(startpos, len(line)):
     char = line[i]
     if char in '([{':
       # Found start of parenthesized expression, push to expression stack
       stack.append(char)
     elif char == '<':
       # Found potential start of template argument list
       if i > 0 and line[i - 1] == '<':
         # Left shift operator
         if stack and stack[-1] == '<':
           stack.pop()
           if not stack:
             return (-1, None)
       elif i > 0 and Search(r'\boperator\s*$', line[0:i]):
         # operator<, don't add to stack
         continue
       else:
         # Tentative start of template argument list
         stack.append('<')
     elif char in ')]}':
       # Found end of parenthesized expression.
       #
       # If we are currently expecting a matching '>', the pending '<'
       # must have been an operator.  Remove them from expression stack.
       while stack and stack[-1] == '<':
         stack.pop()
       if not stack:
         return (-1, None)
       if ((stack[-1] == '(' and char == ')') or
           (stack[-1] == '[' and char == ']') or
           (stack[-1] == '{' and char == '}')):
         stack.pop()
         if not stack:
           return (i + 1, None)
       else:
         # Mismatched parentheses
         return (-1, None)
     elif char == '>':
       # Found potential end of template argument list.
 
       # Ignore "->" and operator functions
       if (i > 0 and
           (line[i - 1] == '-' or Search(r'\boperator\s*$', line[0:i - 1]))):
         continue
 
       # Pop the stack if there is a matching '<'.  Otherwise, ignore
       # this '>' since it must be an operator.
       if stack:
         if stack[-1] == '<':
           stack.pop()
           if not stack:
             return (i + 1, None)
     elif char == ';':
       # Found something that look like end of statements.  If we are currently
       # expecting a '>', the matching '<' must have been an operator, since
       # template argument list should not contain statements.
       while stack and stack[-1] == '<':
         stack.pop()
       if not stack:
         return (-1, None)
 
   # Did not find end of expression or unbalanced parentheses on this line
   return (-1, stack)
@@ -1707,11 +1709,11 @@ def ReverseCloseExpression(clean_lines, linenum, pos):
 def CheckForCopyright(filename, lines, error):
   """Logs an error if no Copyright message appears at the top of the file."""
 
   # We'll say it should occur by line 10. Don't forget there's a
   # dummy line at the front.
-  for line in xrange(1, min(len(lines), 11)):
+  for line in range(1, min(len(lines), 11)):
     if re.search(r'Copyright', lines[line], re.I): break
   else:                       # means no copyright line was found
     error(filename, 0, 'legal/copyright', 5,
           'No copyright message found.  '
           'You should have a line: "Copyright [year] <Copyright Owner>"')
@@ -1762,96 +1764,96 @@ def GetHeaderGuardCPPVariable(filename):
 def CheckForHeaderGuard(filename, clean_lines, error):
   """Checks that the file contains a header guard.
 
   Logs an error if no #ifndef header guard is present.  For other
   headers, checks that the full pathname is used.
 
   Args:
     filename: The name of the C++ header file.
     clean_lines: A CleansedLines instance containing the file.
     error: The function to call with any errors found.
   """
 
   # Don't check for header guards if there are error suppression
   # comments somewhere in this file.
   #
   # Because this is silencing a warning for a nonexistent line, we
   # only support the very specific NOLINT(build/header_guard) syntax,
   # and not the general NOLINT or NOLINT(*) syntax.
   raw_lines = clean_lines.lines_without_raw_strings
   for i in raw_lines:
     if Search(r'//\s*NOLINT\(build/header_guard\)', i):
       return
 
   cppvar = GetHeaderGuardCPPVariable(filename)
 
   ifndef = ''
   ifndef_linenum = 0
   define = ''
   endif = ''
   endif_linenum = 0
   for linenum, line in enumerate(raw_lines):
     linesplit = line.split()
     if len(linesplit) >= 2:
       # find the first occurrence of #ifndef and #define, save arg
       if not ifndef and linesplit[0] == '#ifndef':
         # set ifndef to the header guard presented on the #ifndef line.
         ifndef = linesplit[1]
         ifndef_linenum = linenum
       if not define and linesplit[0] == '#define':
         define = linesplit[1]
     # find the last occurrence of #endif, save entire line
     if line.startswith('#endif'):
       endif = line
       endif_linenum = linenum
 
   if not ifndef or not define or ifndef != define:
     error(filename, 0, 'build/header_guard', 5,
           'No #ifndef header guard found, suggested CPP variable is: %s' %
           cppvar)
     return
 
   # The guard should be PATH_FILE_H_, but we also allow PATH_FILE_H__
   # for backward compatibility.
   if ifndef != cppvar:
     error_level = 0
     if ifndef != cppvar + '_':
       error_level = 5
 
     ParseNolintSuppressions(filename, raw_lines[ifndef_linenum], ifndef_linenum,
                             error)
     error(filename, ifndef_linenum, 'build/header_guard', error_level,
           '#ifndef header guard has wrong style, please use: %s' % cppvar)
 
   # Check for "//" comments on endif line.
   ParseNolintSuppressions(filename, raw_lines[endif_linenum], endif_linenum,
                           error)
   match = Match(r'#endif\s*//\s*' + cppvar + r'(_)?\b', endif)
   if match:
     if match.group(1) == '_':
       # Issue low severity warning for deprecated double trailing underscore
       error(filename, endif_linenum, 'build/header_guard', 0,
             '#endif line should be "#endif  // %s"' % cppvar)
     return
 
   # Didn't find the corresponding "//" comment.  If this file does not
   # contain any "//" comments at all, it could be that the compiler
   # only wants "/**/" comments, look for those instead.
   no_single_line_comments = True
-  for i in xrange(1, len(raw_lines) - 1):
+  for i in range(1, len(raw_lines) - 1):
     line = raw_lines[i]
     if Match(r'^(?:(?:\'(?:\.|[^\'])*\')|(?:"(?:\.|[^"])*")|[^\'"])*//', line):
       no_single_line_comments = False
       break
 
   if no_single_line_comments:
     match = Match(r'#endif\s*/\*\s*' + cppvar + r'(_)?\s*\*/', endif)
     if match:
       if match.group(1) == '_':
         # Low severity warning for double trailing underscore
         error(filename, endif_linenum, 'build/header_guard', 0,
               '#endif line should be "#endif  /* %s */"' % cppvar)
       return
 
   # Didn't find anything
   error(filename, endif_linenum, 'build/header_guard', 5,
         '#endif line should be "#endif  // %s"' % cppvar)
@@ -2139,67 +2141,67 @@ class _ExternCInfo(_BlockInfo):
 class _ClassInfo(_BlockInfo):
   """Stores information about a class."""
 
   def __init__(self, name, class_or_struct, clean_lines, linenum):
     _BlockInfo.__init__(self, linenum, False)
     self.name = name
     self.is_derived = False
     self.check_namespace_indentation = True
     if class_or_struct == 'struct':
       self.access = 'public'
       self.is_struct = True
     else:
       self.access = 'private'
       self.is_struct = False
 
     # Remember initial indentation level for this class.  Using raw_lines here
     # instead of elided to account for leading comments.
     self.class_indent = GetIndentLevel(clean_lines.raw_lines[linenum])
 
     # Try to find the end of the class.  This will be confused by things like:
     #   class A {
     #   } *x = { ...
     #
     # But it's still good enough for CheckSectionSpacing.
     self.last_line = 0
     depth = 0
     for i in range(linenum, clean_lines.NumLines()):
       line = clean_lines.elided[i]
       depth += line.count('{') - line.count('}')
       if not depth:
         self.last_line = i
         break
 
   def CheckBegin(self, filename, clean_lines, linenum, error):
     # Look for a bare ':'
     if Search('(^|[^:]):($|[^:])', clean_lines.elided[linenum]):
       self.is_derived = True
 
   def CheckEnd(self, filename, clean_lines, linenum, error):
     # If there is a DISALLOW macro, it should appear near the end of
     # the class.
     seen_last_thing_in_class = False
-    for i in xrange(linenum - 1, self.starting_linenum, -1):
+    for i in range(linenum - 1, self.starting_linenum, -1):
       match = Search(
           r'\b(DISALLOW_COPY_AND_ASSIGN|DISALLOW_IMPLICIT_CONSTRUCTORS)\(' +
           self.name + r'\)',
           clean_lines.elided[i])
       if match:
         if seen_last_thing_in_class:
           error(filename, i, 'readability/constructors', 3,
                 match.group(1) + ' should be the last thing in the class')
         break
 
       if not Match(r'^\s*$', clean_lines.elided[i]):
         seen_last_thing_in_class = True
 
     # Check that closing brace is aligned with beginning of the class.
     # Only do this if the closing brace is indented by only whitespaces.
     # This means we will not check single-line class definitions.
     indent = Match(r'^( *)\}', clean_lines.elided[linenum])
     if indent and len(indent.group(1)) != self.class_indent:
       if self.is_struct:
         parent = 'struct ' + self.name
       else:
         parent = 'class ' + self.name
       error(filename, linenum, 'whitespace/indent', 3,
             'Closing brace should be aligned with beginning of %s' % parent)
@@ -2283,372 +2285,372 @@ class _PreprocessorInfo(object):
 class NestingState(object):
   """Holds states related to parsing braces."""
 
   def __init__(self):
     # Stack for tracking all braces.  An object is pushed whenever we
     # see a "{", and popped when we see a "}".  Only 3 types of
     # objects are possible:
     # - _ClassInfo: a class or struct.
     # - _NamespaceInfo: a namespace.
     # - _BlockInfo: some other type of block.
     self.stack = []
 
     # Top of the previous stack before each Update().
     #
     # Because the nesting_stack is updated at the end of each line, we
     # had to do some convoluted checks to find out what is the current
     # scope at the beginning of the line.  This check is simplified by
     # saving the previous top of nesting stack.
     #
     # We could save the full stack, but we only need the top.  Copying
     # the full nesting stack would slow down cpplint by ~10%.
     self.previous_stack_top = []
 
     # Stack of _PreprocessorInfo objects.
     self.pp_stack = []
 
   def SeenOpenBrace(self):
     """Check if we have seen the opening brace for the innermost block.
 
     Returns:
       True if we have seen the opening brace, False if the innermost
       block is still expecting an opening brace.
     """
     return (not self.stack) or self.stack[-1].seen_open_brace
 
   def InNamespaceBody(self):
     """Check if we are currently one level inside a namespace body.
 
     Returns:
       True if top of the stack is a namespace block, False otherwise.
     """
     return self.stack and isinstance(self.stack[-1], _NamespaceInfo)
 
   def InExternC(self):
     """Check if we are currently one level inside an 'extern "C"' block.
 
     Returns:
       True if top of the stack is an extern block, False otherwise.
     """
     return self.stack and isinstance(self.stack[-1], _ExternCInfo)
 
   def InClassDeclaration(self):
     """Check if we are currently one level inside a class or struct declaration.
 
     Returns:
       True if top of the stack is a class/struct, False otherwise.
     """
     return self.stack and isinstance(self.stack[-1], _ClassInfo)
 
   def InAsmBlock(self):
     """Check if we are currently one level inside an inline ASM block.
 
     Returns:
       True if the top of the stack is a block containing inline ASM.
     """
     return self.stack and self.stack[-1].inline_asm != _NO_ASM
 
   def InTemplateArgumentList(self, clean_lines, linenum, pos):
     """Check if current position is inside template argument list.
 
     Args:
       clean_lines: A CleansedLines instance containing the file.
       linenum: The number of the line to check.
       pos: position just after the suspected template argument.
     Returns:
       True if (linenum, pos) is inside template arguments.
     """
     while linenum < clean_lines.NumLines():
       # Find the earliest character that might indicate a template argument
       line = clean_lines.elided[linenum]
       match = Match(r'^[^{};=\[\]\.<>]*(.)', line[pos:])
       if not match:
         linenum += 1
         pos = 0
         continue
       token = match.group(1)
       pos += len(match.group(0))
 
       # These things do not look like template argument list:
       #   class Suspect {
       #   class Suspect x; }
       if token in ('{', '}', ';'): return False
 
       # These things look like template argument list:
       #   template <class Suspect>
       #   template <class Suspect = default_value>
       #   template <class Suspect[]>
       #   template <class Suspect...>
       if token in ('>', '=', '[', ']', '.'): return True
 
       # Check if token is an unmatched '<'.
       # If not, move on to the next character.
       if token != '<':
         pos += 1
         if pos >= len(line):
           linenum += 1
           pos = 0
         continue
 
       # We can't be sure if we just find a single '<', and need to
       # find the matching '>'.
       (_, end_line, end_pos) = CloseExpression(clean_lines, linenum, pos - 1)
       if end_pos < 0:
         # Not sure if template argument list or syntax error in file
         return False
       linenum = end_line
       pos = end_pos
     return False
 
   def UpdatePreprocessor(self, line):
     """Update preprocessor stack.
 
     We need to handle preprocessors due to classes like this:
       #ifdef SWIG
       struct ResultDetailsPageElementExtensionPoint {
       #else
       struct ResultDetailsPageElementExtensionPoint : public Extension {
       #endif
 
     We make the following assumptions (good enough for most files):
     - Preprocessor condition evaluates to true from #if up to first
       #else/#elif/#endif.
 
     - Preprocessor condition evaluates to false from #else/#elif up
       to #endif.  We still perform lint checks on these lines, but
       these do not affect nesting stack.
 
     Args:
       line: current line to check.
     """
     if Match(r'^\s*#\s*(if|ifdef|ifndef)\b', line):
       # Beginning of #if block, save the nesting stack here.  The saved
       # stack will allow us to restore the parsing state in the #else case.
       self.pp_stack.append(_PreprocessorInfo(copy.deepcopy(self.stack)))
     elif Match(r'^\s*#\s*(else|elif)\b', line):
       # Beginning of #else block
       if self.pp_stack:
         if not self.pp_stack[-1].seen_else:
           # This is the first #else or #elif block.  Remember the
           # whole nesting stack up to this point.  This is what we
           # keep after the #endif.
           self.pp_stack[-1].seen_else = True
           self.pp_stack[-1].stack_before_else = copy.deepcopy(self.stack)
 
         # Restore the stack to how it was before the #if
         self.stack = copy.deepcopy(self.pp_stack[-1].stack_before_if)
       else:
         # TODO(unknown): unexpected #else, issue warning?
         pass
     elif Match(r'^\s*#\s*endif\b', line):
       # End of #if or #else blocks.
       if self.pp_stack:
         # If we saw an #else, we will need to restore the nesting
         # stack to its former state before the #else, otherwise we
         # will just continue from where we left off.
         if self.pp_stack[-1].seen_else:
           # Here we can just use a shallow copy since we are the last
           # reference to it.
           self.stack = self.pp_stack[-1].stack_before_else
         # Drop the corresponding #if
         self.pp_stack.pop()
       else:
         # TODO(unknown): unexpected #endif, issue warning?
         pass
 
   # TODO(unknown): Update() is too long, but we will refactor later.
   def Update(self, filename, clean_lines, linenum, error):
     """Update nesting state with current line.
 
     Args:
       filename: The name of the current file.
       clean_lines: A CleansedLines instance containing the file.
       linenum: The number of the line to check.
       error: The function to call with any errors found.
     """
     line = clean_lines.elided[linenum]
 
     # Remember top of the previous nesting stack.
     #
     # The stack is always pushed/popped and not modified in place, so
     # we can just do a shallow copy instead of copy.deepcopy.  Using
     # deepcopy would slow down cpplint by ~28%.
     if self.stack:
       self.previous_stack_top = self.stack[-1]
     else:
       self.previous_stack_top = None
 
     # Update pp_stack
     self.UpdatePreprocessor(line)
 
     # Count parentheses.  This is to avoid adding struct arguments to
     # the nesting stack.
     if self.stack:
       inner_block = self.stack[-1]
       depth_change = line.count('(') - line.count(')')
       inner_block.open_parentheses += depth_change
 
       # Also check if we are starting or ending an inline assembly block.
       if inner_block.inline_asm in (_NO_ASM, _END_ASM):
         if (depth_change != 0 and
             inner_block.open_parentheses == 1 and
             _MATCH_ASM.match(line)):
           # Enter assembly block
           inner_block.inline_asm = _INSIDE_ASM
         else:
           # Not entering assembly block.  If previous line was _END_ASM,
           # we will now shift to _NO_ASM state.
           inner_block.inline_asm = _NO_ASM
       elif (inner_block.inline_asm == _INSIDE_ASM and
             inner_block.open_parentheses == 0):
         # Exit assembly block
         inner_block.inline_asm = _END_ASM
 
     # Consume namespace declaration at the beginning of the line.  Do
     # this in a loop so that we catch same line declarations like this:
     #   namespace proto2 { namespace bridge { class MessageSet; } }
     while True:
       # Match start of namespace.  The "\b\s*" below catches namespace
       # declarations even if it weren't followed by a whitespace, this
       # is so that we don't confuse our namespace checker.  The
       # missing spaces will be flagged by CheckSpacing.
       namespace_decl_match = Match(r'^\s*namespace\b\s*([:\w]+)?(.*)$', line)
       if not namespace_decl_match:
         break
 
       new_namespace = _NamespaceInfo(namespace_decl_match.group(1), linenum)
       self.stack.append(new_namespace)
 
       line = namespace_decl_match.group(2)
       if line.find('{') != -1:
         new_namespace.seen_open_brace = True
         line = line[line.find('{') + 1:]
 
     # Look for a class declaration in whatever is left of the line
     # after parsing namespaces.  The regexp accounts for decorated classes
     # such as in:
     #   class LOCKABLE API Object {
     #   };
     class_decl_match = Match(
         r'^(\s*(?:template\s*<[\w\s<>,:]*>\s*)?'
-        r'(class|struct)\s+(?:[A-Z_]+\s+)*(\w+(?:::\w+)*))'
+        r'(class|struct)\s+(?:[A-Z0-9_]+\s+)*(\w+(?:::\w+)*))'
         r'(.*)$', line)
     if (class_decl_match and
         (not self.stack or self.stack[-1].open_parentheses == 0)):
       # We do not want to accept classes that are actually template arguments:
       #   template <class Ignore1,
       #             class Ignore2 = Default<Args>,
       #             template <Args> class Ignore3>
       #   void Function() {};
       #
       # To avoid template argument cases, we scan forward and look for
       # an unmatched '>'.  If we see one, assume we are inside a
       # template argument list.
       end_declaration = len(class_decl_match.group(1))
       if not self.InTemplateArgumentList(clean_lines, linenum, end_declaration):
         self.stack.append(_ClassInfo(
             class_decl_match.group(3), class_decl_match.group(2),
             clean_lines, linenum))
         line = class_decl_match.group(4)
 
     # If we have not yet seen the opening brace for the innermost block,
     # run checks here.
     if not self.SeenOpenBrace():
       self.stack[-1].CheckBegin(filename, clean_lines, linenum, error)
 
     # Update access control if we are inside a class/struct
     if self.stack and isinstance(self.stack[-1], _ClassInfo):
       classinfo = self.stack[-1]
       access_match = Match(
           r'^(.*)\b(public|private|protected|signals)(\s+(?:slots\s*)?)?'
           r':(?:[^:]|$)',
           line)
       if access_match:
         classinfo.access = access_match.group(2)
 
         # Check that access keywords are indented +1 space.  Skip this
         # check if the keywords are not preceded by whitespaces.
         indent = access_match.group(1)
         if (len(indent) != classinfo.class_indent + 1 and
             Match(r'^\s*$', indent)):
           if classinfo.is_struct:
             parent = 'struct ' + classinfo.name
           else:
             parent = 'class ' + classinfo.name
           slots = ''
           if access_match.group(3):
             slots = access_match.group(3)
           error(filename, linenum, 'whitespace/indent', 3,
                 '%s%s: should be indented +1 space inside %s' % (
                     access_match.group(2), slots, parent))
 
     # Consume braces or semicolons from what's left of the line
     while True:
       # Match first brace, semicolon, or closed parenthesis.
       matched = Match(r'^[^{;)}]*([{;)}])(.*)$', line)
       if not matched:
         break
 
       token = matched.group(1)
       if token == '{':
         # If namespace or class hasn't seen a opening brace yet, mark
         # namespace/class head as complete.  Push a new block onto the
         # stack otherwise.
         if not self.SeenOpenBrace():
           self.stack[-1].seen_open_brace = True
         elif Match(r'^extern\s*"[^"]*"\s*\{', line):
           self.stack.append(_ExternCInfo(linenum))
         else:
           self.stack.append(_BlockInfo(linenum, True))
           if _MATCH_ASM.match(line):
             self.stack[-1].inline_asm = _BLOCK_ASM
 
       elif token == ';' or token == ')':
         # If we haven't seen an opening brace yet, but we already saw
         # a semicolon, this is probably a forward declaration.  Pop
         # the stack for these.
         #
         # Similarly, if we haven't seen an opening brace yet, but we
         # already saw a closing parenthesis, then these are probably
         # function arguments with extra "class" or "struct" keywords.
         # Also pop these stack for these.
         if not self.SeenOpenBrace():
           self.stack.pop()
       else:  # token == '}'
         # Perform end of block checks and pop the stack.
         if self.stack:
           self.stack[-1].CheckEnd(filename, clean_lines, linenum, error)
           self.stack.pop()
       line = matched.group(2)
 
   def InnermostClass(self):
     """Get class info on the top of the stack.
 
     Returns:
       A _ClassInfo object if we are inside a class, or None otherwise.
     """
     for i in range(len(self.stack), 0, -1):
       classinfo = self.stack[i - 1]
       if isinstance(classinfo, _ClassInfo):
         return classinfo
     return None
 
   def CheckCompletedBlocks(self, filename, error):
     """Checks that all classes and namespaces have been completely parsed.
 
     Call this when all lines in a file have been processed.
     Args:
       filename: The name of the current file.
       error: The function to call with any errors found.
     """
     # Note: This test can result in false positives if #ifdef constructs
     # get in the way of brace matching. See the testBuildClass test in
     # cpplint_unittest.py for an example of this.
     for obj in self.stack:
       if isinstance(obj, _ClassInfo):
         error(filename, obj.starting_linenum, 'build/class', 5,
               'Failed to find complete declaration of class %s' %
               obj.name)
       elif isinstance(obj, _NamespaceInfo):
         error(filename, obj.starting_linenum, 'build/namespaces', 5,
               'Failed to find complete declaration of namespace %s' %
               obj.name)
@@ -2817,75 +2819,75 @@ def CheckForNonStandardConstructs(filename, clean_lines, linenum,
 def CheckSpacingForFunctionCall(filename, clean_lines, linenum, error):
   """Checks for the correctness of various spacing around function calls.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     error: The function to call with any errors found.
   """
   line = clean_lines.elided[linenum]
 
   # Since function calls often occur inside if/for/while/switch
   # expressions - which have their own, more liberal conventions - we
   # first see if we should be looking inside such an expression for a
   # function call, to which we can apply more strict standards.
   fncall = line    # if there's no control flow construct, look at whole line
   for pattern in (r'\bif\s*\((.*)\)\s*{',
                   r'\bfor\s*\((.*)\)\s*{',
                   r'\bwhile\s*\((.*)\)\s*[{;]',
                   r'\bswitch\s*\((.*)\)\s*{'):
     match = Search(pattern, line)
     if match:
       fncall = match.group(1)    # look inside the parens for function calls
       break
 
   # Except in if/for/while/switch, there should never be space
   # immediately inside parens (eg "f( 3, 4 )").  We make an exception
   # for nested parens ( (a+b) + c ).  Likewise, there should never be
   # a space before a ( when it's a function argument.  I assume it's a
   # function argument when the char before the whitespace is legal in
   # a function name (alnum + _) and we're not starting a macro. Also ignore
   # pointers and references to arrays and functions coz they're too tricky:
   # we use a very simple way to recognize these:
   # " (something)(maybe-something)" or
   # " (something)(maybe-something," or
   # " (something)[something]"
   # Note that we assume the contents of [] to be short enough that
   # they'll never need to wrap.
   if (  # Ignore control structures.
       not Search(r'\b(if|for|while|switch|return|new|delete|catch|sizeof)\b',
                  fncall) and
       # Ignore pointers/references to functions.
       not Search(r' \([^)]+\)\([^)]*(\)|,$)', fncall) and
       # Ignore pointers/references to arrays.
       not Search(r' \([^)]+\)\[[^\]]+\]', fncall)):
     if Search(r'\w\s*\(\s(?!\s*\\$)', fncall):      # a ( used for a fn call
       error(filename, linenum, 'whitespace/parens', 4,
             'Extra space after ( in function call')
     elif Search(r'\(\s+(?!(\s*\\)|\()', fncall):
       error(filename, linenum, 'whitespace/parens', 2,
             'Extra space after (')
     if (Search(r'\w\s+\(', fncall) and
         not Search(r'_{0,2}asm_{0,2}\s+_{0,2}volatile_{0,2}\s+\(', fncall) and
-        not Search(r'#\s*define|typedef|using\s+\w+\s*=', fncall) and
+        not Search(r'#\s*define|typedef|__except|using\s+\w+\s*=', fncall) and
         not Search(r'\w\s+\((\w+::)*\*\w+\)\(', fncall) and
         not Search(r'\bcase\s+\(', fncall)):
       # TODO(unknown): Space after an operator function seem to be a common
       # error, silence those for now by restricting them to highest verbosity.
       if Search(r'\boperator_*\b', line):
         error(filename, linenum, 'whitespace/parens', 0,
               'Extra space before ( in function call')
       else:
         error(filename, linenum, 'whitespace/parens', 4,
               'Extra space before ( in function call')
     # If the ) is followed only by a newline or a { + newline, assume it's
     # part of a control statement (if/while/etc), and don't complain
     if Search(r'[^)]\s+\)\s*[^{\s]', fncall):
       # If the closing parenthesis is preceded by only whitespaces,
       # try to give a more descriptive error message.
       if Search(r'^\s+\)', fncall):
         error(filename, linenum, 'whitespace/parens', 2,
               'Closing ) should be moved to the previous line')
       else:
         error(filename, linenum, 'whitespace/parens', 2,
               'Extra space before )')
@@ -2923,66 +2925,66 @@ def CheckForNamespaceIndentation(filename, nesting_state, clean_lines, line,
 def CheckForFunctionLengths(filename, clean_lines, linenum,
                             function_state, error):
   """Reports for long function bodies.
 
   For an overview why this is done, see:
   https://google.github.io/styleguide/cppguide.html#Write_Short_Functions
 
   Uses a simplistic algorithm assuming other style guidelines
   (especially spacing) are followed.
   Only checks unindented functions, so class members are unchecked.
   Trivial bodies are unchecked, so constructors with huge initializer lists
   may be missed.
   Blank/comment lines are not counted so as to avoid encouraging the removal
   of vertical space and comments just to get through a lint check.
   NOLINT *on the last line of a function* disables this check.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     function_state: Current function name and lines in body so far.
     error: The function to call with any errors found.
   """
   lines = clean_lines.lines
   line = lines[linenum]
   joined_line = ''
 
   starting_func = False
   regexp = r'(\w(\w|::|\*|\&|\s)*)\('  # decls * & space::name( ...
   match_result = Match(regexp, line)
   if match_result:
     # If the name is all caps and underscores, figure it's a macro and
     # ignore it, unless it's TEST or TEST_F.
     function_name = match_result.group(1).split()[-1]
     if function_name == 'TEST' or function_name == 'TEST_F' or (
-        not Match(r'[A-Z_]+$', function_name)):
+        not Match(r'[A-Z_0-9]+$', function_name)):
       starting_func = True
 
   if starting_func:
     body_found = False
-    for start_linenum in xrange(linenum, clean_lines.NumLines()):
+    for start_linenum in range(linenum, clean_lines.NumLines()):
       start_line = lines[start_linenum]
       joined_line += ' ' + start_line.lstrip()
       if Search(r'(;|})', start_line):  # Declarations and trivial functions
         body_found = True
         break                              # ... ignore
       elif Search(r'{', start_line):
         body_found = True
         function = Search(r'((\w|:)*)\(', line).group(1)
         if Match(r'TEST', function):    # Handle TEST... macros
           parameter_regexp = Search(r'(\(.*\))', joined_line)
           if parameter_regexp:             # Ignore bad syntax
             function += parameter_regexp.group(1)
         else:
           function += '()'
         function_state.Begin(function)
         break
     if not body_found:
       # No body for the function (or evidence of a non-function) was found.
       error(filename, linenum, 'readability/fn_size', 5,
             'Lint failed to find start of function body.')
   elif Match(r'^\}\s*$', line):  # function end
     function_state.Check(error, filename, linenum)
     function_state.End()
   elif not Match(r'^\s*$', line):
     function_state.Count()  # Count non-blank/non-comment lines.
@@ -3048,126 +3050,129 @@ def CheckComment(line, filename, linenum, next_line_start, error):
 def CheckSpacing(filename, clean_lines, linenum, nesting_state, error):
   """Checks for the correctness of various spacing issues in the code.
 
   Things we check for: spaces around operators, spaces after
   if/for/while/switch, no spaces around parens in function calls, two
   spaces between code and comment, don't start a block with a blank
   line, don't end a function with a blank line, don't add a blank line
   after public/protected/private, don't have too many blank lines in a row.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     nesting_state: A NestingState instance which maintains information about
                    the current stack of nested blocks being parsed.
     error: The function to call with any errors found.
   """
 
   # Don't use "elided" lines here, otherwise we can't check commented lines.
   # Don't want to use "raw" either, because we don't want to check inside C++11
   # raw strings,
   raw = clean_lines.lines_without_raw_strings
   line = raw[linenum]
 
   # Before nixing comments, check if the line is blank for no good
   # reason.  This includes the first line after a block is opened, and
   # blank lines at the end of a function (ie, right before a line like '}'
   #
   # Skip all the blank line checks if we are immediately inside a
   # namespace body.  In other words, don't issue blank line warnings
   # for this block:
   #   namespace {
   #
   #   }
   #
   # A warning about missing end of namespace comments will be issued instead.
   #
   # Also skip blank line checks for 'extern "C"' blocks, which are formatted
   # like namespaces.
   if (IsBlankLine(line) and
       not nesting_state.InNamespaceBody() and
       not nesting_state.InExternC()):
     elided = clean_lines.elided
     prev_line = elided[linenum - 1]
     prevbrace = prev_line.rfind('{')
     # TODO(unknown): Don't complain if line before blank line, and line after,
     #                both start with alnums and are indented the same amount.
     #                This ignores whitespace at the start of a namespace block
     #                because those are not usually indented.
     if prevbrace != -1 and prev_line[prevbrace:].find('}') == -1:
       # OK, we have a blank line at the start of a code block.  Before we
       # complain, we check if it is an exception to the rule: The previous
       # non-empty line has the parameters of a function header that are indented
       # 4 spaces (because they did not fit in a 80 column line when placed on
       # the same line as the function name).  We also check for the case where
       # the previous line is indented 6 spaces, which may happen when the
       # initializers of a constructor do not fit into a 80 column line.
       exception = False
       if Match(r' {6}\w', prev_line):  # Initializer list?
         # We are looking for the opening column of initializer list, which
         # should be indented 4 spaces to cause 6 space indentation afterwards.
         search_position = linenum-2
         while (search_position >= 0
                and Match(r' {6}\w', elided[search_position])):
           search_position -= 1
         exception = (search_position >= 0
                      and elided[search_position][:5] == '    :')
       else:
         # Search for the function arguments or an initializer list.  We use a
         # simple heuristic here: If the line is indented 4 spaces; and we have a
         # closing paren, without the opening paren, followed by an opening brace
         # or colon (for initializer lists) we assume that it is the last line of
         # a function header.  If we have a colon indented 4 spaces, it is an
         # initializer list.
         exception = (Match(r' {4}\w[^\(]*\)\s*(const\s*)?(\{\s*$|:)',
                            prev_line)
                      or Match(r' {4}:', prev_line))
 
       if not exception:
         error(filename, linenum, 'whitespace/blank_line', 2,
               'Redundant blank line at the start of a code block '
               'should be deleted.')
     # Ignore blank lines at the end of a block in a long if-else
     # chain, like this:
     #   if (condition1) {
     #     // Something followed by a blank line
     #
     #   } else if (condition2) {
     #     // Something else
     #   }
     if linenum + 1 < clean_lines.NumLines():
       next_line = raw[linenum + 1]
       if (next_line
           and Match(r'\s*}', next_line)
           and next_line.find('} else ') == -1):
         error(filename, linenum, 'whitespace/blank_line', 3,
               'Redundant blank line at the end of a code block '
               'should be deleted.')
 
     matched = Match(r'\s*(public|protected|private):', prev_line)
     if matched:
       error(filename, linenum, 'whitespace/blank_line', 3,
             'Do not leave a blank line after "%s:"' % matched.group(1))
 
   # Next, check comments
   next_line_start = 0
   if linenum + 1 < clean_lines.NumLines():
     next_line = raw[linenum + 1]
     next_line_start = len(next_line) - len(next_line.lstrip())
   CheckComment(line, filename, linenum, next_line_start, error)
 
   # get rid of comments and strings
   line = clean_lines.elided[linenum]
 
   # You shouldn't have spaces before your brackets, except maybe after
-  # 'delete []' or 'return []() {};'
-  if Search(r'\w\s+\[', line) and not Search(r'(?:delete|return)\s+\[', line):
+  # 'delete []' or 'return []() {};', or in the case of c++ attributes
+  # like 'class [[clang::lto_visibility_public]] MyClass'.
+  if (Search(r'\w\s+\[', line)
+      and not Search(r'(?:delete|return)\s+\[', line)
+      and not Search(r'\s+\[\[', line)):
     error(filename, linenum, 'whitespace/braces', 5,
           'Extra space before [')
 
   # In range-based for, we wanted spaces before and after the colon, but
   # not around "::" tokens that might appear.
   if (Search(r'for *\(.*[^:]:[^: ]', line) or
       Search(r'for *\(.*[^: ]:[^:]', line)):
     error(filename, linenum, 'whitespace/forcolon', 2,
           'Missing space around colon in range-based for loop')
@@ -3365,61 +3370,61 @@ def CheckCommaSpacing(filename, clean_lines, linenum, error):
 def _IsType(clean_lines, nesting_state, expr):
   """Check if expression looks like a type name, returns true if so.
 
   Args:
     clean_lines: A CleansedLines instance containing the file.
     nesting_state: A NestingState instance which maintains information about
                    the current stack of nested blocks being parsed.
     expr: The expression to check.
   Returns:
     True, if token looks like a type.
   """
   # Keep only the last token in the expression
   last_word = Match(r'^.*(\b\S+)$', expr)
   if last_word:
     token = last_word.group(1)
   else:
     token = expr
 
   # Match native types and stdint types
   if _TYPES.match(token):
     return True
 
   # Try a bit harder to match templated types.  Walk up the nesting
   # stack until we find something that resembles a typename
   # declaration for what we are looking for.
   typename_pattern = (r'\b(?:typename|class|struct)\s+' + re.escape(token) +
                       r'\b')
   block_index = len(nesting_state.stack) - 1
   while block_index >= 0:
     if isinstance(nesting_state.stack[block_index], _NamespaceInfo):
       return False
 
     # Found where the opening brace is.  We want to scan from this
     # line up to the beginning of the function, minus a few lines.
     #   template <typename Type1,  // stop scanning here
     #             ...>
     #   class C
     #     : public ... {  // start scanning here
     last_line = nesting_state.stack[block_index].starting_linenum
 
     next_block_start = 0
     if block_index > 0:
       next_block_start = nesting_state.stack[block_index - 1].starting_linenum
     first_line = last_line
     while first_line >= next_block_start:
       if clean_lines.elided[first_line].find('template') >= 0:
         break
       first_line -= 1
     if first_line < next_block_start:
       # Didn't find any "template" keyword before reaching the next block,
       # there are probably no template things to check for this block
       block_index -= 1
       continue
 
     # Look for typename in the specified range
-    for i in xrange(first_line, last_line + 1, 1):
+    for i in range(first_line, last_line + 1, 1):
       if Search(typename_pattern, clean_lines.elided[i]):
         return True
     block_index -= 1
 
   return False
@@ -3428,87 +3433,87 @@ def _IsType(clean_lines, nesting_state, expr):
 def CheckBracesSpacing(filename, clean_lines, linenum, nesting_state, error):
   """Checks for horizontal spacing near commas.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     nesting_state: A NestingState instance which maintains information about
                    the current stack of nested blocks being parsed.
     error: The function to call with any errors found.
   """
   line = clean_lines.elided[linenum]
 
   # Except after an opening paren, or after another opening brace (in case of
   # an initializer list, for instance), you should have spaces before your
   # braces when they are delimiting blocks, classes, namespaces etc.
   # And since you should never have braces at the beginning of a line,
   # this is an easy test.  Except that braces used for initialization don't
   # follow the same rule; we often don't want spaces before those.
   match = Match(r'^(.*[^ ({>]){', line)
 
   if match:
     # Try a bit harder to check for brace initialization.  This
     # happens in one of the following forms:
     #   Constructor() : initializer_list_{} { ... }
     #   Constructor{}.MemberFunction()
     #   Type variable{};
     #   FunctionCall(type{}, ...);
     #   LastArgument(..., type{});
     #   LOG(INFO) << type{} << " ...";
     #   map_of_type[{...}] = ...;
     #   ternary = expr ? new type{} : nullptr;
     #   OuterTemplate<InnerTemplateConstructor<Type>{}>
     #
     # We check for the character following the closing brace, and
     # silence the warning if it's one of those listed above, i.e.
     # "{.;,)<>]:".
     #
     # To account for nested initializer list, we allow any number of
     # closing braces up to "{;,)<".  We can't simply silence the
     # warning on first sight of closing brace, because that would
     # cause false negatives for things that are not initializer lists.
     #   Silence this:         But not this:
     #     Outer{                if (...) {
     #       Inner{...}            if (...){  // Missing space before {
     #     };                    }
     #
     # There is a false negative with this approach if people inserted
     # spurious semicolons, e.g. "if (cond){};", but we will catch the
     # spurious semicolon with a separate check.
     leading_text = match.group(1)
     (endline, endlinenum, endpos) = CloseExpression(
         clean_lines, linenum, len(match.group(1)))
     trailing_text = ''
     if endpos > -1:
       trailing_text = endline[endpos:]
-    for offset in xrange(endlinenum + 1,
+    for offset in range(endlinenum + 1,
                          min(endlinenum + 3, clean_lines.NumLines() - 1)):
       trailing_text += clean_lines.elided[offset]
     # We also suppress warnings for `uint64_t{expression}` etc., as the style
     # guide recommends brace initialization for integral types to avoid
     # overflow/truncation.
     if (not Match(r'^[\s}]*[{.;,)<>\]:]', trailing_text)
         and not _IsType(clean_lines, nesting_state, leading_text)):
       error(filename, linenum, 'whitespace/braces', 5,
             'Missing space before {')
 
   # Make sure '} else {' has spaces.
   if Search(r'}else', line):
     error(filename, linenum, 'whitespace/braces', 5,
           'Missing space before else')
 
   # You shouldn't have a space before a semicolon at the end of the line.
   # There's a special case for "for" since the style guide allows space before
   # the semicolon there.
   if Search(r':\s*;\s*$', line):
     error(filename, linenum, 'whitespace/semicolon', 5,
           'Semicolon defining empty statement. Use {} instead.')
   elif Search(r'^\s*;\s*$', line):
     error(filename, linenum, 'whitespace/semicolon', 5,
           'Line contains only semicolon. If this should be an empty statement, '
           'use {} instead.')
   elif (Search(r'\s+;\s*$', line) and
         not Search(r'\bfor\b', line)):
     error(filename, linenum, 'whitespace/semicolon', 5,
           'Extra space before last semicolon. If this should be an empty '
           'statement, use {} instead.')
@@ -3732,137 +3737,137 @@ def CheckBraces(filename, clean_lines, linenum, error):
 def CheckTrailingSemicolon(filename, clean_lines, linenum, error):
   """Looks for redundant trailing semicolon.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     error: The function to call with any errors found.
   """
 
   line = clean_lines.elided[linenum]
 
   # Block bodies should not be followed by a semicolon.  Due to C++11
   # brace initialization, there are more places where semicolons are
-  # required than not, so we use a whitelist approach to check these
-  # rather than a blacklist.  These are the places where "};" should
+  # required than not, so we use an allowlist approach to check these
+  # rather than a blocklist.  These are the places where "};" should
   # be replaced by just "}":
   # 1. Some flavor of block following closing parenthesis:
   #    for (;;) {};
   #    while (...) {};
   #    switch (...) {};
   #    Function(...) {};
   #    if (...) {};
   #    if (...) else if (...) {};
   #
   # 2. else block:
   #    if (...) else {};
   #
   # 3. const member function:
   #    Function(...) const {};
   #
   # 4. Block following some statement:
   #    x = 42;
   #    {};
   #
   # 5. Block at the beginning of a function:
   #    Function(...) {
   #      {};
   #    }
   #
   #    Note that naively checking for the preceding "{" will also match
   #    braces inside multi-dimensional arrays, but this is fine since
   #    that expression will not contain semicolons.
   #
   # 6. Block following another block:
   #    while (true) {}
   #    {};
   #
   # 7. End of namespaces:
   #    namespace {};
   #
   #    These semicolons seems far more common than other kinds of
   #    redundant semicolons, possibly due to people converting classes
   #    to namespaces.  For now we do not warn for this case.
   #
   # Try matching case 1 first.
   match = Match(r'^(.*\)\s*)\{', line)
   if match:
     # Matched closing parenthesis (case 1).  Check the token before the
     # matching opening parenthesis, and don't warn if it looks like a
     # macro.  This avoids these false positives:
     #  - macro that defines a base class
     #  - multi-line macro that defines a base class
     #  - macro that defines the whole class-head
     #
     # But we still issue warnings for macros that we know are safe to
     # warn, specifically:
     #  - TEST, TEST_F, TEST_P, MATCHER, MATCHER_P
     #  - TYPED_TEST
     #  - INTERFACE_DEF
     #  - EXCLUSIVE_LOCKS_REQUIRED, SHARED_LOCKS_REQUIRED, LOCKS_EXCLUDED:
     #
-    # We implement a whitelist of safe macros instead of a blacklist of
+    # We implement an allowlist of safe macros instead of a blocklist of
     # unsafe macros, even though the latter appears less frequently in
-    # google code and would have been easier to implement.  This is because
-    # the downside for getting the whitelist wrong means some extra
-    # semicolons, while the downside for getting the blacklist wrong
+    # google code and would have been easier to implement. This is because
+    # the downside for getting the allowlist wrong means some extra
+    # semicolons, while the downside for getting the blocklist wrong
     # would result in compile errors.
     #
     # In addition to macros, we also don't want to warn on
     #  - Compound literals
     #  - Lambdas
     #  - alignas specifier with anonymous structs
     #  - decltype
     closing_brace_pos = match.group(1).rfind(')')
     opening_parenthesis = ReverseCloseExpression(
         clean_lines, linenum, closing_brace_pos)
     if opening_parenthesis[2] > -1:
       line_prefix = opening_parenthesis[0][0:opening_parenthesis[2]]
       macro = Search(r'\b([A-Z_][A-Z0-9_]*)\s*$', line_prefix)
       func = Match(r'^(.*\])\s*$', line_prefix)
       if ((macro and
            macro.group(1) not in (
                'TEST', 'TEST_F', 'MATCHER', 'MATCHER_P', 'TYPED_TEST',
                'EXCLUSIVE_LOCKS_REQUIRED', 'SHARED_LOCKS_REQUIRED',
                'LOCKS_EXCLUDED', 'INTERFACE_DEF')) or
           (func and not Search(r'\boperator\s*\[\s*\]', func.group(1))) or
           Search(r'\b(?:struct|union)\s+alignas\s*$', line_prefix) or
           Search(r'\bdecltype$', line_prefix) or
           Search(r'\s+=\s*$', line_prefix)):
         match = None
     if (match and
         opening_parenthesis[1] > 1 and
         Search(r'\]\s*$', clean_lines.elided[opening_parenthesis[1] - 1])):
       # Multi-line lambda-expression
       match = None
 
   else:
     # Try matching cases 2-3.
     match = Match(r'^(.*(?:else|\)\s*const)\s*)\{', line)
     if not match:
       # Try matching cases 4-6.  These are always matched on separate lines.
       #
       # Note that we can't simply concatenate the previous line to the
       # current line and do a single match, otherwise we may output
       # duplicate warnings for the blank line case:
       #   if (cond) {
       #     // blank line
       #   }
       prevline = GetPreviousNonBlankLine(clean_lines, linenum)[0]
       if prevline and Search(r'[;{}]\s*$', prevline):
         match = Match(r'^(\s*)\{', line)
 
   # Check matching closing brace
   if match:
     (endline, endlinenum, endpos) = CloseExpression(
         clean_lines, linenum, len(match.group(1)))
     if endpos > -1 and Match(r'^\s*;', endline[endpos:]):
       # Current {} pair is eligible for semicolon check, and we have found
       # the redundant semicolon, output warning here.
       #
       # Note: because we are scanning forward for opening braces, and
       # outputting warnings for the matching closing brace, if there are
       # nested blocks with trailing semicolons, we will get the error
       # messages in reversed order.
       error(filename, endlinenum, 'readability/braces', 4,
             "You don't need a ; after a }")
@@ -3998,116 +4003,116 @@ def FindCheckMacro(line):
 def CheckCheck(filename, clean_lines, linenum, error):
   """Checks the use of CHECK and EXPECT macros.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     error: The function to call with any errors found.
   """
 
   # Decide the set of replacement macros that should be suggested
   lines = clean_lines.elided
   (check_macro, start_pos) = FindCheckMacro(lines[linenum])
   if not check_macro:
     return
 
   # Find end of the boolean expression by matching parentheses
   (last_line, end_line, end_pos) = CloseExpression(
       clean_lines, linenum, start_pos)
   if end_pos < 0:
     return
 
   # If the check macro is followed by something other than a
   # semicolon, assume users will log their own custom error messages
   # and don't suggest any replacements.
   if not Match(r'\s*;', last_line[end_pos:]):
     return
 
   if linenum == end_line:
     expression = lines[linenum][start_pos + 1:end_pos - 1]
   else:
     expression = lines[linenum][start_pos + 1:]
-    for i in xrange(linenum + 1, end_line):
+    for i in range(linenum + 1, end_line):
       expression += lines[i]
     expression += last_line[0:end_pos - 1]
 
   # Parse expression so that we can take parentheses into account.
   # This avoids false positives for inputs like "CHECK((a < 4) == b)",
   # which is not replaceable by CHECK_LE.
   lhs = ''
   rhs = ''
   operator = None
   while expression:
     matched = Match(r'^\s*(<<|<<=|>>|>>=|->\*|->|&&|\|\||'
                     r'==|!=|>=|>|<=|<|\()(.*)$', expression)
     if matched:
       token = matched.group(1)
       if token == '(':
         # Parenthesized operand
         expression = matched.group(2)
         (end, _) = FindEndOfExpressionInLine(expression, 0, ['('])
         if end < 0:
           return  # Unmatched parenthesis
         lhs += '(' + expression[0:end]
         expression = expression[end:]
       elif token in ('&&', '||'):
         # Logical and/or operators.  This means the expression
         # contains more than one term, for example:
         #   CHECK(42 < a && a < b);
         #
         # These are not replaceable with CHECK_LE, so bail out early.
         return
       elif token in ('<<', '<<=', '>>', '>>=', '->*', '->'):
         # Non-relational operator
         lhs += token
         expression = matched.group(2)
       else:
         # Relational operator
         operator = token
         rhs = matched.group(2)
         break
     else:
       # Unparenthesized operand.  Instead of appending to lhs one character
       # at a time, we do another regular expression match to consume several
       # characters at once if possible.  Trivial benchmark shows that this
       # is more efficient when the operands are longer than a single
       # character, which is generally the case.
       matched = Match(r'^([^-=!<>()&|]+)(.*)$', expression)
       if not matched:
         matched = Match(r'^(\s*\S)(.*)$', expression)
         if not matched:
           break
       lhs += matched.group(1)
       expression = matched.group(2)
 
   # Only apply checks if we got all parts of the boolean expression
   if not (lhs and operator and rhs):
     return
 
   # Check that rhs do not contain logical operators.  We already know
   # that lhs is fine since the loop above parses out && and ||.
   if rhs.find('&&') > -1 or rhs.find('||') > -1:
     return
 
   # At least one of the operands must be a constant literal.  This is
   # to avoid suggesting replacements for unprintable things like
   # CHECK(variable != iterator)
   #
   # The following pattern matches decimal, hex integers, strings, and
   # characters (in that order).
   lhs = lhs.strip()
   rhs = rhs.strip()
   match_constant = r'^([-+]?(\d+|0[xX][0-9a-fA-F]+)[lLuU]{0,3}|".*"|\'.*\')$'
   if Match(match_constant, lhs) or Match(match_constant, rhs):
     # Note: since we know both lhs and rhs, we can provide a more
     # descriptive error message like:
     #   Consider using CHECK_EQ(x, 42) instead of CHECK(x == 42)
     # Instead of:
     #   Consider using CHECK_EQ instead of CHECK(a == b)
     #
     # We are still keeping the less descriptive message because if lhs
     # or rhs gets long, the error message might become unreadable.
     error(filename, linenum, 'readability/check', 2,
           'Consider using %s instead of %s(a %s b)' % (
               _CHECK_REPLACEMENT[check_macro][operator],
               check_macro, operator))
@@ -4148,20 +4153,20 @@ def CheckAltTokens(filename, clean_lines, linenum, error):
 def GetLineWidth(line):
   """Determines the width of the line in column positions.
 
   Args:
     line: A string, which may be a Unicode string.
 
   Returns:
     The width of the line in column positions, accounting for Unicode
     combining characters and wide characters.
   """
-  if isinstance(line, unicode):
+  if sys.version_info == 2 and isinstance(line, unicode):
     width = 0
     for uc in unicodedata.normalize('NFC', line):
       if unicodedata.east_asian_width(uc) in ('W', 'F'):
         width += 2
       elif not unicodedata.combining(uc):
         width += 1
     return width
   else:
     return len(line)
@@ -4385,71 +4390,71 @@ def _ClassifyInclude(fileinfo, include, is_system):
 def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):
   """Check rules that are applicable to #include lines.
 
   Strings on #include lines are NOT removed from elided line, to make
   certain tasks easier. However, to prevent false positives, checks
   applicable to #include lines in CheckLanguage must be put here.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     include_state: An _IncludeState instance in which the headers are inserted.
     error: The function to call with any errors found.
   """
   fileinfo = FileInfo(filename)
   line = clean_lines.lines[linenum]
 
   # "include" should use the new style "foo/bar.h" instead of just "bar.h"
   # Only do this check if the included header follows google naming
   # conventions.  If not, assume that it's a 3rd party API that
   # requires special include conventions.
   #
   # We also make an exception for Lua headers, which follow google
   # naming convention but not the include convention.
   match = Match(r'#include\s*"([^/]+\.h)"', line)
   if match and not _THIRD_PARTY_HEADERS_PATTERN.match(match.group(1)):
-    error(filename, linenum, 'build/include', 4,
+    error(filename, linenum, 'build/include_directory', 4,
           'Include the directory when naming .h files')
 
   # we shouldn't include a file more than once. actually, there are a
   # handful of instances where doing so is okay, but in general it's
   # not.
   match = _RE_PATTERN_INCLUDE.search(line)
   if match:
     include = match.group(2)
     is_system = (match.group(1) == '<')
     duplicate_line = include_state.FindHeader(include)
     if duplicate_line >= 0:
       error(filename, linenum, 'build/include', 4,
             '"%s" already included at %s:%s' %
             (include, filename, duplicate_line))
     elif (include.endswith('.cc') and
           os.path.dirname(fileinfo.RepositoryName()) != os.path.dirname(include)):
       error(filename, linenum, 'build/include', 4,
             'Do not include .cc files from other packages')
     elif not _THIRD_PARTY_HEADERS_PATTERN.match(include):
       include_state.include_list[-1].append((include, linenum))
 
       # We want to ensure that headers appear in the right order:
       # 1) for foo.cc, foo.h  (preferred location)
       # 2) c system files
       # 3) cpp system files
       # 4) for foo.cc, foo.h  (deprecated location)
       # 5) other google headers
       #
       # We classify each include statement as one of those 5 types
       # using a number of techniques. The include_state object keeps
       # track of the highest type seen, and complains if we see a
       # lower type after that.
       error_message = include_state.CheckNextIncludeOrder(
           _ClassifyInclude(fileinfo, include, is_system))
       if error_message:
         error(filename, linenum, 'build/include_order', 4,
               '%s. Should be: %s.h, c system, c++ system, other.' %
               (error_message, fileinfo.BaseName()))
       canonical_include = include_state.CanonicalizeAlphabeticalOrder(include)
       if not include_state.IsInAlphabeticalOrder(
           clean_lines, linenum, canonical_include):
         error(filename, linenum, 'build/include_alpha', 4,
               'Include "%s" not in alphabetical order' % include)
       include_state.SetLastHeader(canonical_include)
@@ -4459,65 +4464,65 @@ def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):
 def _GetTextInside(text, start_pattern):
   r"""Retrieves all the text between matching open and close parentheses.
 
   Given a string of lines and a regular expression string, retrieve all the text
   following the expression and between opening punctuation symbols like
   (, [, or {, and the matching close-punctuation symbol. This properly nested
   occurrences of the punctuations, so for the text like
     printf(a(), b(c()));
   a call to _GetTextInside(text, r'printf\(') will return 'a(), b(c())'.
   start_pattern must match string having an open punctuation symbol at the end.
 
   Args:
     text: The lines to extract text. Its comments and strings must be elided.
            It can be single line and can span multiple lines.
     start_pattern: The regexp string indicating where to start extracting
                    the text.
   Returns:
     The extracted text.
     None if either the opening string or ending punctuation could not be found.
   """
   # TODO(unknown): Audit cpplint.py to see what places could be profitably
   # rewritten to use _GetTextInside (and use inferior regexp matching today).
 
   # Give opening punctuations to get the matching close-punctuations.
   matching_punctuation = {'(': ')', '{': '}', '[': ']'}
-  closing_punctuation = set(matching_punctuation.itervalues())
+  closing_punctuation = set(matching_punctuation.values())
 
   # Find the position to start extracting text.
   match = re.search(start_pattern, text, re.M)
   if not match:  # start_pattern not found in text.
     return None
   start_position = match.end(0)
 
   assert start_position > 0, (
       'start_pattern must ends with an opening punctuation.')
   assert text[start_position - 1] in matching_punctuation, (
       'start_pattern must ends with an opening punctuation.')
   # Stack of closing punctuations we expect to have in text after position.
   punctuation_stack = [matching_punctuation[text[start_position - 1]]]
   position = start_position
   while punctuation_stack and position < len(text):
     if text[position] == punctuation_stack[-1]:
       punctuation_stack.pop()
     elif text[position] in closing_punctuation:
       # A closing punctuation without matching opening punctuations.
       return None
     elif text[position] in matching_punctuation:
       punctuation_stack.append(matching_punctuation[text[position]])
     position += 1
   if punctuation_stack:
     # Opening punctuations left without matching close-punctuations.
     return None
   # punctuations match.
   return text[start_position:position - 1]
 
 
 # Patterns for matching call-by-reference parameters.
 #
 # Supports nested templates up to 2 levels deep using this messy pattern:
 #   < (?: < (?: < [^<>]*
 #               >
 #           |   [^<>] )*
 #         >
 #     |   [^<>] )*
 #   >
@@ -4544,156 +4549,159 @@ _RE_PATTERN_REF_STREAM_PARAM = (
 def CheckLanguage(filename, clean_lines, linenum, file_extension,
                   include_state, nesting_state, error):
   """Checks rules from the 'C++ language rules' section of cppguide.html.
 
   Some of these rules are hard to test (function overloading, using
   uint32 inappropriately), but we do the best we can.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     file_extension: The extension (without the dot) of the filename.
     include_state: An _IncludeState instance in which the headers are inserted.
     nesting_state: A NestingState instance which maintains information about
                    the current stack of nested blocks being parsed.
     error: The function to call with any errors found.
   """
   # If the line is empty or consists of entirely a comment, no need to
   # check it.
   line = clean_lines.elided[linenum]
   if not line:
     return
 
   match = _RE_PATTERN_INCLUDE.search(line)
   if match:
     CheckIncludeLine(filename, clean_lines, linenum, include_state, error)
     return
 
   # Reset include state across preprocessor directives.  This is meant
   # to silence warnings for conditional includes.
   match = Match(r'^\s*#\s*(if|ifdef|ifndef|elif|else|endif)\b', line)
   if match:
     include_state.ResetSection(match.group(1))
 
   # Make Windows paths like Unix.
   fullname = os.path.abspath(filename).replace('\\', '/')
 
   # Perform other checks now that we are sure that this is not an include line
   CheckCasts(filename, clean_lines, linenum, error)
   CheckGlobalStatic(filename, clean_lines, linenum, error)
   CheckPrintf(filename, clean_lines, linenum, error)
 
   if file_extension == 'h':
     # TODO(unknown): check that 1-arg constructors are explicit.
     #                How to tell it's a constructor?
     #                (handled in CheckForNonStandardConstructs for now)
     # TODO(unknown): check that classes declare or disable copy/assign
     #                (level 1 error)
     pass
 
   # Check if people are using the verboten C basic types.  The only exception
   # we regularly allow is "unsigned short port" for port.
   if Search(r'\bshort port\b', line):
     if not Search(r'\bunsigned short port\b', line):
       error(filename, linenum, 'runtime/int', 4,
             'Use "unsigned short" for ports, not "short"')
   else:
     match = Search(r'\b(short|long(?! +double)|long long)\b', line)
     if match:
       error(filename, linenum, 'runtime/int', 4,
             'Use int16/int64/etc, rather than the C type %s' % match.group(1))
 
   # Check if some verboten operator overloading is going on
   # TODO(unknown): catch out-of-line unary operator&:
   #   class X {};
   #   int operator&(const X& x) { return 42; }  // unary operator&
   # The trick is it's hard to tell apart from binary operator&:
   #   class Y { int operator&(const Y& x) { return 23; } }; // binary operator&
   if Search(r'\boperator\s*&\s*\(\s*\)', line):
     error(filename, linenum, 'runtime/operator', 4,
           'Unary operator& is dangerous.  Do not use it.')
 
   # Check for suspicious usage of "if" like
   # } if (a == b) {
   if Search(r'\}\s*if\s*\(', line):
     error(filename, linenum, 'readability/braces', 4,
           'Did you mean "else if"? If not, start a new line for "if".')
 
   # Check for potential format string bugs like printf(foo).
   # We constrain the pattern not to pick things like DocidForPrintf(foo).
   # Not perfect but it can catch printf(foo.c_str()) and printf(foo->c_str())
   # TODO(unknown): Catch the following case. Need to change the calling
   # convention of the whole function to process multiple line to handle it.
   #   printf(
   #       boy_this_is_a_really_long_variable_that_cannot_fit_on_the_prev_line);
   printf_args = _GetTextInside(line, r'(?i)\b(string)?printf\s*\(')
   if printf_args:
     match = Match(r'([\w.\->()]+)$', printf_args)
     if match and match.group(1) != '__VA_ARGS__':
       function_name = re.search(r'\b((?:string)?printf)\s*\(',
                                 line, re.I).group(1)
       error(filename, linenum, 'runtime/printf', 4,
             'Potential format string bug. Do %s("%%s", %s) instead.'
             % (function_name, match.group(1)))
 
   # Check for potential memset bugs like memset(buf, sizeof(buf), 0).
   match = Search(r'memset\s*\(([^,]*),\s*([^,]*),\s*0\s*\)', line)
   if match and not Match(r"^''|-?[0-9]+|0x[0-9A-Fa-f]$", match.group(2)):
     error(filename, linenum, 'runtime/memset', 4,
           'Did you mean "memset(%s, 0, %s)"?'
           % (match.group(1), match.group(2)))
 
   if Search(r'\busing namespace\b', line):
     error(filename, linenum, 'build/namespaces', 5,
           'Do not use namespace using-directives.  '
           'Use using-declarations instead.')
 
   # Detect variable-length arrays.
   match = Match(r'\s*(.+::)?(\w+) [a-z]\w*\[(.+)];', line)
   if (match and match.group(2) != 'return' and match.group(2) != 'delete' and
       match.group(3).find(']') == -1):
     # Split the size using space and arithmetic operators as delimiters.
     # If any of the resulting tokens are not compile time constants then
     # report the error.
     tokens = re.split(r'\s|\+|\-|\*|\/|<<|>>]', match.group(3))
     is_const = True
     skip_next = False
     for tok in tokens:
       if skip_next:
         skip_next = False
         continue
 
       if Search(r'sizeof\(.+\)', tok): continue
       if Search(r'arraysize\(\w+\)', tok): continue
+      if Search(r'base::size\(.+\)', tok): continue
+      if Search(r'std::size\(.+\)', tok): continue
+      if Search(r'std::extent<.+>', tok): continue
 
       tok = tok.lstrip('(')
       tok = tok.rstrip(')')
       if not tok: continue
       if Match(r'\d+', tok): continue
       if Match(r'0[xX][0-9a-fA-F]+', tok): continue
       if Match(r'k[A-Z0-9]\w*', tok): continue
       if Match(r'(.+::)?k[A-Z0-9]\w*', tok): continue
       if Match(r'(.+::)?[A-Z][A-Z0-9_]*', tok): continue
       # A catch all for tricky sizeof cases, including 'sizeof expression',
       # 'sizeof(*type)', 'sizeof(const type)', 'sizeof(struct StructName)'
       # requires skipping the next token because we split on ' ' and '*'.
       if tok.startswith('sizeof'):
         skip_next = True
         continue
       is_const = False
       break
     if not is_const:
       error(filename, linenum, 'runtime/arrays', 1,
             'Do not use variable-length arrays.  Use an appropriately named '
             "('k' followed by CamelCase) compile-time constant for the size.")
 
   # Check for use of unnamed namespaces in header files.  Registration
   # macros are typically OK, so we allow use of "namespace {" on lines
   # that end with backslashes.
   if (file_extension == 'h'
       and Search(r'\bnamespace\s*{', line)
       and line[-1] != '\\'):
     error(filename, linenum, 'build/namespaces', 4,
           'Do not use unnamed namespaces in header files.  See '
           'https://google.github.io/styleguide/cppguide.html#Namespaces'
           ' for more information.')
@@ -4792,20 +4800,20 @@ def CheckPrintf(filename, clean_lines, linenum, error):
 def IsDerivedFunction(clean_lines, linenum):
   """Check if current line contains an inherited function.
 
   Args:
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
   Returns:
     True if current line contains a function with "override"
     virt-specifier.
   """
   # Scan back a few lines for start of current function
-  for i in xrange(linenum, max(-1, linenum - 10), -1):
+  for i in range(linenum, max(-1, linenum - 10), -1):
     match = Match(r'^([^()]*\w+)\(', clean_lines.elided[i])
     if match:
       # Look for "override" after the matching closing parenthesis
       line, _, closing_paren = CloseExpression(
           clean_lines, i, len(match.group(1)))
       return (closing_paren >= 0 and
               Search(r'\boverride\b', line[closing_paren:]))
   return False
@@ -4814,14 +4822,14 @@ def IsDerivedFunction(clean_lines, linenum):
 def IsOutOfLineMethodDefinition(clean_lines, linenum):
   """Check if current line contains an out-of-line method definition.
 
   Args:
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
   Returns:
     True if current line contains an out-of-line method definition.
   """
   # Scan back a few lines for start of current function
-  for i in xrange(linenum, max(-1, linenum - 10), -1):
+  for i in range(linenum, max(-1, linenum - 10), -1):
     if Match(r'^([^()]*\w+)\(', clean_lines.elided[i]):
       return Match(r'^[^()]*\w+::\w+\(', clean_lines.elided[i]) is not None
   return False
@@ -4830,40 +4838,40 @@ def IsOutOfLineMethodDefinition(clean_lines, linenum):
 def IsInitializerList(clean_lines, linenum):
   """Check if current line is inside constructor initializer list.
 
   Args:
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
   Returns:
     True if current line appears to be inside constructor initializer
     list, False otherwise.
   """
-  for i in xrange(linenum, 1, -1):
+  for i in range(linenum, 1, -1):
     line = clean_lines.elided[i]
     if i == linenum:
       remove_function_body = Match(r'^(.*)\{\s*$', line)
       if remove_function_body:
         line = remove_function_body.group(1)
 
     if Search(r'\s:\s*\w+[({]', line):
       # A lone colon tend to indicate the start of a constructor
       # initializer list.  It could also be a ternary operator, which
       # also tend to appear in constructor initializer lists as
       # opposed to parameter lists.
       return True
     if Search(r'\}\s*,\s*$', line):
       # A closing brace followed by a comma is probably the end of a
       # brace-initialized member in constructor initializer list.
       return True
     if Search(r'[{};]\s*$', line):
       # Found one of the following:
       # - A closing brace or semicolon, probably the end of the previous
       #   function.
       # - An opening brace, probably the start of current class or namespace.
       #
       # Current line is probably not inside an initializer list since
       # we saw one of those things without seeing the starting colon.
       return False
 
   # Got to the beginning of the file without seeing the start of
   # constructor initializer list.
   return False
@@ -4872,137 +4880,137 @@ def IsInitializerList(clean_lines, linenum):
 def CheckForNonConstReference(filename, clean_lines, linenum,
                               nesting_state, error):
   """Check for non-const references.
 
   Separate from CheckLanguage since it scans backwards from current
   line, instead of scanning forward.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     nesting_state: A NestingState instance which maintains information about
                    the current stack of nested blocks being parsed.
     error: The function to call with any errors found.
   """
   # Do nothing if there is no '&' on current line.
   line = clean_lines.elided[linenum]
   if '&' not in line:
     return
 
   # If a function is inherited, current function doesn't have much of
   # a choice, so any non-const references should not be blamed on
   # derived function.
   if IsDerivedFunction(clean_lines, linenum):
     return
 
   # Don't warn on out-of-line method definitions, as we would warn on the
   # in-line declaration, if it isn't marked with 'override'.
   if IsOutOfLineMethodDefinition(clean_lines, linenum):
     return
 
   # Long type names may be broken across multiple lines, usually in one
   # of these forms:
   #   LongType
   #       ::LongTypeContinued &identifier
   #   LongType::
   #       LongTypeContinued &identifier
   #   LongType<
   #       ...>::LongTypeContinued &identifier
   #
   # If we detected a type split across two lines, join the previous
   # line to current line so that we can match const references
   # accordingly.
   #
   # Note that this only scans back one line, since scanning back
   # arbitrary number of lines would be expensive.  If you have a type
   # that spans more than 2 lines, please use a typedef.
   if linenum > 1:
     previous = None
     if Match(r'\s*::(?:[\w<>]|::)+\s*&\s*\S', line):
       # previous_line\n + ::current_line
       previous = Search(r'\b((?:const\s*)?(?:[\w<>]|::)+[\w<>])\s*$',
                         clean_lines.elided[linenum - 1])
     elif Match(r'\s*[a-zA-Z_]([\w<>]|::)+\s*&\s*\S', line):
       # previous_line::\n + current_line
       previous = Search(r'\b((?:const\s*)?(?:[\w<>]|::)+::)\s*$',
                         clean_lines.elided[linenum - 1])
     if previous:
       line = previous.group(1) + line.lstrip()
     else:
       # Check for templated parameter that is split across multiple lines
       endpos = line.rfind('>')
       if endpos > -1:
         (_, startline, startpos) = ReverseCloseExpression(
             clean_lines, linenum, endpos)
         if startpos > -1 and startline < linenum:
           # Found the matching < on an earlier line, collect all
           # pieces up to current line.
           line = ''
-          for i in xrange(startline, linenum + 1):
+          for i in range(startline, linenum + 1):
             line += clean_lines.elided[i].strip()
 
   # Check for non-const references in function parameters.  A single '&' may
   # found in the following places:
   #   inside expression: binary & for bitwise AND
   #   inside expression: unary & for taking the address of something
   #   inside declarators: reference parameter
   # We will exclude the first two cases by checking that we are not inside a
   # function body, including one that was just introduced by a trailing '{'.
   # TODO(unknown): Doesn't account for 'catch(Exception& e)' [rare].
   if (nesting_state.previous_stack_top and
       not (isinstance(nesting_state.previous_stack_top, _ClassInfo) or
            isinstance(nesting_state.previous_stack_top, _NamespaceInfo))):
     # Not at toplevel, not within a class, and not within a namespace
     return
 
   # Avoid initializer lists.  We only need to scan back from the
   # current line for something that starts with ':'.
   #
   # We don't need to check the current line, since the '&' would
   # appear inside the second set of parentheses on the current line as
   # opposed to the first set.
   if linenum > 0:
-    for i in xrange(linenum - 1, max(0, linenum - 10), -1):
+    for i in range(linenum - 1, max(0, linenum - 10), -1):
       previous_line = clean_lines.elided[i]
       if not Search(r'[),]\s*$', previous_line):
         break
       if Match(r'^\s*:\s+\S', previous_line):
         return
 
   # Avoid preprocessors
   if Search(r'\\\s*$', line):
     return
 
   # Avoid constructor initializer lists
   if IsInitializerList(clean_lines, linenum):
     return
 
   # We allow non-const references in a few standard places, like functions
   # called "swap()" or iostream operators like "<<" or ">>".  Do not check
   # those function parameters.
   #
   # We also accept & in static_assert, which looks like a function but
   # it's actually a declaration expression.
-  whitelisted_functions = (r'(?:[sS]wap(?:<\w:+>)?|'
+  allowlisted_functions = (r'(?:[sS]wap(?:<\w:+>)?|'
                            r'operator\s*[<>][<>]|'
                            r'static_assert|COMPILE_ASSERT'
                            r')\s*\(')
-  if Search(whitelisted_functions, line):
+  if Search(allowlisted_functions, line):
     return
   elif not Search(r'\S+\([^)]*$', line):
-    # Don't see a whitelisted function on this line.  Actually we
+    # Don't see an allowlisted function on this line.  Actually we
     # didn't see any function name on this line, so this is likely a
     # multi-line parameter list.  Try a bit harder to catch this case.
-    for i in xrange(2):
+    for i in range(2):
       if (linenum > i and
-          Search(whitelisted_functions, clean_lines.elided[linenum - i - 1])):
+          Search(allowlisted_functions, clean_lines.elided[linenum - i - 1])):
         return
 
   decls = ReplaceAll(r'{[^}]*}', ' ', line)  # exclude function body
   for parameter in re.findall(_RE_PATTERN_REF_PARAM, decls):
     if (not Match(_RE_PATTERN_CONST_REF_PARAM, parameter) and
         not Match(_RE_PATTERN_REF_STREAM_PARAM, parameter)):
       error(filename, linenum, 'runtime/references', 2,
             'Is this a non-const reference? '
             'If so, make const or use a pointer: ' +
             ReplaceAll(' *<', '<', parameter))
@@ -5130,51 +5138,51 @@ def CheckCasts(filename, clean_lines, linenum, error):
 def CheckCStyleCast(filename, clean_lines, linenum, cast_type, pattern, error):
   """Checks for a C-style cast by looking for the pattern.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     cast_type: The string for the C++ cast to recommend.  This is either
       reinterpret_cast, static_cast, or const_cast, depending.
     pattern: The regular expression used to find C-style casts.
     error: The function to call with any errors found.
 
   Returns:
     True if an error was emitted.
     False otherwise.
   """
   line = clean_lines.elided[linenum]
   match = Search(pattern, line)
   if not match:
     return False
 
   # Exclude lines with keywords that tend to look like casts
   context = line[0:match.start(1) - 1]
   if Match(r'.*\b(?:sizeof|alignof|alignas|[_A-Z][_A-Z0-9]*)\s*$', context):
     return False
 
   # Try expanding current context to see if we one level of
   # parentheses inside a macro.
   if linenum > 0:
-    for i in xrange(linenum - 1, max(0, linenum - 5), -1):
+    for i in range(linenum - 1, max(0, linenum - 5), -1):
       context = clean_lines.elided[i] + context
   if Match(r'.*\b[_A-Z][_A-Z0-9]*\s*\((?:\([^()]*\)|[^()])*$', context):
     return False
 
   # operator++(int) and operator--(int)
   if context.endswith(' operator++') or context.endswith(' operator--'):
     return False
 
   # A single unnamed argument for a function tends to look like old style cast.
   # If we see those, don't issue warnings for deprecated casts.
   remainder = line[match.end(0):]
   if Match(r'^\s*(?:;|const\b|throw\b|final\b|override\b|[=>{),]|->)',
            remainder):
     return False
 
   # At this point, all that should be left is actual casts.
   error(filename, linenum, 'readability/casting', 4,
         'Using C-style cast.  Use %s<%s>(...) instead' %
         (cast_type, match.group(1)))
 
   return True
@@ -5357,97 +5365,97 @@ def UpdateIncludeState(filename, include_dict, io=codecs):
 def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,
                               io=codecs):
   """Reports for missing stl includes.
 
   This function will output warnings to make sure you are including the headers
   necessary for the stl containers and functions that you use. We only give one
   reason to include a header. For example, if you use both equal_to<> and
   less<> in a .h file, only one (the latter in the file) of these will be
   reported as a reason to include the <functional>.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     include_state: An _IncludeState instance.
     error: The function to call with any errors found.
     io: The IO factory to use to read the header file. Provided for unittest
         injection.
   """
   required = {}  # A map of header name to linenumber and the template entity.
                  # Example of required: { '<functional>': (1219, 'less<>') }
 
-  for linenum in xrange(clean_lines.NumLines()):
+  for linenum in range(clean_lines.NumLines()):
     line = clean_lines.elided[linenum]
     if not line or line[0] == '#':
       continue
 
     # String is special -- it is a non-templatized type in STL.
     matched = _RE_PATTERN_STRING.search(line)
     if matched:
       # Don't warn about strings in non-STL namespaces:
       # (We check only the first match per line; good enough.)
       prefix = line[:matched.start()]
       if prefix.endswith('std::') or not prefix.endswith('::'):
         required['<string>'] = (linenum, 'string')
 
     for pattern, template, header in _re_pattern_headers_maybe_templates:
       if pattern.search(line):
         required[header] = (linenum, template)
 
     # The following function is just a speed up, no semantics are changed.
     if not '<' in line:  # Reduces the cpu time usage by skipping lines.
       continue
 
     for pattern, template, header in _re_pattern_templates:
       matched = pattern.search(line)
       if matched:
         # Don't warn about IWYU in non-STL namespaces:
         # (We check only the first match per line; good enough.)
         prefix = line[:matched.start()]
         if prefix.endswith('std::') or not prefix.endswith('::'):
           required[header] = (linenum, template)
 
   # The policy is that if you #include something in foo.h you don't need to
   # include it again in foo.cc. Here, we will look at possible includes.
   # Let's flatten the include_state include_list and copy it into a dictionary.
   include_dict = dict([item for sublist in include_state.include_list
                        for item in sublist])
 
   # Did we find the header for this file (if any) and successfully load it?
   header_found = False
 
   # Use the absolute path so that matching works properly.
   abs_filename = FileInfo(filename).FullName()
 
   # For Emacs's flymake.
   # If cpplint is invoked from Emacs's flymake, a temporary file is generated
   # by flymake and that file name might end with '_flymake.cc'. In that case,
   # restore original file name here so that the corresponding header file can be
   # found.
   # e.g. If the file name is 'foo_flymake.cc', we should search for 'foo.h'
   # instead of 'foo_flymake.h'
   abs_filename = re.sub(r'_flymake\.cc$', '.cc', abs_filename)
 
   # include_dict is modified during iteration, so we iterate over a copy of
   # the keys.
-  header_keys = include_dict.keys()
+  header_keys = list(include_dict.keys())
   for header in header_keys:
     (same_module, common_path) = FilesBelongToSameModule(abs_filename, header)
     fullpath = common_path + header
     if same_module and UpdateIncludeState(fullpath, include_dict, io):
       header_found = True
 
   # If we can't find the header file for a .cc, assume it's because we don't
   # know where to look. In that case we'll give up as we're not sure they
   # didn't include it in the .h file.
   # TODO(unknown): Do a better job of finding .h files so we are confident that
   # not having the .h file means there isn't one.
   if filename.endswith('.cc') and not header_found:
     return
 
   # All the lines have been processed, report the errors found.
   for required_header_unstripped in required:
     template = required[required_header_unstripped][1]
     if required_header_unstripped.strip('<>"') not in include_dict:
       error(filename, required[required_header_unstripped][0],
             'build/include_what_you_use', 4,
             'Add #include ' + required_header_unstripped + ' for ' + template)
@@ -5480,62 +5488,62 @@ def CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):
 def CheckRedundantVirtual(filename, clean_lines, linenum, error):
   """Check if line contains a redundant "virtual" function-specifier.
 
   Args:
     filename: The name of the current file.
     clean_lines: A CleansedLines instance containing the file.
     linenum: The number of the line to check.
     error: The function to call with any errors found.
   """
   # Look for "virtual" on current line.
   line = clean_lines.elided[linenum]
   virtual = Match(r'^(.*)(\bvirtual\b)(.*)$', line)
   if not virtual: return
 
   # Ignore "virtual" keywords that are near access-specifiers.  These
   # are only used in class base-specifier and do not apply to member
   # functions.
   if (Search(r'\b(public|protected|private)\s+$', virtual.group(1)) or
       Match(r'^\s+(public|protected|private)\b', virtual.group(3))):
     return
 
   # Ignore the "virtual" keyword from virtual base classes.  Usually
   # there is a column on the same line in these cases (virtual base
   # classes are rare in google3 because multiple inheritance is rare).
   if Match(r'^.*[^:]:[^:].*$', line): return
 
   # Look for the next opening parenthesis.  This is the start of the
   # parameter list (possibly on the next line shortly after virtual).
   # TODO(unknown): doesn't work if there are virtual functions with
   # decltype() or other things that use parentheses, but csearch suggests
   # that this is rare.
   end_col = -1
   end_line = -1
   start_col = len(virtual.group(2))
-  for start_line in xrange(linenum, min(linenum + 3, clean_lines.NumLines())):
+  for start_line in range(linenum, min(linenum + 3, clean_lines.NumLines())):
     line = clean_lines.elided[start_line][start_col:]
     parameter_list = Match(r'^([^(]*)\(', line)
     if parameter_list:
       # Match parentheses to find the end of the parameter list
       (_, end_line, end_col) = CloseExpression(
           clean_lines, start_line, start_col + len(parameter_list.group(1)))
       break
     start_col = 0
 
   if end_col < 0:
     return  # Couldn't find end of parameter list, give up
 
   # Look for "override" or "final" after the parameter list
   # (possibly on the next few lines).
-  for i in xrange(end_line, min(end_line + 3, clean_lines.NumLines())):
+  for i in range(end_line, min(end_line + 3, clean_lines.NumLines())):
     line = clean_lines.elided[i][end_col:]
     match = Search(r'\b(override|final)\b', line)
     if match:
       error(filename, linenum, 'readability/inheritance', 4,
             ('"virtual" is redundant since function is '
              'already declared as "%s"' % match.group(1)))
 
     # Set end_col to check whole lines after we are done with the
     # first line.
     end_col = 0
     if Search(r'[^\w]\s*$', line):
       break
@@ -5754,50 +5762,50 @@ def FlagCxx14Features(filename, clean_lines, linenum, error):
 def ProcessFileData(filename, file_extension, lines, error,
                     extra_check_functions=[]):
   """Performs lint checks and reports any errors to the given error function.
 
   Args:
     filename: Filename of the file that is being processed.
     file_extension: The extension (dot not included) of the file.
     lines: An array of strings, each representing a line of the file, with the
            last element being empty if the file is terminated with a newline.
     error: A callable to which errors are reported, which takes 4 arguments:
            filename, line number, error level, and message
     extra_check_functions: An array of additional check functions that will be
                            run on each source line. Each function takes 4
                            arguments: filename, clean_lines, line, error
   """
   lines = (['// marker so line numbers and indices both start at 1'] + lines +
            ['// marker so line numbers end in a known way'])
 
   include_state = _IncludeState()
   function_state = _FunctionState()
   nesting_state = NestingState()
 
   ResetNolintSuppressions()
 
   CheckForCopyright(filename, lines, error)
   ProcessGlobalSuppresions(lines)
   RemoveMultiLineComments(filename, lines, error)
   clean_lines = CleansedLines(lines)
 
   if file_extension == 'h':
     CheckForHeaderGuard(filename, clean_lines, error)
 
-  for line in xrange(clean_lines.NumLines()):
+  for line in range(clean_lines.NumLines()):
     ProcessLine(filename, file_extension, clean_lines, line,
                 include_state, function_state, nesting_state, error,
                 extra_check_functions)
     FlagCxx11Features(filename, clean_lines, line, error)
   nesting_state.CheckCompletedBlocks(filename, error)
 
   CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error)
 
   # Check that the .cc file has included its header if it exists.
   if _IsSourceExtension(file_extension):
     CheckHeaderFileIncluded(filename, include_state, error)
 
   # We check here rather than inside ProcessLine so that we see raw
   # lines rather than "cleaned" lines.
   CheckForBadCharacters(filename, lines, error)
 
   CheckForNewlineAtEOF(filename, lines, error)
@@ -5991,74 +5999,76 @@ def PrintCategories():
 def ParseArguments(args):
   """Parses the command line arguments.
 
   This may set the output format and verbosity level as side-effects.
 
   Args:
     args: The command line arguments:
 
   Returns:
     The list of filenames to lint.
   """
   try:
     (opts, filenames) = getopt.getopt(args, '', ['help', 'output=', 'verbose=',
+                                                 'headers=', # We understand but ignore headers.
                                                  'counting=',
                                                  'filter=',
                                                  'root=',
                                                  'linelength=',
                                                  'extensions=',
-                                                 'project_root='])
-  except getopt.GetoptError:
-    PrintUsage('Invalid arguments.')
+                                                 'project_root=',
+                                                 'repository='])
+  except getopt.GetoptError as e:
+    PrintUsage('Invalid arguments: {}'.format(e))
 
   verbosity = _VerboseLevel()
   output_format = _OutputFormat()
   filters = ''
   counting_style = ''
 
   for (opt, val) in opts:
     if opt == '--help':
       PrintUsage(None)
     elif opt == '--output':
       if val not in ('emacs', 'vs7', 'eclipse'):
         PrintUsage('The only allowed output formats are emacs, vs7 and eclipse.')
       output_format = val
     elif opt == '--verbose':
       verbosity = int(val)
     elif opt == '--filter':
       filters = val
       if not filters:
         PrintCategories()
     elif opt == '--counting':
       if val not in ('total', 'toplevel', 'detailed'):
         PrintUsage('Valid counting options are total, toplevel, and detailed')
       counting_style = val
     elif opt == '--root':
       global _root
       _root = val
-    elif opt == '--project_root':
+    elif opt == '--project_root' or opt == "--repository":
       global _project_root
       _project_root = val
       if not os.path.isabs(_project_root):
         PrintUsage('Project root must be an absolute path.')
     elif opt == '--linelength':
       global _line_length
       try:
           _line_length = int(val)
       except ValueError:
           PrintUsage('Line length must be digits.')
     elif opt == '--extensions':
       global _valid_extensions
       try:
           _valid_extensions = set(val.split(','))
       except ValueError:
           PrintUsage('Extensions must be comma separated list.')
 
   if not filenames:
     PrintUsage('No files were specified.')
 
   _SetOutputFormat(output_format)
   _SetVerboseLevel(verbosity)
   _SetFilters(filters)
   _SetCountingStyle(counting_style)
 
   return filenames
@@ -6067,16 +6077,17 @@ def ParseArguments(args):
 def main():
   filenames = ParseArguments(sys.argv[1:])
 
   # Change stderr to write with replacement characters so we don't die
   # if we try to print something containing non-ASCII characters.
-  sys.stderr = codecs.StreamReaderWriter(sys.stderr,
-                                         codecs.getreader('utf8'),
-                                         codecs.getwriter('utf8'),
-                                         'replace')
+  # We use sys.stderr.buffer in Python 3, since StreamReaderWriter writes bytes
+  # to the specified stream.
+  sys.stderr = codecs.StreamReaderWriter(
+      getattr(sys.stderr, 'buffer', sys.stderr),
+      codecs.getreader('utf8'), codecs.getwriter('utf8'), 'replace')
 
   _cpplint_state.ResetErrorCounts()
   for filename in filenames:
     ProcessFile(filename, _cpplint_state.verbose_level)
   _cpplint_state.PrintErrorCounts()
 
   sys.exit(_cpplint_state.error_count > 0)
diff --git a/scripts/pre-commit.hook b/scripts/pre-commit.hook
index 21cfe93..15a3ba2 100755
--- a/scripts/pre-commit.hook
+++ b/scripts/pre-commit.hook
@@ -27,17 +27,30 @@ if [ ! -x "$CPPLINT" ]; then
     # Running from "scripts" folder.
     CPPLINT="$ROOT/cpplint.py"
 fi
 
+PYTHON=$(which python || true)
+if [ -z "$PYTHON" ]; then
+    PYTHON=$(which python3 || true)
+fi
+
 # Run cpplint against changed C/C++ files and check if all enums from the API
 # are also updated in the Emscripten/Go files.
 check_c_enums=
 check_go_enums=
+logged_python=
 for file in `git diff-index --cached --name-only HEAD --diff-filter=ACMR| grep -E "\.cc$|\.h$|\.c$"` ; do
-    "$CPPLINT" "$file"
+    if [ -z "$PYTHON" ]; then
+        if [ -z "$logged_python" ]; then
+            echo "WARNING: Could not find valid Python interpreter to run cpplint, skipping checks..."
+            logged_python=1
+        fi
+    else
+        "$PYTHON" "$CPPLINT" "$file"
+    fi
     if [ "$file" = "libheif/heif.h" ] ; then
         check_c_enums=1
         check_go_enums=1
     fi
     if [ "$file" = "libheif/heif_emscripten.h" ] ; then
         check_c_enums=1
     fi
diff --git a/scripts/run-ci.sh b/scripts/run-ci.sh
index 9ee560b..0158780 100755
--- a/scripts/run-ci.sh
+++ b/scripts/run-ci.sh
@@ -44,11 +44,20 @@ if [ ! -z "$CHECK_LICENSES" ]; then
 fi
 
 if [ ! -z "$CPPLINT" ]; then
-    echo "Running cpplint ..."
-    find -name "*.c" -o -name "*.cc" -o -name "*.h" | sort | xargs ./scripts/cpplint.py --extensions=c,cc,h
+    PYTHON=$(which python || true)
+    if [ -z "$PYTHON" ]; then
+        PYTHON=$(which python3 || true)
+        if [ -z "$PYTHON" ]; then
+            echo "Could not find valid Python interpreter to run cpplint."
+            echo "Make sure you have either python or python3 in your PATH."
+            exit 1
+        fi
+    fi
+    echo "Running cpplint with $PYTHON ..."
+    find -name "*.c" -o -name "*.cc" -o -name "*.h" | sort | xargs "$PYTHON" ./scripts/cpplint.py --extensions=c,cc,h
     ./scripts/check-emscripten-enums.sh
     ./scripts/check-go-enums.sh
 
     echo "Running gofmt ..."
     ./scripts/check-gofmt.sh
     exit 0
