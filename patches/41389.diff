commit 48b15b0dfb4c5976519f2c7be005971565a84795
Merge: 9f611e8b8 a7d538a82
Author: David Garske <david@wolfssl.com>
Date:   Wed Dec 1 16:16:14 2021 -0800

    Merge pull request #4616 from SparkiDev/sp_int_mips32
    
    SP math all: MIPS asm fix

diff --git a/wolfcrypt/src/sp_int.c b/wolfcrypt/src/sp_int.c
index 4bc04d3a8..964f1a27e 100644
--- a/wolfcrypt/src/sp_int.c
+++ b/wolfcrypt/src/sp_int.c
@@ -616,1577 +616,1577 @@ static WC_INLINE sp_int_digit sp_div_word(sp_int_digit hi, sp_int_digit lo,
 #ifndef WOLFSSL_SP_DIV_WORD_HALF
 /* Divide a two digit number by a digit number and return. (hi | lo) / d
  *
  * Using divl instruction on Intel x64.
  *
  * @param  [in]  hi  SP integer digit. High digit of the dividend.
  * @param  [in]  lo  SP integer digit. Lower digit of the dividend.
  * @param  [in]  d   SP integer digit. Number to divide by.
  * @reutrn  The division result.
  */
 static WC_INLINE sp_int_digit sp_div_word(sp_int_digit hi, sp_int_digit lo,
                                           sp_int_digit d)
 {
     __asm__ __volatile__ (
         "divl %2"
         : "+a" (lo)
         : "d" (hi), "r" (d)
         : "cc"
     );
     return lo;
 }
 #define SP_ASM_DIV_WORD
 #endif
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_X86 && SP_WORD_SIZE == 32 */
 
     #if defined(WOLFSSL_SP_ARM64) && SP_WORD_SIZE == 64
 /*
  * CPU: Aarch64
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[b]	\n\t"            \
         "umulh	%[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory", "cc"                                 \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[b]		\n\t"            \
         "umulh	%[h], %[a], %[b]	\n\t"            \
         "mov	%[l], x8		\n\t"            \
         "mov	%[o], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "x8"                                           \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[b]		\n\t"            \
         "umulh	x9, %[a], %[b]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adcs	%[h], %[h], x9		\n\t"            \
         "adc	%[o], %[o], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "x8", "x9", "cc"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[b]		\n\t"            \
         "umulh	x9, %[a], %[b]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adc	%[h], %[h], x9		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "x8", "x9", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[b]		\n\t"            \
         "umulh	x9, %[a], %[b]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adcs	%[h], %[h], x9		\n\t"            \
         "adc	%[o], %[o], xzr		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adcs	%[h], %[h], x9		\n\t"            \
         "adc	%[o], %[o], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "x8", "x9", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[b]		\n\t"            \
         "umulh	x9, %[a], %[b]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adc	%[h], %[h], x9		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adcs	%[h], %[h], x9		\n\t"            \
         "adc	%[o], %[o], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "x8", "x9", "cc"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[a]	\n\t"            \
         "umulh	%[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[a]		\n\t"            \
         "umulh	x9, %[a], %[a]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adcs	%[h], %[h], x9		\n\t"            \
         "adc	%[o], %[o], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "x8", "x9", "cc"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "mul	x8, %[a], %[a]		\n\t"            \
         "umulh	x9, %[a], %[a]		\n\t"            \
         "adds	%[l], %[l], x8		\n\t"            \
         "adc	%[h], %[h], x9		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "x8", "x9", "cc"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adc	%[h], %[h], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "subs	%[l], %[l], %[a]	\n\t"            \
         "sbc	%[h], %[h], xzr		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adcs	%[h], %[h], %[b]	\n\t"            \
         "adc	%[o], %[o], %[c]	\n\t"            \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adcs	%[h], %[h], %[b]	\n\t"            \
         "adc	%[o], %[o], %[c]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "cc"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_ARM64 && SP_WORD_SIZE == 64 */
 
     #if (defined(WOLFSSL_SP_ARM32) || defined(WOLFSSL_SP_ARM_CORTEX_M)) && \
         SP_WORD_SIZE == 32
 /*
  * CPU: ARM32 or Cortex-M4 and similar
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "umull	%[l], %[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory"                                       \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "umull	%[l], %[h], %[a], %[b]	\n\t"            \
         "mov	%[o], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "umull	r8, r9, %[a], %[b]	\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adcs	%[h], %[h], r9		\n\t"            \
         "adc	%[o], %[o], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r8", "r9", "cc"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "umlal	%[l], %[h], %[a], %[b]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "umull	r8, r9, %[a], %[b]	\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adcs	%[h], %[h], r9		\n\t"            \
         "adc	%[o], %[o], #0		\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adcs	%[h], %[h], r9		\n\t"            \
         "adc	%[o], %[o], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r8", "r9", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "umull	r8, r9, %[a], %[b]	\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adc	%[h], %[h], r9		\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adcs	%[h], %[h], r9		\n\t"            \
         "adc	%[o], %[o], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r8", "r9", "cc"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "umull	%[l], %[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "umull	r8, r9, %[a], %[a]	\n\t"            \
         "adds	%[l], %[l], r8		\n\t"            \
         "adcs	%[h], %[h], r9		\n\t"            \
         "adc	%[o], %[o], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "r8", "r9", "cc"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "umlal	%[l], %[h], %[a], %[a]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adc	%[h], %[h], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "subs	%[l], %[l], %[a]	\n\t"            \
         "sbc	%[h], %[h], #0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adcs	%[h], %[h], %[b]	\n\t"            \
         "adc	%[o], %[o], %[c]	\n\t"            \
         "adds	%[l], %[l], %[a]	\n\t"            \
         "adcs	%[h], %[h], %[b]	\n\t"            \
         "adc	%[o], %[o], %[c]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "cc"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* (WOLFSSL_SP_ARM32 || ARM_CORTEX_M) && SP_WORD_SIZE == 32 */
 
     #if defined(WOLFSSL_SP_PPC64) && SP_WORD_SIZE == 64
 /*
  * CPU: PPC64
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "mulld	%[l], %[a], %[b]	\n\t"            \
         "mulhdu	%[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory"                                       \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mulhdu	%[h], %[a], %[b]	\n\t"            \
         "mulld	%[l], %[a], %[b]	\n\t"            \
         "li	%[o], 0			\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[b]		\n\t"            \
         "mulhdu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[b]		\n\t"            \
         "mulhdu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[b]		\n\t"            \
         "mulhdu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[b]		\n\t"            \
         "mulhdu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "mulld	%[l], %[a], %[a]	\n\t"            \
         "mulhdu	%[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[a]		\n\t"            \
         "mulhdu	17, %[a], %[a]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "16", "17", "cc"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "mulld	16, %[a], %[a]		\n\t"            \
         "mulhdu	17, %[a], %[a]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "16", "17", "cc"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "addze	%[h], %[h]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "subfc	%[l], %[a], %[l]	\n\t"            \
         "li    16, 0			\n\t"            \
         "subfe %[h], 16, %[h]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "16", "cc"                                     \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "adde	%[h], %[h], %[b]	\n\t"            \
         "adde	%[o], %[o], %[c]	\n\t"            \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "adde	%[h], %[h], %[b]	\n\t"            \
         "adde	%[o], %[o], %[c]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "cc"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_PPC64 && SP_WORD_SIZE == 64 */
 
     #if defined(WOLFSSL_SP_PPC) && SP_WORD_SIZE == 32
 /*
  * CPU: PPC 32-bit
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "mullw	%[l], %[a], %[b]	\n\t"            \
         "mulhwu	%[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory"                                       \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mulhwu	%[h], %[a], %[b]	\n\t"            \
         "mullw	%[l], %[a], %[b]	\n\t"            \
         "li	%[o], 0			\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[b]		\n\t"            \
         "mulhwu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[b]		\n\t"            \
         "mulhwu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[b]		\n\t"            \
         "mulhwu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[b]		\n\t"            \
         "mulhwu	17, %[a], %[b]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "16", "17", "cc"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "mullw	%[l], %[a], %[a]	\n\t"            \
         "mulhwu	%[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[a]		\n\t"            \
         "mulhwu	17, %[a], %[a]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         "addze	%[o], %[o]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "16", "17", "cc"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "mullw	16, %[a], %[a]		\n\t"            \
         "mulhwu	17, %[a], %[a]		\n\t"            \
         "addc	%[l], %[l], 16		\n\t"            \
         "adde	%[h], %[h], 17		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "16", "17", "cc"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "addze	%[h], %[h]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "cc"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "subfc	%[l], %[a], %[l]	\n\t"            \
         "li	16, 0			\n\t"            \
         "subfe	%[h], 16, %[h]		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "16", "cc"                                     \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "adde	%[h], %[h], %[b]	\n\t"            \
         "adde	%[o], %[o], %[c]	\n\t"            \
         "addc	%[l], %[l], %[a]	\n\t"            \
         "adde	%[h], %[h], %[b]	\n\t"            \
         "adde	%[o], %[o], %[c]	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "cc"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_PPC && SP_WORD_SIZE == 64 */
 
     #if defined(WOLFSSL_SP_MIPS64) && SP_WORD_SIZE == 64
 /*
  * CPU: MIPS 64-bit
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory", "$lo", "$hi"                         \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         "move	%[o], $0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "$lo", "$hi"                                   \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[a]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory", "$lo", "$hi"                         \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[a]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "dmultu	%[a], %[a]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "daddu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "daddu	%[h], %[h], $11		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "$10", "$11", "$12", "$lo", "$hi"              \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "daddu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "$12"                                          \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "move	$12, %[l]		\n\t"            \
         "dsubu	%[l], $12, %[a]		\n\t"            \
         "sltu	$12, $12, %[l]		\n\t"            \
         "dsubu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "$12"                                          \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "daddu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], %[b]	\n\t"            \
         "sltu	$12, %[h], %[b]		\n\t"            \
         "daddu	%[o], %[o], %[c]	\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "daddu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         "daddu	%[h], %[h], %[b]	\n\t"            \
         "sltu	$12, %[h], %[b]		\n\t"            \
         "daddu	%[o], %[o], %[c]	\n\t"            \
         "daddu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "$12"                                          \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_MIPS64 && SP_WORD_SIZE == 64 */
 
     #if defined(WOLFSSL_SP_MIPS) && SP_WORD_SIZE == 32
 /*
  * CPU: MIPS 32-bit
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "memory", "$lo", "$hi"                         \
+        : "memory", "%lo", "%hi"                         \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         "move	%[o], $0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "$lo", "$hi"                                   \
+        : "%lo", "%hi"                                   \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[b]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[a]		\n\t"            \
         "mflo	%[l]			\n\t"            \
         "mfhi	%[h]			\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
-        : "memory", "$lo", "$hi"                         \
+        : "memory", "%lo", "%hi"                         \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[a]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "sltu	$12, %[h], $11		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "multu	%[a], %[a]		\n\t"            \
         "mflo	$10			\n\t"            \
         "mfhi	$11			\n\t"            \
         "addu	%[l], %[l], $10		\n\t"            \
         "sltu	$12, %[l], $10		\n\t"            \
         "addu	%[h], %[h], $11		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
-        : "$10", "$11", "$12", "$lo", "$hi"              \
+        : "$10", "$11", "$12", "%lo", "%hi"              \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "addu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "$12"                                          \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "move	$12, %[l]		\n\t"            \
         "subu	%[l], $12, %[a]		\n\t"            \
         "sltu	$12, $12, %[l]		\n\t"            \
         "subu	%[h], %[h], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "$12"                                          \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "addu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], %[b]	\n\t"            \
         "sltu	$12, %[h], %[b]		\n\t"            \
         "addu	%[o], %[o], %[c]	\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[l], %[l], %[a]	\n\t"            \
         "sltu	$12, %[l], %[a]		\n\t"            \
         "addu	%[h], %[h], $12		\n\t"            \
         "sltu	$12, %[h], $12		\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         "addu	%[h], %[h], %[b]	\n\t"            \
         "sltu	$12, %[h], %[b]		\n\t"            \
         "addu	%[o], %[o], %[c]	\n\t"            \
         "addu	%[o], %[o], $12		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "$12"                                          \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_MIPS && SP_WORD_SIZE == 32 */
 
     #if defined(WOLFSSL_SP_RISCV64) && SP_WORD_SIZE == 64
 /*
  * CPU: RISCV 64-bit
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[b]	\n\t"            \
         "mulhu	%[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory"                                       \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mulhu	%[h], %[a], %[b]	\n\t"            \
         "mul	%[l], %[a], %[b]	\n\t"            \
         "add	%[o], zero, zero	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[a]	\n\t"            \
         "mulhu	%[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[a]		\n\t"            \
         "mulhu	a6, %[a], %[a]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "a5", "a6", "a7"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[a]		\n\t"            \
         "mulhu	a6, %[a], %[a]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a5", "a6", "a7"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a7"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "add	a7, %[l], zero		\n\t"            \
         "sub	%[l], a7, %[a]		\n\t"            \
         "sltu	a7, a7, %[l]		\n\t"            \
         "sub	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a7"                                           \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], %[b]	\n\t"            \
         "sltu	a7, %[h], %[b]		\n\t"            \
         "add	%[o], %[o], %[c]	\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], %[b]	\n\t"            \
         "sltu	a7, %[h], %[b]		\n\t"            \
         "add	%[o], %[o], %[c]	\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "a7"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_RISCV64 && SP_WORD_SIZE == 64 */
 
     #if defined(WOLFSSL_SP_RISCV32) && SP_WORD_SIZE == 32
 /*
  * CPU: RISCV 32-bit
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[b]	\n\t"            \
         "mulhu	%[h], %[a], %[b]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory"                                       \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mulhu	%[h], %[a], %[b]	\n\t"            \
         "mul	%[l], %[a], %[b]	\n\t"            \
         "add	%[o], zero, zero	\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         :                                                \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[b]		\n\t"            \
         "mulhu	a6, %[a], %[b]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "a5", "a6", "a7"                               \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "mul	%[l], %[a], %[a]	\n\t"            \
         "mulhu	%[h], %[a], %[a]	\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory"                                       \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[a]		\n\t"            \
         "mulhu	a6, %[a], %[a]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "sltu	a7, %[h], a6		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "a5", "a6", "a7"                               \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "mul	a5, %[a], %[a]		\n\t"            \
         "mulhu	a6, %[a], %[a]		\n\t"            \
         "add	%[l], %[l], a5		\n\t"            \
         "sltu	a7, %[l], a5		\n\t"            \
         "add	%[h], %[h], a6		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a5", "a6", "a7"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a7"                                           \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "add	a7, %[l], zero		\n\t"            \
         "sub	%[l], a7, %[a]		\n\t"            \
         "sltu	a7, a7, %[l]		\n\t"            \
         "sub	%[h], %[h], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "a7"                                           \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], %[b]	\n\t"            \
         "sltu	a7, %[h], %[b]		\n\t"            \
         "add	%[o], %[o], %[c]	\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[l], %[l], %[a]	\n\t"            \
         "sltu	a7, %[l], %[a]		\n\t"            \
         "add	%[h], %[h], a7		\n\t"            \
         "sltu	a7, %[h], a7		\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         "add	%[h], %[h], %[b]	\n\t"            \
         "sltu	a7, %[h], %[b]		\n\t"            \
         "add	%[o], %[o], %[c]	\n\t"            \
         "add	%[o], %[o], a7		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "a7"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_RISCV32 && SP_WORD_SIZE == 32 */
 
     #if defined(WOLFSSL_SP_S390X) && SP_WORD_SIZE == 64
 /*
  * CPU: Intel s390x
  */
 
 /* Multiply va by vb and store double size result in: vh | vl */
 #define SP_ASM_MUL(vl, vh, va, vb)                       \
     __asm__ __volatile__ (                               \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "lgr	%[l], %%r1		\n\t"            \
         "lgr	%[h], %%r0		\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "memory", "r0", "r1"                           \
     )
 /* Multiply va by vb and store double size result in: vo | vh | vl */
 #define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "lghi	%[o], 0			\n\t"            \
         "lgr	%[l], %%r1		\n\t"            \
         "lgr	%[h], %%r0		\n\t"            \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r0", "r1"                                     \
     )
 /* Multiply va by vb and add double size result into: vo | vh | vl */
 #define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "alcgr	%[o], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r0", "r1", "r10", "cc"                        \
     )
 /* Multiply va by vb and add double size result into: vh | vl */
 #define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
     __asm__ __volatile__ (                               \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r0", "r1", "cc"                               \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl */
 #define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "alcgr	%[o], %%r10	\n\t"                    \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "alcgr	%[o], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r0", "r1", "r10", "cc"                        \
     )
 /* Multiply va by vb and add double size result twice into: vo | vh | vl
  * Assumes first add will not overflow vh | vl
  */
 #define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %[b]		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "alcgr	%[o], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb)                     \
         : "r0", "r1", "r10", "cc"                        \
     )
 /* Square va and store double size result in: vh | vl */
 #define SP_ASM_SQR(vl, vh, va)                           \
     __asm__ __volatile__ (                               \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %%r1		\n\t"            \
         "lgr	%[l], %%r1		\n\t"            \
         "lgr	%[h], %%r0		\n\t"            \
         : [h] "+r" (vh), [l] "+r" (vl)                   \
         : [a] "r" (va)                                   \
         : "memory", "r0", "r1"                           \
     )
 /* Square va and add double size result into: vo | vh | vl */
 #define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %%r1		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         "alcgr	%[o], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va)                                   \
         : "r0", "r1", "r10", "cc"                        \
     )
 /* Square va and add double size result into: vh | vl */
 #define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
     __asm__ __volatile__ (                               \
         "lgr	%%r1, %[a]		\n\t"            \
         "mlgr	%%r0, %%r1		\n\t"            \
         "algr	%[l], %%r1	\n\t"                    \
         "alcgr	%[h], %%r0	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "r0", "r1", "cc"                               \
     )
 /* Add va into: vh | vl */
 #define SP_ASM_ADDC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "algr	%[l], %[a]	\n\t"                    \
         "alcgr	%[h], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "r10", "cc"                                    \
     )
 /* Sub va from: vh | vl */
 #define SP_ASM_SUBC(vl, vh, va)                          \
     __asm__ __volatile__ (                               \
         "lghi	%%r10, 0	\n\t"                    \
         "slgr	%[l], %[a]	\n\t"                    \
         "slbgr	%[h], %%r10	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh)                   \
         : [a] "r" (va)                                   \
         : "r10", "cc"                                    \
     )
 /* Add two times vc | vb | va into vo | vh | vl */
 #define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
     __asm__ __volatile__ (                               \
         "algr	%[l], %[a]	\n\t"                    \
         "alcgr	%[h], %[b]	\n\t"                    \
         "alcgr	%[o], %[c]	\n\t"                    \
         "algr	%[l], %[a]	\n\t"                    \
         "alcgr	%[h], %[b]	\n\t"                    \
         "alcgr	%[o], %[c]	\n\t"                    \
         : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "cc"                                           \
     )
 
 #define SP_INT_ASM_AVAILABLE
 
     #endif /* WOLFSSL_SP_S390X && SP_WORD_SIZE == 64 */
 
 #ifdef SP_INT_ASM_AVAILABLE
     #ifndef SP_INT_NO_ASM
         #define SQR_MUL_ASM
     #endif
     #ifndef SP_ASM_ADDC_REG
         #define SP_ASM_ADDC_REG  SP_ASM_ADDC
     #endif /* SP_ASM_ADDC_REG */
 #endif /* SQR_MUL_ASM */
 
 #endif /* !WOLFSSL_NO_ASM */
 
 
 #if (!defined(NO_RSA) && !defined(WOLFSSL_RSA_PUBLIC_ONLY)) || \
     !defined(NO_DSA) || !defined(NO_DH) || \
     (defined(HAVE_ECC) && defined(HAVE_COMP_KEY)) || defined(OPENSSL_EXTRA) || \
     (defined(WOLFSSL_SP_MATH_ALL) && !defined(WOLFSSL_RSA_PUBLIC_ONLY))
 #ifndef WC_NO_CACHE_RESISTANT
     /* Mask of address for constant time operations. */
     const size_t sp_off_on_addr[2] =
     {
         (size_t) 0,
         (size_t)-1
     };
 #endif
 #endif
 
 
 #if defined(WOLFSSL_HAVE_SP_DH) || defined(WOLFSSL_HAVE_SP_RSA)
 
 #ifdef __cplusplus
